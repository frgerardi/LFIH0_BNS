{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(1, './modules/')\n",
    "import pydelfi_t1.priors as priors\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#importing simulation modules and parameters file______\n",
    "import simulator as sims\n",
    "data_generation=sims.simulations()\n",
    "from set_params import *\n",
    "\n",
    "data_generation=sims.simulations()\n",
    "#______________________________________________________\n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow {}\\nnumpy {}\".format(\n",
    "    tf.__version__, np.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_data = True\n",
    "\n",
    "def check_data(data):\n",
    "    print(data.shape)\n",
    "    for j in range (n_obs):\n",
    "        for i in range (int(100)):\n",
    "            plt.hist(data[i,100*j:100*(j+1)])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating real data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sets = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_realdata = True\n",
    "\n",
    "if new_realdata == True:\n",
    "    if not os.path.exists('{}'.format(pathtorealsamples)):\n",
    "        os.makedirs('{}'.format(pathtorealsamples))\n",
    "    print('APPLYING LATIN HYPERCUBE')\n",
    "\n",
    "    sampling = LHS(xlimits=np.array([[65,75],[-0.7,-0.3]]))\n",
    "    draws = sampling(n_sets)\n",
    "    \n",
    "    print(np.corrcoef(draws[:,0],draws[:,1]))\n",
    "    plt.scatter(draws[:,0],draws[:,1])\n",
    "    plt.show()\n",
    "    \n",
    "    real_data = np.zeros((n_sets,(n_obs)*n_sources))\n",
    "    \n",
    "    for i in range (n_sets):\n",
    "        theta=np.array([draws[i][0],draws[i][1]])\n",
    "        sim = data_generation.data_simulator(theta = theta)\n",
    "        real_data[i] = sim    \n",
    "\n",
    "    np.savetxt('{}'.format(pathtorealsamples)+'/multi_thetas{}.txt'.format(ref_filename),draws)    \n",
    "    np.savetxt('{}'.format(pathtorealsamples)+'/multi_randomdata{}.txt'.format(ref_filename),real_data)\n",
    "    \n",
    "\n",
    "if checking_data == True:\n",
    "    data = np.loadtxt('{}'.format(pathtorealsamples)+'/multi_randomdata{}.txt'.format(ref_filename))\n",
    "    check_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating training data for the regression neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_NN_data = True\n",
    "\n",
    "if new_NN_data == True:\n",
    "    data_generation.NN_datasets()\n",
    "    \n",
    "if checking_data == True:\n",
    "    train_data = np.load('{}'.format(pathtoNNsims)+'training_datasets{}.npy'.format(ref_filename))\n",
    "    check_data(train_data)\n",
    "    val_data = np.load('{}'.format(pathtoNNsims)+'validation_datasets{}.npy'.format(ref_filename))\n",
    "    check_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the prerun simulation for LFI computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prerunsims = True\n",
    "n_sims = 2000\n",
    "\n",
    "if new_prerunsims == True:\n",
    "    \n",
    "    pathlib.Path('{}'.format(pathtopydelfiprerunsims)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # drawing thetas\n",
    "\n",
    "    print('APPLYING UNIFORM PRIOR')\n",
    "    prior_distr = priors.Uniform(lower, upper)     \n",
    "\n",
    "    draws = np.zeros((n_sims,2))\n",
    "    for i in range (n_sims):\n",
    "        draws[i]=prior_distr.draw()\n",
    "    \n",
    "    np.savetxt('{}'.format(pathtopydelfiprerunsims)+'/prerun_thetas{}.txt'.format(ref_filename),draws) \n",
    "\n",
    "    #sims\n",
    "\n",
    "    prerun_sims = np.zeros((n_sims,(n_obs)*n_sources))\n",
    "    for i in range (n_sims):\n",
    "        theta=np.array([draws[i][0],draws[i][1]])\n",
    "        sim = data_generation.data_simulator(theta = theta)\n",
    "        prerun_sims[i] = sim  \n",
    "    \n",
    "    np.savetxt('{}'.format(pathtopydelfiprerunsims)+'/prerun_sims{}.txt'.format(ref_filename),prerun_sims)\n",
    "\n",
    "    print(prerun_sims.shape)\n",
    "    print(draws.shape)\n",
    "    \n",
    "if checking_data == True:\n",
    "    prerun_data = np.loadtxt('{}'.format(pathtopydelfiprerunsims)+'/prerun_sims{}.txt'.format(ref_filename))\n",
    "    check_data(prerun_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ./modules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if sys.version[0]==3:\n",
    "    pathlib.Path('{}'.format(pathtoNNmodels)).mkdir(parents=True, exist_ok=True) \n",
    "else:\n",
    "    if not os.path.exists('{}'.format(pathtoNNmodels)):\n",
    "        os.makedirs('{}'.format(pathtoNNmodels))\n",
    "\n",
    "if MPI_process == True:\n",
    "    !mpiexec -np 12 python NN.py\n",
    "else:\n",
    "    %run NN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./modules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range (1):\n",
    "    np.save('real_data_element',k)\n",
    "    %run STAN.py\n",
    "os.remove(\"real_data_element.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood free inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./modules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version[0]==3:\n",
    "    pathlib.Path('{}'.format(pathtoLFIresults)).mkdir(parents=True, exist_ok=True) \n",
    "else:\n",
    "    if not os.path.exists('{}'.format(pathtoLFIresults)):\n",
    "        os.makedirs('{}'.format(pathtoLFIresults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_real_data = True\n",
    "if all_real_data == True:\n",
    "    for k in range (100):\n",
    "        np.save('real_data_element',k)\n",
    "        if MPI_process == True:\n",
    "            !mpiexec -np 12 python LFI.py\n",
    "        else:\n",
    "            %run LFI.py\n",
    "        dest = '../LFI_results/results_pydelfi_{}'.format(k)\n",
    "        if os.path.isdir(dest) == True:\n",
    "            for file in glob.glob('../results_pydelfi/*'):\n",
    "                shutil.move(file, dest)\n",
    "        else:\n",
    "            os.rename('../results_pydelfi',dest)\n",
    "    os.remove('real_data_element.npy')\n",
    "else:\n",
    "    if MPI_process == True:\n",
    "        !mpiexec -np 1 python LFI.py\n",
    "    else:\n",
    "        %run LFI.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
