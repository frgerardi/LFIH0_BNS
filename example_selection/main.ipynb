{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.15.0\n",
      "numpy 1.19.5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(1, './modules/')\n",
    "import pydelfi_t1.priors as priors\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#importing simulation modules and parameters file______\n",
    "import simulator as sims\n",
    "data_generation=sims.simulations()\n",
    "from set_params import *\n",
    "\n",
    "data_generation=sims.simulations()\n",
    "#______________________________________________________\n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow {}\\nnumpy {}\".format(\n",
    "    tf.__version__, np.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_data = True\n",
    "\n",
    "def check_data(data,n_sims=100):\n",
    "    print(data.shape)\n",
    "    for j in range (n_obs):\n",
    "        for i in range (n_sims):\n",
    "            plt.hist(data[i,100*j:100*(j+1)])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating real data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sets = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING LATIN HYPERCUBE\n",
      "(2, 300)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_realdata = True\n",
    "\n",
    "if new_realdata == True:\n",
    "    if not os.path.exists('{}'.format(pathtorealsamples)):\n",
    "        os.makedirs('{}'.format(pathtorealsamples))\n",
    "    print('APPLYING LATIN HYPERCUBE')\n",
    "\n",
    "    sampling = LHS(xlimits=np.array([[65,75],[-0.7,-0.3]]))\n",
    "    draws = sampling(n_sets)\n",
    "    \n",
    "    #print(np.corrcoef(draws[:,0],draws[:,1]))\n",
    "    #plt.scatter(draws[:,0],draws[:,1])\n",
    "    #plt.show()\n",
    "    \n",
    "    real_data = np.zeros((n_sets,(n_obs)*n_sources))\n",
    "    \n",
    "    for i in range (n_sets):\n",
    "        theta=np.array([draws[i][0],draws[i][1]])\n",
    "        sim = data_generation.data_simulator(theta = theta)\n",
    "        real_data[i] = sim\n",
    "\n",
    "    np.savetxt('{}'.format(pathtorealsamples)+'/multi_thetas{}.txt'.format(ref_filename),draws)    \n",
    "    np.savetxt('{}'.format(pathtorealsamples)+'/multi_randomdata{}.txt'.format(ref_filename),real_data)\n",
    "    \n",
    "\n",
    "if checking_data == True:\n",
    "    data = np.loadtxt('{}'.format(pathtorealsamples)+'/multi_randomdata{}.txt'.format(ref_filename))\n",
    "    check_data(data,n_sims=n_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating training data for the regression neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing training simulations\n",
      "(5, 1000, 302)\n",
      "0/1000 thetas done\n",
      "time for all sims 0:00:01\n",
      "100/1000 thetas done\n",
      "time for all sims 0:00:22\n",
      "200/1000 thetas done\n",
      "time for all sims 0:00:44\n",
      "300/1000 thetas done\n",
      "time for all sims 0:01:05\n",
      "400/1000 thetas done\n",
      "time for all sims 0:01:27\n",
      "500/1000 thetas done\n",
      "time for all sims 0:01:47\n",
      "600/1000 thetas done\n",
      "time for all sims 0:02:09\n",
      "700/1000 thetas done\n",
      "time for all sims 0:02:31\n",
      "800/1000 thetas done\n",
      "time for all sims 0:02:52\n",
      "900/1000 thetas done\n",
      "time for all sims 0:03:14\n",
      "computing validation simulations\n",
      "(2, 1000, 302)\n",
      "0/1000 thetas done\n",
      "time for all sims 0:00:00\n",
      "100/1000 thetas done\n",
      "time for all sims 0:00:09\n",
      "200/1000 thetas done\n",
      "time for all sims 0:00:18\n",
      "300/1000 thetas done\n",
      "time for all sims 0:00:26\n",
      "400/1000 thetas done\n",
      "time for all sims 0:00:34\n",
      "500/1000 thetas done\n",
      "time for all sims 0:00:43\n",
      "600/1000 thetas done\n",
      "time for all sims 0:00:51\n",
      "700/1000 thetas done\n",
      "time for all sims 0:01:00\n",
      "800/1000 thetas done\n",
      "time for all sims 0:01:09\n",
      "900/1000 thetas done\n",
      "time for all sims 0:01:17\n",
      "(5000, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_NN_data = True\n",
    "\n",
    "if new_NN_data == True:\n",
    "    data_generation.NN_datasets()\n",
    "    \n",
    "if checking_data == True:\n",
    "    train_data = np.load('{}'.format(pathtoNNsims)+'training_datasets{}.npy'.format(ref_filename))\n",
    "    check_data(train_data)\n",
    "    val_data = np.load('{}'.format(pathtoNNsims)+'validation_datasets{}.npy'.format(ref_filename))\n",
    "    check_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the prerun simulation for LFI computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING UNIFORM PRIOR\n",
      "(2000, 300)\n",
      "(2000, 2)\n",
      "(2000, 300)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT6ElEQVR4nO3dfbBc9V3H8fdXShsfUKBcITxck2ItwWFI6x3EqUBILFAGJUxqQ3VoqmhMhbFVrKbijNfBGYuVPo0pMRWmsYMQlPIwlEoxCYTOtNhQ0wK9RR47JQRiLbQ4Cm3ar3/suWHvze7d583+yPs1s7Pn/M7v7Plk78n3nnv2d85GZiJJKs+P7O8AkqTuWMAlqVAWcEkqlAVckgplAZekQr1qmBs74ogjcsGCBcPcpCQV7/777/9WZo7Nbh9qAV+wYAHbt28f5iYlqXgR8Y1G7Z5CkaRCWcAlqVAWcEkqlAVckgplAZekQlnAJalQFnBJKpQFXJIKZQGXpEIN9UpMaZRt3nL8ULazbOljQ9mOXvk8ApekQlnAJalQFnBJKpQFXJIKZQGXpEJZwCWpUBZwSSqUBVySCtWygEfEvIj494j4SkQ8FBF/WbUvjIj7IuLRiNgUEa8efFxJ0rR2jsBfApZm5snAYuCciDgVuBL4cGb+LPAccPHAUkqS9tGygGfN/1SzB1ePBJYC/1K1bwSWDyKgJKmxts6BR8RBEbED2A3cBTwGPJ+Ze6ouTwHHDCShJKmhtm5mlZk/ABZHxKHAzcAJ7W4gIlYDqwHGx8e7iCj1x+Tk5JzLTzu9/ddatu1b3QfZ9lOd9Z/8Tvfb0itaR6NQMvN5YCvwS8ChETH9C+BYYGeTdTZk5kRmToyNjfWSVZJUp51RKGPVkTcR8aPAW4ApaoX8bVW3VcCtA8ooSWqgnVMo84GNEXEQtYJ/Y2beHhFfA26IiL8C/gO4ZoA5JUmztCzgmflV4I0N2h8HThlEKElSa16JKUmFsoBLUqEs4JJUKAu4JBXKAi5JhbKAS1KhLOCSVCgLuCQVqq2bWUklanXzqtnu3XZR232X8eEO00j95xG4JBXKAi5JhbKAS1KhLOCSVCgLuCQVylEoGhlTJyzq7wteuLK/ryeNGI/AJalQFnBJKpQFXJIKZQGXpEJZwCWpUBZwSSqUwwhVjLe/v9Pd9aa+Z1jxxIq+v6bULY/AJalQFnBJKlTLAh4Rx0XE1oj4WkQ8FBHvqdonI2JnROyoHucOPq4kaVo7JxX3AJdl5pcj4hDg/oi4q1r24cz828HFkyQ107KAZ+YuYFc1/UJETAHHDDqYJGluHX2sHxELgDcC9wFvBi6NiHcC26kdpT/XYJ3VwGqA8fHxXvPqALRlybpq6j0Def01X/ho5ysd5Veqaf9r+0PMiPgJauOy3puZ3wWuBo4HFlM7Qr+q0XqZuSEzJzJzYmxsrPfEkiSgzQIeEQdTK97XZeanATLz2cz8QWb+EPgEcMrgYkqSZmtnFEoA1wBTmfmhuvb5dd0uAB7sfzxJUjPtnAN/M3AR8EBE7Kja/gx4R0QsBhJ4Evi9AeSTJDXRziiUzwPRYNEd/Y8jSWqX90LRAaOr0SZNrHvm5hnzlxx1QcN+Jy3sw8irjSft03TjX+9p2HXR16d6356K4aX0klQoC7gkFcoCLkmFsoBLUqEs4JJUKAu4JBXKYYQaGU9//HsN20/gdwH4SBev+d5v/hifnfp4bebQrmI1devz3+/vC3ag2Xv19JbjO3qdZUsf60cc7ScegUtSoSzgklQoC7gkFcoCLkmFsoBLUqEchaKhO6nBzZkAPnLckIP00dQNRzdsv5HGN51q19vf3/i/6NG//+o512s2SkWvLB6BS1KhLOCSVCgLuCQVygIuSYWygEtSoSzgklQohxFqv1nxxIqZDcd9qu/bWPOFj/b9JlbSqPAIXJIKZQGXpEK1LOARcVxEbI2Ir0XEQxHxnqr98Ii4KyIeqZ4PG3xcSdK0do7A9wCXZeaJwKnAJRFxIrAW2JyZrwc2V/OSpCFpWcAzc1dmfrmafgGYAo4Bzgc2Vt02AssHlFGS1EBHo1AiYgHwRuA+4MjM3FUtegY4ssk6q4HVAOPj410H1Wh6au29bfc9dt55TN1wNDfubdk0Y/nTp/ctltrU6Od37AdO2w9J1I22P8SMiJ8AbgLem5nfrV+WmQlko/Uyc0NmTmTmxNjYWE9hJUkva6uAR8TB1Ir3dZn56ar52YiYXy2fD+weTERJUiPtjEIJ4BpgKjM/VLfoNmBVNb0KuLX/8SRJzbRzDvzNwEXAAxGxo2r7M+ADwI0RcTHwDeDtA0koSWqoZQHPzM8D0WTxsv7GkSS1yysxJalQ3sxKrwi/GTc1XrASrujhdbff+cKM+X+YtxmA007/FCfUtT/dhxOIrb7nUprNI3BJKpQFXJIKZQGXpEJZwCWpUBZwSSqUo1DUlQVrP9Oyz+f5yX3atixZx9K7LxlEpOIdsnwDAC/csnpv241/vaer12p3RMsLtfvMcebV17/cuHUHz5y5uKvtarg8ApekQlnAJalQFnBJKpQFXJIKZQGXpEJZwCWpUA4j1D7WrdnSutOhjZvfNe9LL8+82Ppuw3ecfPze6cVMtd7ukE3fvEoaRR6BS1KhLOCSVCgLuCQVygIuSYWygEtSoRyFoo6t/6X3wNQHZrS9ePYxtWUc83K/fda8B4Cldw8uWykafgXc2dPP1++7rE3X5YoZ8+3e1GrenTv3/gwBjtq6A4A199zSdJ3JyclO46nPPAKXpEJZwCWpUBZwSSpUywIeEddGxO6IeLCubTIidkbEjupx7mBjSpJma+cI/JPAOQ3aP5yZi6vHHf2NJUlqpWUBz8xtwLeHkEWS1IFehhFeGhHvBLYDl2Xmc406RcRqqH3x3vj4eA+b0yBctfK8fdrmHfZHc35v5dK7YdGFvzGj7ahqiOBsz9xzxj5tUxzdWUh1bcuSdU2X1f+M64cQ1lt/xnJg7uGE2n+6/RDzauB4YDGwC7iqWcfM3JCZE5k5MTY21uXmJEmzdVXAM/PZzPxBZv4Q+ARwSn9jSZJa6aqAR8T8utkLgAeb9ZUkDUbLc+ARcT2wBDgiIp4C/gJYEhGLgQSeBH5vcBElSY20LOCZ+Y4GzdcMIIskqQPezOoAd+5XHtun7cyrD+eKld3fUKneUWfMHJ3SaFTKKJsehbFPO43bR835hx68d/rW57/ftN/Wdzc6TmvujpOP56qV53HZptu7zqbeeSm9JBXKAi5JhbKAS1KhLOCSVCgLuCQVygIuSYVyGOEBZvOW42fMH01735moV7ZFFz4NwIIX/4nP3vLHba930saT2u77wKoHOs6luXkELkmFsoBLUqEs4JJUKAu4JBXKAi5JhXIUygHgqbX3ArDpiStZvJ9v/Lv59CPg9O/tnV/M1H5Mo169646f2Tv9yXO/MWffdWu2AHDJ+qUDzXQg8QhckgplAZekQlnAJalQFnBJKpQFXJIKZQGXpEI5jPAA9ptxE1vp7LsQ+7FNjZ6TFo4DcAhr2TRvZVevseKJiYbtNy30Zz4oHoFLUqEs4JJUqJYFPCKujYjdEfFgXdvhEXFXRDxSPR822JiSpNnaOQL/JHDOrLa1wObMfD2wuZqXJA1RywKemduAb89qPh/YWE1vBJb3N5YkqZVuR6EcmZm7qulngCObdYyI1cBqgPHx8S43p3ZMnbCoYfshyzc0bL8uV/D0xweZSKPk/EMPntlQt198tsd7iv3DvM1Nl33kuP8F4OKp/wPgg2s/s3fZu+Z9ae/05ORkbyEOQD1/iJmZCeQcyzdk5kRmToyNjfW6OUlSpdsC/mxEzAeonnf3L5IkqR3dFvDbgFXV9Crg1v7EkSS1q51hhNcDXwDeEBFPRcTFwAeAt0TEI8CvVPOSpCFq+SFmZja71npZn7NIkjrglZiSVChvZjWCjtq6o+my963/8+Yrnnx84/Ynrpwxe++2i+YOcMbcizW69rlZ2Nn9e+3rcgUAb/jcJ7ta/5qz/qDpspb7pBryCFySCmUBl6RCWcAlqVAWcEkqlAVckgrlKBRJA7Xj7xvfZK3eIWznqpXnAXDZptsHHekVwyNwSSqUBVySCmUBl6RCWcAlqVAWcEkqlAVckgrlMMJRMflTeye33nB00253NLthVQPzDvujfdq+fiNw1LaOokm9WLnwT9k064Zqc6r7v7DumZv3Tl+yfmk/Y70ieAQuSYWygEtSoSzgklQoC7gkFcoCLkmFchTKEC1Y+xne9/yPNln68qftLGn+GvP6GUjqk/VnLGfNPbd0te4H1/zVzPkm/a6Y46sGG5nz6wdnKfUGWh6BS1KhLOCSVKieTqFExJPAC8APgD2ZOdGPUJKk1vpxDvzMzPxWH15HktQBT6FIUqF6PQJP4HMRkcDfZ+aG2R0iYjWwGmB8fLzHzZXhpI0nzZhf84WPAvA+mo1Aac+Lz31oxvzsT+/bt7ynHNJsW9/9jqbLXmAT59LZfXzUnl6PwH85M98EvBW4JCJOn90hMzdk5kRmToyNjfW4OUnStJ4KeGburJ53UxvIfEo/QkmSWuu6gEfEj0fEIdPTwFnAg/0KJkmaWy/nwI8Ebo6I6df5p8z8176kkiS11HUBz8zHgZP7mEWS1AGHEUpSoQ7Im1lt3tLbcKb3fvPH5ly+4okVM+b/a46vMBt7Zp+BO9Ir0mWL7p0xf9XUaQPd3sqFf7pP2wu3rG7Yd+qERQBsWbKu4fJR/To3j8AlqVAWcEkqlAVckgplAZekQlnAJalQkZlD29jExERu3759aNtrZnJysq1+K2/Y1JftnXn19X15HUn9MdfNt6bVj0jZ36NQIuL+Rt+34BG4JBXKAi5JhbKAS1KhLOCSVCgLuCQVygIuSYU6IG9m1U9blqxj6d2X7O8Ykma5LlewbNu3Gi57avntLdc/v77/2nub9qt37LzzahOT32mrf688ApekQlnAJalQFnBJKpQFXJIKZQGXpEIVMwpl+iuP+mFlG30WXfg0XNhGPy5giqN7ziSp/yb5w8YL5m3ep+l3XlzWt+2uW7Nln7ZB3BDLI3BJKpQFXJIKZQGXpEL1VMAj4pyIeDgiHo2Itf0KJUlqresCHhEHAeuAtwInAu+IiBP7FUySNLdejsBPAR7NzMcz83vADcy8fYAkaYC6/k7MiHgbcE5m/k41fxHwi5l56ax+q4HV1ewbgIeBI4DGd5kZPWbtv1JyQjlZS8kJZu3Gz2Tm2OzGgY8Dz8wNwIb6tojY3ugLOkeRWfuvlJxQTtZScoJZ+6mXUyg7gePq5o+t2iRJQ9BLAf8S8PqIWBgRr6Z23eJt/YklSWql61MombknIi4F7gQOAq7NzIfaXH1D6y4jw6z9V0pOKCdrKTnBrH3T9YeYkqT9yysxJalQFnBJKtRACnhEfDAivh4RX42ImyPi0Lpl768uvX84Is6ua294WX71Iel9Vfum6gPTfuX89Yh4KCJ+GBETde0LIuL/ImJH9Vhft+wXIuKBKs/HIiKq9sMj4q6IeKR6PqxfOefKWi0bmfe0Qe7JiNhZ916e223uYRqFDLNFxJPVvrcjIrZXbQ33u6j5WJX/qxHxpgFnuzYidkfEg3VtHWeLiFVV/0ciYtWQcha5jwKQmX1/AGcBr6qmrwSurKZPBL4CvAZYCDxG7QPQg6rp1wGvrvqcWK1zI3BhNb0eeHcfcy6idnHR3cBEXfsC4MEm6/w7cCoQwGeBt1btfwOsrabXTv+bh5B1pN7TBrkngT9u0N5x7mE9RiFDk1xPAkfMamu43wHnVvtnVPvrfQPOdjrwpvr/N51mAw4HHq+eD6umDxtCzuL20enHQI7AM/Nzmbmnmv0itTHiULvU/obMfCkznwAepXZJfsPL8quj26XAv1TrbwSW9zHnVGY+3G7/iJgP/GRmfjFrP+F/rMtzfpWv7zlhzqwj9Z52oKPcQ842Chna1Wy/Ox/4x6z5InBotf8ORGZuA77dY7azgbsy89uZ+RxwF3DOEHI2M8r7KDCcc+C/Te23LcAxwDfrlj1VtTVrfy3wfN0vg+n2YVgYEf8REfdExGlV2zFVhtk5AY7MzF3V9DPAkUPKWcJ7emn1p/K1daeWOs09TKOQoZEEPhcR90ftFhXQfL8bhX9Dp9n2Z+bS9lGgh3HgEfFvwFENFl2embdWfS4H9gDXdbudXrWTs4FdwHhm/ndE/AJwS0T8fLvbzMyMiI7HZ3aZdb+bKzdwNXAFteJzBXAVtV/q6twvZ+bOiPhp4K6I+Hr9wm73u2EY5WwUvI/2ciHPr8y1PCLeBZwHLKtON8Dcl983av9van9evao6Yuz4cv1WOZus8xLwUjV9f0Q8Bvxcte1j67rW53k2IuZn5q7qz8HdXWy346zsh/d0tnZzR8QngNu7zD1MI3mbiMzcWT3vjoibqf0p32y/G4V/Q6fZdgJLZrXfPeiQmfns9HRB+ygwuFEo5wB/AvxaZv5v3aLbgAsj4jURsRB4PbUPBRtell8V/q3A26r1VwEDPxKNiLGo3e+ciHhdlfPx6s/B70bEqdW55HfW5bmtyje0nHXbHdn3dNZ51wuA6U//O8o9qHxNjEKGGSLixyPikOlpagMFHqT5fncb8M5qxMepwHfqTmcMS6fZ7gTOiojDqtMYZ1VtA1XoPloziE9GqZ3s/yawo3qsr1t2ObVPcB+mGsGRL38y/Z/Vssvr2l9H7U17FPhn4DV9zHkBtfNXLwHPAndW7SuAh6rsXwZ+tW6dCWo/4MeAv+Plq1lfC2wGHgH+DTi8z+9pw6yj9p42yP0p4AHgq9R28vnd5h7mYxQyzMrzOmqjHb5S7ZuXz7XfURvhsa7K/wB1I5cGlO96aqcev1/tpxd3k43aqYtHq8dvDSlnkftoZnopvSSVyisxJalQFnBJKpQFXJIKZQGXpEJZwCWpUBZwSSqUBVySCvX/YYiXY6SZh+0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_prerunsims = True\n",
    "n_sims = 2000\n",
    "\n",
    "if new_prerunsims == True:\n",
    "    \n",
    "    pathlib.Path('{}'.format(pathtopydelfiprerunsims)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # drawing thetas\n",
    "\n",
    "    print('APPLYING UNIFORM PRIOR')\n",
    "    prior_distr = priors.Uniform(lower, upper)     \n",
    "\n",
    "    draws = np.zeros((n_sims,2))\n",
    "    for i in range (n_sims):\n",
    "        draws[i]=prior_distr.draw()\n",
    "    \n",
    "    np.savetxt('{}'.format(pathtopydelfiprerunsims)+'/prerun_thetas{}.txt'.format(ref_filename),draws) \n",
    "\n",
    "    #sims\n",
    "\n",
    "    prerun_sims = np.zeros((n_sims,(n_obs)*n_sources))\n",
    "    for i in range (n_sims):\n",
    "        theta=np.array([draws[i][0],draws[i][1]])\n",
    "        sim = data_generation.data_simulator(theta = theta)\n",
    "        prerun_sims[i] = sim  \n",
    "    \n",
    "    np.savetxt('{}'.format(pathtopydelfiprerunsims)+'/prerun_sims{}.txt'.format(ref_filename),prerun_sims)\n",
    "\n",
    "    print(prerun_sims.shape)\n",
    "    print(draws.shape)\n",
    "    \n",
    "if checking_data == True:\n",
    "    prerun_data = np.loadtxt('{}'.format(pathtopydelfiprerunsims)+'/prerun_sims{}.txt'.format(ref_filename))\n",
    "    check_data(prerun_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/data1/fgerardi/code_github/example_selection/modules\n"
     ]
    }
   ],
   "source": [
    "%cd ./modules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 18:04:18.778613: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "2021-04-06 18:04:18.803389: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "____PROCESS0 for [l1,bs,lr]=[array([0.0001]), array([100]), array([0.0001])]have been set____\n",
      "2021-04-06 18:04:19.402807: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "2021-04-06 18:04:19.402843: W external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "Using TensorFlow backend.\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Figure(640x480)\n",
      "(5000, 300)\n",
      "(2000, 300)\n",
      "Train on 5000 samples, validate on 2000 samples\n",
      "2021-04-06 18:04:56.777154: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "2021-04-06 18:04:56.777194: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "Epoch 1/10000\n",
      "5000/5000 [==============================] - 0s 59us/sample - loss: 6.6987 - mean_squared_error: 6.2736 - val_loss: 1.5766 - val_mean_squared_error: 1.1518\n",
      "Epoch 2/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 1.4548 - mean_squared_error: 1.0302 - val_loss: 1.2848 - val_mean_squared_error: 0.8603\n",
      "Epoch 3/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 1.1953 - mean_squared_error: 0.7711 - val_loss: 1.1167 - val_mean_squared_error: 0.6926\n",
      "Epoch 4/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 1.0478 - mean_squared_error: 0.6239 - val_loss: 1.0094 - val_mean_squared_error: 0.5857\n",
      "Epoch 5/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.9497 - mean_squared_error: 0.5262 - val_loss: 0.9355 - val_mean_squared_error: 0.5122\n",
      "Epoch 6/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.8747 - mean_squared_error: 0.4516 - val_loss: 0.8787 - val_mean_squared_error: 0.4558\n",
      "Epoch 7/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.8180 - mean_squared_error: 0.3953 - val_loss: 0.8342 - val_mean_squared_error: 0.4116\n",
      "Epoch 8/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.7729 - mean_squared_error: 0.3506 - val_loss: 0.7960 - val_mean_squared_error: 0.3739\n",
      "Epoch 9/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.7367 - mean_squared_error: 0.3147 - val_loss: 0.7658 - val_mean_squared_error: 0.3440\n",
      "Epoch 10/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.7071 - mean_squared_error: 0.2856 - val_loss: 0.7413 - val_mean_squared_error: 0.3199\n",
      "Epoch 11/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.6817 - mean_squared_error: 0.2605 - val_loss: 0.7211 - val_mean_squared_error: 0.3001\n",
      "Epoch 12/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.6608 - mean_squared_error: 0.2400 - val_loss: 0.7033 - val_mean_squared_error: 0.2827\n",
      "Epoch 13/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.6426 - mean_squared_error: 0.2222 - val_loss: 0.6888 - val_mean_squared_error: 0.2686\n",
      "Epoch 14/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.6264 - mean_squared_error: 0.2065 - val_loss: 0.6748 - val_mean_squared_error: 0.2550\n",
      "Epoch 15/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.6130 - mean_squared_error: 0.1934 - val_loss: 0.6642 - val_mean_squared_error: 0.2448\n",
      "Epoch 16/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.6008 - mean_squared_error: 0.1816 - val_loss: 0.6541 - val_mean_squared_error: 0.2352\n",
      "Epoch 17/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.5904 - mean_squared_error: 0.1717 - val_loss: 0.6453 - val_mean_squared_error: 0.2267\n",
      "Epoch 18/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5805 - mean_squared_error: 0.1622 - val_loss: 0.6365 - val_mean_squared_error: 0.2183\n",
      "Epoch 19/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5717 - mean_squared_error: 0.1538 - val_loss: 0.6295 - val_mean_squared_error: 0.2118\n",
      "Epoch 20/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5637 - mean_squared_error: 0.1462 - val_loss: 0.6227 - val_mean_squared_error: 0.2054\n",
      "Epoch 21/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5564 - mean_squared_error: 0.1393 - val_loss: 0.6164 - val_mean_squared_error: 0.1995\n",
      "Epoch 22/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5497 - mean_squared_error: 0.1331 - val_loss: 0.6112 - val_mean_squared_error: 0.1948\n",
      "Epoch 23/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5435 - mean_squared_error: 0.1273 - val_loss: 0.6057 - val_mean_squared_error: 0.1898\n",
      "Epoch 24/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5380 - mean_squared_error: 0.1222 - val_loss: 0.6010 - val_mean_squared_error: 0.1855\n",
      "Epoch 25/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5329 - mean_squared_error: 0.1177 - val_loss: 0.5966 - val_mean_squared_error: 0.1815\n",
      "Epoch 26/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5272 - mean_squared_error: 0.1124 - val_loss: 0.5924 - val_mean_squared_error: 0.1778\n",
      "Epoch 27/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5226 - mean_squared_error: 0.1082 - val_loss: 0.5881 - val_mean_squared_error: 0.1740\n",
      "Epoch 28/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5178 - mean_squared_error: 0.1040 - val_loss: 0.5843 - val_mean_squared_error: 0.1707\n",
      "Epoch 29/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.5137 - mean_squared_error: 0.1003 - val_loss: 0.5811 - val_mean_squared_error: 0.1680\n",
      "Epoch 30/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5097 - mean_squared_error: 0.0968 - val_loss: 0.5777 - val_mean_squared_error: 0.1650\n",
      "Epoch 31/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.5057 - mean_squared_error: 0.0934 - val_loss: 0.5745 - val_mean_squared_error: 0.1624\n",
      "Epoch 32/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.5024 - mean_squared_error: 0.0905 - val_loss: 0.5715 - val_mean_squared_error: 0.1599\n",
      "Epoch 33/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4988 - mean_squared_error: 0.0875 - val_loss: 0.5684 - val_mean_squared_error: 0.1573\n",
      "Epoch 34/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4953 - mean_squared_error: 0.0844 - val_loss: 0.5656 - val_mean_squared_error: 0.1551\n",
      "Epoch 35/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4920 - mean_squared_error: 0.0816 - val_loss: 0.5628 - val_mean_squared_error: 0.1527\n",
      "Epoch 36/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4889 - mean_squared_error: 0.0792 - val_loss: 0.5605 - val_mean_squared_error: 0.1510\n",
      "Epoch 37/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4861 - mean_squared_error: 0.0769 - val_loss: 0.5579 - val_mean_squared_error: 0.1489\n",
      "Epoch 38/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4829 - mean_squared_error: 0.0742 - val_loss: 0.5554 - val_mean_squared_error: 0.1470\n",
      "Epoch 39/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4802 - mean_squared_error: 0.0721 - val_loss: 0.5535 - val_mean_squared_error: 0.1456\n",
      "Epoch 40/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4774 - mean_squared_error: 0.0698 - val_loss: 0.5510 - val_mean_squared_error: 0.1437\n",
      "Epoch 41/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4749 - mean_squared_error: 0.0679 - val_loss: 0.5490 - val_mean_squared_error: 0.1423\n",
      "Epoch 42/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4727 - mean_squared_error: 0.0663 - val_loss: 0.5466 - val_mean_squared_error: 0.1405\n",
      "Epoch 43/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4700 - mean_squared_error: 0.0642 - val_loss: 0.5445 - val_mean_squared_error: 0.1390\n",
      "Epoch 44/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4675 - mean_squared_error: 0.0623 - val_loss: 0.5423 - val_mean_squared_error: 0.1374\n",
      "Epoch 45/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4650 - mean_squared_error: 0.0604 - val_loss: 0.5407 - val_mean_squared_error: 0.1364\n",
      "Epoch 46/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4631 - mean_squared_error: 0.0591 - val_loss: 0.5398 - val_mean_squared_error: 0.1361\n",
      "Epoch 47/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4612 - mean_squared_error: 0.0579 - val_loss: 0.5370 - val_mean_squared_error: 0.1340\n",
      "Epoch 48/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4586 - mean_squared_error: 0.0558 - val_loss: 0.5353 - val_mean_squared_error: 0.1329\n",
      "Epoch 49/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4567 - mean_squared_error: 0.0546 - val_loss: 0.5336 - val_mean_squared_error: 0.1318\n",
      "Epoch 50/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4544 - mean_squared_error: 0.0529 - val_loss: 0.5310 - val_mean_squared_error: 0.1299\n",
      "Epoch 51/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4522 - mean_squared_error: 0.0514 - val_loss: 0.5293 - val_mean_squared_error: 0.1289\n",
      "Epoch 52/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4501 - mean_squared_error: 0.0500 - val_loss: 0.5275 - val_mean_squared_error: 0.1278\n",
      "Epoch 53/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4483 - mean_squared_error: 0.0488 - val_loss: 0.5262 - val_mean_squared_error: 0.1272\n",
      "Epoch 54/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4463 - mean_squared_error: 0.0476 - val_loss: 0.5241 - val_mean_squared_error: 0.1257\n",
      "Epoch 55/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4444 - mean_squared_error: 0.0464 - val_loss: 0.5221 - val_mean_squared_error: 0.1244\n",
      "Epoch 56/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4425 - mean_squared_error: 0.0452 - val_loss: 0.5206 - val_mean_squared_error: 0.1236\n",
      "Epoch 57/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4407 - mean_squared_error: 0.0441 - val_loss: 0.5185 - val_mean_squared_error: 0.1222\n",
      "Epoch 58/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4389 - mean_squared_error: 0.0431 - val_loss: 0.5171 - val_mean_squared_error: 0.1216\n",
      "Epoch 59/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4373 - mean_squared_error: 0.0422 - val_loss: 0.5156 - val_mean_squared_error: 0.1208\n",
      "Epoch 60/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4354 - mean_squared_error: 0.0410 - val_loss: 0.5138 - val_mean_squared_error: 0.1198\n",
      "Epoch 61/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4335 - mean_squared_error: 0.0399 - val_loss: 0.5122 - val_mean_squared_error: 0.1190\n",
      "Epoch 62/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.4321 - mean_squared_error: 0.0393 - val_loss: 0.5107 - val_mean_squared_error: 0.1183\n",
      "Epoch 63/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4304 - mean_squared_error: 0.0383 - val_loss: 0.5090 - val_mean_squared_error: 0.1174\n",
      "Epoch 64/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4285 - mean_squared_error: 0.0373 - val_loss: 0.5073 - val_mean_squared_error: 0.1164\n",
      "Epoch 65/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4268 - mean_squared_error: 0.0363 - val_loss: 0.5061 - val_mean_squared_error: 0.1161\n",
      "Epoch 66/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4256 - mean_squared_error: 0.0360 - val_loss: 0.5040 - val_mean_squared_error: 0.1148\n",
      "Epoch 67/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4237 - mean_squared_error: 0.0348 - val_loss: 0.5026 - val_mean_squared_error: 0.1143\n",
      "Epoch 68/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4220 - mean_squared_error: 0.0341 - val_loss: 0.5009 - val_mean_squared_error: 0.1134\n",
      "Epoch 69/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4203 - mean_squared_error: 0.0332 - val_loss: 0.4995 - val_mean_squared_error: 0.1128\n",
      "Epoch 70/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4190 - mean_squared_error: 0.0327 - val_loss: 0.4981 - val_mean_squared_error: 0.1123\n",
      "Epoch 71/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4171 - mean_squared_error: 0.0318 - val_loss: 0.4961 - val_mean_squared_error: 0.1112\n",
      "Epoch 72/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4157 - mean_squared_error: 0.0312 - val_loss: 0.4950 - val_mean_squared_error: 0.1110\n",
      "Epoch 73/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4140 - mean_squared_error: 0.0304 - val_loss: 0.4933 - val_mean_squared_error: 0.1101\n",
      "Epoch 74/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4125 - mean_squared_error: 0.0299 - val_loss: 0.4919 - val_mean_squared_error: 0.1097\n",
      "Epoch 75/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4111 - mean_squared_error: 0.0294 - val_loss: 0.4906 - val_mean_squared_error: 0.1093\n",
      "Epoch 76/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4094 - mean_squared_error: 0.0286 - val_loss: 0.4885 - val_mean_squared_error: 0.1082\n",
      "Epoch 77/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4078 - mean_squared_error: 0.0279 - val_loss: 0.4871 - val_mean_squared_error: 0.1078\n",
      "Epoch 78/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4063 - mean_squared_error: 0.0274 - val_loss: 0.4854 - val_mean_squared_error: 0.1070\n",
      "Epoch 79/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4046 - mean_squared_error: 0.0267 - val_loss: 0.4836 - val_mean_squared_error: 0.1062\n",
      "Epoch 80/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4033 - mean_squared_error: 0.0263 - val_loss: 0.4822 - val_mean_squared_error: 0.1058\n",
      "Epoch 81/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.4017 - mean_squared_error: 0.0258 - val_loss: 0.4804 - val_mean_squared_error: 0.1050\n",
      "Epoch 82/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.4001 - mean_squared_error: 0.0252 - val_loss: 0.4791 - val_mean_squared_error: 0.1047\n",
      "Epoch 83/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3986 - mean_squared_error: 0.0247 - val_loss: 0.4775 - val_mean_squared_error: 0.1042\n",
      "Epoch 84/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3971 - mean_squared_error: 0.0243 - val_loss: 0.4754 - val_mean_squared_error: 0.1032\n",
      "Epoch 85/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3955 - mean_squared_error: 0.0238 - val_loss: 0.4737 - val_mean_squared_error: 0.1025\n",
      "Epoch 86/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3940 - mean_squared_error: 0.0233 - val_loss: 0.4726 - val_mean_squared_error: 0.1025\n",
      "Epoch 87/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3924 - mean_squared_error: 0.0228 - val_loss: 0.4709 - val_mean_squared_error: 0.1019\n",
      "Epoch 88/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3908 - mean_squared_error: 0.0223 - val_loss: 0.4690 - val_mean_squared_error: 0.1011\n",
      "Epoch 89/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3894 - mean_squared_error: 0.0220 - val_loss: 0.4676 - val_mean_squared_error: 0.1008\n",
      "Epoch 90/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3877 - mean_squared_error: 0.0215 - val_loss: 0.4660 - val_mean_squared_error: 0.1003\n",
      "Epoch 91/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3865 - mean_squared_error: 0.0214 - val_loss: 0.4648 - val_mean_squared_error: 0.1002\n",
      "Epoch 92/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3846 - mean_squared_error: 0.0207 - val_loss: 0.4630 - val_mean_squared_error: 0.0996\n",
      "Epoch 93/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3834 - mean_squared_error: 0.0206 - val_loss: 0.4609 - val_mean_squared_error: 0.0987\n",
      "Epoch 94/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3817 - mean_squared_error: 0.0201 - val_loss: 0.4594 - val_mean_squared_error: 0.0984\n",
      "Epoch 95/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3800 - mean_squared_error: 0.0196 - val_loss: 0.4573 - val_mean_squared_error: 0.0976\n",
      "Epoch 96/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3783 - mean_squared_error: 0.0191 - val_loss: 0.4558 - val_mean_squared_error: 0.0973\n",
      "Epoch 97/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3767 - mean_squared_error: 0.0188 - val_loss: 0.4539 - val_mean_squared_error: 0.0967\n",
      "Epoch 98/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3752 - mean_squared_error: 0.0185 - val_loss: 0.4522 - val_mean_squared_error: 0.0961\n",
      "Epoch 99/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3738 - mean_squared_error: 0.0183 - val_loss: 0.4507 - val_mean_squared_error: 0.0959\n",
      "Epoch 100/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3721 - mean_squared_error: 0.0180 - val_loss: 0.4495 - val_mean_squared_error: 0.0960\n",
      "Epoch 101/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3705 - mean_squared_error: 0.0176 - val_loss: 0.4472 - val_mean_squared_error: 0.0950\n",
      "Epoch 102/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3690 - mean_squared_error: 0.0174 - val_loss: 0.4449 - val_mean_squared_error: 0.0940\n",
      "Epoch 103/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3673 - mean_squared_error: 0.0170 - val_loss: 0.4437 - val_mean_squared_error: 0.0941\n",
      "Epoch 104/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3656 - mean_squared_error: 0.0167 - val_loss: 0.4420 - val_mean_squared_error: 0.0938\n",
      "Epoch 105/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3642 - mean_squared_error: 0.0166 - val_loss: 0.4397 - val_mean_squared_error: 0.0929\n",
      "Epoch 106/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3624 - mean_squared_error: 0.0162 - val_loss: 0.4378 - val_mean_squared_error: 0.0923\n",
      "Epoch 107/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3607 - mean_squared_error: 0.0158 - val_loss: 0.4362 - val_mean_squared_error: 0.0921\n",
      "Epoch 108/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3591 - mean_squared_error: 0.0157 - val_loss: 0.4342 - val_mean_squared_error: 0.0915\n",
      "Epoch 109/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3574 - mean_squared_error: 0.0154 - val_loss: 0.4322 - val_mean_squared_error: 0.0910\n",
      "Epoch 110/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.3557 - mean_squared_error: 0.0151 - val_loss: 0.4307 - val_mean_squared_error: 0.0909\n",
      "Epoch 111/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3541 - mean_squared_error: 0.0150 - val_loss: 0.4287 - val_mean_squared_error: 0.0903\n",
      "Epoch 112/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3525 - mean_squared_error: 0.0148 - val_loss: 0.4269 - val_mean_squared_error: 0.0899\n",
      "Epoch 113/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3509 - mean_squared_error: 0.0147 - val_loss: 0.4245 - val_mean_squared_error: 0.0890\n",
      "Epoch 114/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3491 - mean_squared_error: 0.0143 - val_loss: 0.4231 - val_mean_squared_error: 0.0891\n",
      "Epoch 115/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3474 - mean_squared_error: 0.0141 - val_loss: 0.4213 - val_mean_squared_error: 0.0888\n",
      "Epoch 116/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3458 - mean_squared_error: 0.0141 - val_loss: 0.4188 - val_mean_squared_error: 0.0878\n",
      "Epoch 117/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3439 - mean_squared_error: 0.0137 - val_loss: 0.4166 - val_mean_squared_error: 0.0871\n",
      "Epoch 118/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3421 - mean_squared_error: 0.0134 - val_loss: 0.4149 - val_mean_squared_error: 0.0870\n",
      "Epoch 119/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3405 - mean_squared_error: 0.0134 - val_loss: 0.4126 - val_mean_squared_error: 0.0863\n",
      "Epoch 120/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3388 - mean_squared_error: 0.0132 - val_loss: 0.4109 - val_mean_squared_error: 0.0861\n",
      "Epoch 121/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3372 - mean_squared_error: 0.0132 - val_loss: 0.4085 - val_mean_squared_error: 0.0853\n",
      "Epoch 122/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3351 - mean_squared_error: 0.0126 - val_loss: 0.4068 - val_mean_squared_error: 0.0852\n",
      "Epoch 123/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3333 - mean_squared_error: 0.0125 - val_loss: 0.4046 - val_mean_squared_error: 0.0846\n",
      "Epoch 124/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3315 - mean_squared_error: 0.0123 - val_loss: 0.4028 - val_mean_squared_error: 0.0843\n",
      "Epoch 125/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3300 - mean_squared_error: 0.0124 - val_loss: 0.4007 - val_mean_squared_error: 0.0839\n",
      "Epoch 126/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3280 - mean_squared_error: 0.0121 - val_loss: 0.3978 - val_mean_squared_error: 0.0827\n",
      "Epoch 127/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3263 - mean_squared_error: 0.0119 - val_loss: 0.3961 - val_mean_squared_error: 0.0826\n",
      "Epoch 128/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3244 - mean_squared_error: 0.0117 - val_loss: 0.3939 - val_mean_squared_error: 0.0821\n",
      "Epoch 129/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3225 - mean_squared_error: 0.0115 - val_loss: 0.3917 - val_mean_squared_error: 0.0815\n",
      "Epoch 130/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3209 - mean_squared_error: 0.0115 - val_loss: 0.3899 - val_mean_squared_error: 0.0814\n",
      "Epoch 131/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3192 - mean_squared_error: 0.0115 - val_loss: 0.3877 - val_mean_squared_error: 0.0809\n",
      "Epoch 132/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3171 - mean_squared_error: 0.0112 - val_loss: 0.3859 - val_mean_squared_error: 0.0808\n",
      "Epoch 133/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3154 - mean_squared_error: 0.0111 - val_loss: 0.3841 - val_mean_squared_error: 0.0808\n",
      "Epoch 134/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3135 - mean_squared_error: 0.0110 - val_loss: 0.3817 - val_mean_squared_error: 0.0801\n",
      "Epoch 135/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3121 - mean_squared_error: 0.0112 - val_loss: 0.3791 - val_mean_squared_error: 0.0792\n",
      "Epoch 136/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3101 - mean_squared_error: 0.0110 - val_loss: 0.3766 - val_mean_squared_error: 0.0784\n",
      "Epoch 137/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3079 - mean_squared_error: 0.0105 - val_loss: 0.3747 - val_mean_squared_error: 0.0782\n",
      "Epoch 138/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3060 - mean_squared_error: 0.0104 - val_loss: 0.3730 - val_mean_squared_error: 0.0782\n",
      "Epoch 139/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3043 - mean_squared_error: 0.0104 - val_loss: 0.3706 - val_mean_squared_error: 0.0776\n",
      "Epoch 140/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.3025 - mean_squared_error: 0.0104 - val_loss: 0.3679 - val_mean_squared_error: 0.0767\n",
      "Epoch 141/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.3007 - mean_squared_error: 0.0103 - val_loss: 0.3655 - val_mean_squared_error: 0.0761\n",
      "Epoch 142/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2987 - mean_squared_error: 0.0101 - val_loss: 0.3636 - val_mean_squared_error: 0.0759\n",
      "Epoch 143/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2967 - mean_squared_error: 0.0099 - val_loss: 0.3612 - val_mean_squared_error: 0.0753\n",
      "Epoch 144/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2949 - mean_squared_error: 0.0098 - val_loss: 0.3594 - val_mean_squared_error: 0.0753\n",
      "Epoch 145/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2930 - mean_squared_error: 0.0098 - val_loss: 0.3573 - val_mean_squared_error: 0.0750\n",
      "Epoch 146/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2912 - mean_squared_error: 0.0097 - val_loss: 0.3546 - val_mean_squared_error: 0.0741\n",
      "Epoch 147/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2895 - mean_squared_error: 0.0098 - val_loss: 0.3522 - val_mean_squared_error: 0.0734\n",
      "Epoch 148/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2875 - mean_squared_error: 0.0096 - val_loss: 0.3500 - val_mean_squared_error: 0.0731\n",
      "Epoch 149/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2855 - mean_squared_error: 0.0095 - val_loss: 0.3486 - val_mean_squared_error: 0.0734\n",
      "Epoch 150/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2838 - mean_squared_error: 0.0095 - val_loss: 0.3456 - val_mean_squared_error: 0.0723\n",
      "Epoch 151/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2818 - mean_squared_error: 0.0093 - val_loss: 0.3435 - val_mean_squared_error: 0.0720\n",
      "Epoch 152/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2799 - mean_squared_error: 0.0092 - val_loss: 0.3414 - val_mean_squared_error: 0.0717\n",
      "Epoch 153/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2781 - mean_squared_error: 0.0092 - val_loss: 0.3388 - val_mean_squared_error: 0.0709\n",
      "Epoch 154/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2762 - mean_squared_error: 0.0092 - val_loss: 0.3365 - val_mean_squared_error: 0.0704\n",
      "Epoch 155/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2745 - mean_squared_error: 0.0092 - val_loss: 0.3348 - val_mean_squared_error: 0.0705\n",
      "Epoch 156/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2724 - mean_squared_error: 0.0090 - val_loss: 0.3323 - val_mean_squared_error: 0.0698\n",
      "Epoch 157/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2708 - mean_squared_error: 0.0091 - val_loss: 0.3306 - val_mean_squared_error: 0.0699\n",
      "Epoch 158/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2688 - mean_squared_error: 0.0090 - val_loss: 0.3280 - val_mean_squared_error: 0.0691\n",
      "Epoch 159/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2669 - mean_squared_error: 0.0088 - val_loss: 0.3259 - val_mean_squared_error: 0.0688\n",
      "Epoch 160/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2652 - mean_squared_error: 0.0090 - val_loss: 0.3240 - val_mean_squared_error: 0.0688\n",
      "Epoch 161/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2632 - mean_squared_error: 0.0088 - val_loss: 0.3215 - val_mean_squared_error: 0.0680\n",
      "Epoch 162/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2614 - mean_squared_error: 0.0087 - val_loss: 0.3196 - val_mean_squared_error: 0.0680\n",
      "Epoch 163/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2596 - mean_squared_error: 0.0087 - val_loss: 0.3173 - val_mean_squared_error: 0.0674\n",
      "Epoch 164/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2580 - mean_squared_error: 0.0089 - val_loss: 0.3150 - val_mean_squared_error: 0.0669\n",
      "Epoch 165/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2558 - mean_squared_error: 0.0086 - val_loss: 0.3131 - val_mean_squared_error: 0.0668\n",
      "Epoch 166/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2542 - mean_squared_error: 0.0087 - val_loss: 0.3111 - val_mean_squared_error: 0.0666\n",
      "Epoch 167/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2522 - mean_squared_error: 0.0086 - val_loss: 0.3087 - val_mean_squared_error: 0.0660\n",
      "Epoch 168/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2505 - mean_squared_error: 0.0086 - val_loss: 0.3068 - val_mean_squared_error: 0.0658\n",
      "Epoch 169/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2488 - mean_squared_error: 0.0087 - val_loss: 0.3044 - val_mean_squared_error: 0.0652\n",
      "Epoch 170/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2468 - mean_squared_error: 0.0084 - val_loss: 0.3025 - val_mean_squared_error: 0.0650\n",
      "Epoch 171/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2450 - mean_squared_error: 0.0084 - val_loss: 0.3003 - val_mean_squared_error: 0.0646\n",
      "Epoch 172/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2432 - mean_squared_error: 0.0083 - val_loss: 0.2983 - val_mean_squared_error: 0.0644\n",
      "Epoch 173/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2415 - mean_squared_error: 0.0084 - val_loss: 0.2962 - val_mean_squared_error: 0.0640\n",
      "Epoch 174/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2399 - mean_squared_error: 0.0086 - val_loss: 0.2950 - val_mean_squared_error: 0.0645\n",
      "Epoch 175/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2382 - mean_squared_error: 0.0086 - val_loss: 0.2921 - val_mean_squared_error: 0.0634\n",
      "Epoch 176/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2362 - mean_squared_error: 0.0082 - val_loss: 0.2901 - val_mean_squared_error: 0.0630\n",
      "Epoch 177/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2345 - mean_squared_error: 0.0083 - val_loss: 0.2880 - val_mean_squared_error: 0.0626\n",
      "Epoch 178/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2328 - mean_squared_error: 0.0083 - val_loss: 0.2864 - val_mean_squared_error: 0.0627\n",
      "Epoch 179/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2311 - mean_squared_error: 0.0083 - val_loss: 0.2844 - val_mean_squared_error: 0.0625\n",
      "Epoch 180/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2294 - mean_squared_error: 0.0083 - val_loss: 0.2824 - val_mean_squared_error: 0.0621\n",
      "Epoch 181/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2278 - mean_squared_error: 0.0083 - val_loss: 0.2802 - val_mean_squared_error: 0.0616\n",
      "Epoch 182/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2260 - mean_squared_error: 0.0081 - val_loss: 0.2784 - val_mean_squared_error: 0.0614\n",
      "Epoch 183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2245 - mean_squared_error: 0.0083 - val_loss: 0.2765 - val_mean_squared_error: 0.0612\n",
      "Epoch 184/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2227 - mean_squared_error: 0.0082 - val_loss: 0.2745 - val_mean_squared_error: 0.0608\n",
      "Epoch 185/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2209 - mean_squared_error: 0.0080 - val_loss: 0.2730 - val_mean_squared_error: 0.0609\n",
      "Epoch 186/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2192 - mean_squared_error: 0.0080 - val_loss: 0.2709 - val_mean_squared_error: 0.0604\n",
      "Epoch 187/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2179 - mean_squared_error: 0.0082 - val_loss: 0.2689 - val_mean_squared_error: 0.0600\n",
      "Epoch 188/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2161 - mean_squared_error: 0.0081 - val_loss: 0.2678 - val_mean_squared_error: 0.0606\n",
      "Epoch 189/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2146 - mean_squared_error: 0.0081 - val_loss: 0.2651 - val_mean_squared_error: 0.0594\n",
      "Epoch 190/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2129 - mean_squared_error: 0.0080 - val_loss: 0.2632 - val_mean_squared_error: 0.0591\n",
      "Epoch 191/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2116 - mean_squared_error: 0.0082 - val_loss: 0.2619 - val_mean_squared_error: 0.0594\n",
      "Epoch 192/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2099 - mean_squared_error: 0.0081 - val_loss: 0.2599 - val_mean_squared_error: 0.0589\n",
      "Epoch 193/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2081 - mean_squared_error: 0.0078 - val_loss: 0.2578 - val_mean_squared_error: 0.0583\n",
      "Epoch 194/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2067 - mean_squared_error: 0.0080 - val_loss: 0.2565 - val_mean_squared_error: 0.0585\n",
      "Epoch 195/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.2052 - mean_squared_error: 0.0080 - val_loss: 0.2547 - val_mean_squared_error: 0.0583\n",
      "Epoch 196/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2036 - mean_squared_error: 0.0079 - val_loss: 0.2526 - val_mean_squared_error: 0.0577\n",
      "Epoch 197/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2020 - mean_squared_error: 0.0078 - val_loss: 0.2512 - val_mean_squared_error: 0.0578\n",
      "Epoch 198/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.2007 - mean_squared_error: 0.0080 - val_loss: 0.2498 - val_mean_squared_error: 0.0579\n",
      "Epoch 199/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1992 - mean_squared_error: 0.0079 - val_loss: 0.2482 - val_mean_squared_error: 0.0577\n",
      "Epoch 200/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1976 - mean_squared_error: 0.0078 - val_loss: 0.2471 - val_mean_squared_error: 0.0581\n",
      "Epoch 201/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1963 - mean_squared_error: 0.0079 - val_loss: 0.2445 - val_mean_squared_error: 0.0569\n",
      "Epoch 202/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1948 - mean_squared_error: 0.0079 - val_loss: 0.2436 - val_mean_squared_error: 0.0575\n",
      "Epoch 203/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1935 - mean_squared_error: 0.0080 - val_loss: 0.2413 - val_mean_squared_error: 0.0566\n",
      "Epoch 204/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1919 - mean_squared_error: 0.0078 - val_loss: 0.2399 - val_mean_squared_error: 0.0566\n",
      "Epoch 205/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1904 - mean_squared_error: 0.0077 - val_loss: 0.2382 - val_mean_squared_error: 0.0562\n",
      "Epoch 206/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1891 - mean_squared_error: 0.0078 - val_loss: 0.2370 - val_mean_squared_error: 0.0564\n",
      "Epoch 207/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1881 - mean_squared_error: 0.0082 - val_loss: 0.2357 - val_mean_squared_error: 0.0565\n",
      "Epoch 208/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1864 - mean_squared_error: 0.0079 - val_loss: 0.2337 - val_mean_squared_error: 0.0558\n",
      "Epoch 209/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1849 - mean_squared_error: 0.0077 - val_loss: 0.2323 - val_mean_squared_error: 0.0558\n",
      "Epoch 210/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1835 - mean_squared_error: 0.0076 - val_loss: 0.2309 - val_mean_squared_error: 0.0556\n",
      "Epoch 211/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1822 - mean_squared_error: 0.0077 - val_loss: 0.2294 - val_mean_squared_error: 0.0555\n",
      "Epoch 212/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1811 - mean_squared_error: 0.0078 - val_loss: 0.2278 - val_mean_squared_error: 0.0552\n",
      "Epoch 213/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1797 - mean_squared_error: 0.0077 - val_loss: 0.2266 - val_mean_squared_error: 0.0553\n",
      "Epoch 214/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1784 - mean_squared_error: 0.0077 - val_loss: 0.2257 - val_mean_squared_error: 0.0557\n",
      "Epoch 215/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1770 - mean_squared_error: 0.0076 - val_loss: 0.2237 - val_mean_squared_error: 0.0549\n",
      "Epoch 216/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1758 - mean_squared_error: 0.0076 - val_loss: 0.2234 - val_mean_squared_error: 0.0559\n",
      "Epoch 217/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1746 - mean_squared_error: 0.0076 - val_loss: 0.2213 - val_mean_squared_error: 0.0550\n",
      "Epoch 218/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1731 - mean_squared_error: 0.0074 - val_loss: 0.2201 - val_mean_squared_error: 0.0550\n",
      "Epoch 219/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1721 - mean_squared_error: 0.0076 - val_loss: 0.2186 - val_mean_squared_error: 0.0547\n",
      "Epoch 220/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1708 - mean_squared_error: 0.0075 - val_loss: 0.2172 - val_mean_squared_error: 0.0545\n",
      "Epoch 221/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1694 - mean_squared_error: 0.0073 - val_loss: 0.2157 - val_mean_squared_error: 0.0543\n",
      "Epoch 222/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1682 - mean_squared_error: 0.0073 - val_loss: 0.2143 - val_mean_squared_error: 0.0540\n",
      "Epoch 223/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1671 - mean_squared_error: 0.0074 - val_loss: 0.2135 - val_mean_squared_error: 0.0544\n",
      "Epoch 224/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1659 - mean_squared_error: 0.0073 - val_loss: 0.2119 - val_mean_squared_error: 0.0540\n",
      "Epoch 225/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1650 - mean_squared_error: 0.0076 - val_loss: 0.2107 - val_mean_squared_error: 0.0539\n",
      "Epoch 226/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1638 - mean_squared_error: 0.0075 - val_loss: 0.2108 - val_mean_squared_error: 0.0551\n",
      "Epoch 227/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1625 - mean_squared_error: 0.0074 - val_loss: 0.2085 - val_mean_squared_error: 0.0540\n",
      "Epoch 228/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1615 - mean_squared_error: 0.0075 - val_loss: 0.2074 - val_mean_squared_error: 0.0540\n",
      "Epoch 229/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1605 - mean_squared_error: 0.0075 - val_loss: 0.2063 - val_mean_squared_error: 0.0539\n",
      "Epoch 230/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1592 - mean_squared_error: 0.0073 - val_loss: 0.2056 - val_mean_squared_error: 0.0543\n",
      "Epoch 231/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1582 - mean_squared_error: 0.0074 - val_loss: 0.2046 - val_mean_squared_error: 0.0544\n",
      "Epoch 232/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1571 - mean_squared_error: 0.0074 - val_loss: 0.2026 - val_mean_squared_error: 0.0535\n",
      "Epoch 233/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1558 - mean_squared_error: 0.0072 - val_loss: 0.2016 - val_mean_squared_error: 0.0535\n",
      "Epoch 234/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1549 - mean_squared_error: 0.0073 - val_loss: 0.2005 - val_mean_squared_error: 0.0534\n",
      "Epoch 235/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1537 - mean_squared_error: 0.0071 - val_loss: 0.1997 - val_mean_squared_error: 0.0536\n",
      "Epoch 236/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1527 - mean_squared_error: 0.0071 - val_loss: 0.1985 - val_mean_squared_error: 0.0535\n",
      "Epoch 237/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1520 - mean_squared_error: 0.0074 - val_loss: 0.1978 - val_mean_squared_error: 0.0537\n",
      "Epoch 238/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1512 - mean_squared_error: 0.0076 - val_loss: 0.1964 - val_mean_squared_error: 0.0533\n",
      "Epoch 239/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1499 - mean_squared_error: 0.0073 - val_loss: 0.1953 - val_mean_squared_error: 0.0532\n",
      "Epoch 240/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1488 - mean_squared_error: 0.0072 - val_loss: 0.1947 - val_mean_squared_error: 0.0535\n",
      "Epoch 241/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1478 - mean_squared_error: 0.0071 - val_loss: 0.1939 - val_mean_squared_error: 0.0537\n",
      "Epoch 242/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1469 - mean_squared_error: 0.0071 - val_loss: 0.1923 - val_mean_squared_error: 0.0530\n",
      "Epoch 243/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1459 - mean_squared_error: 0.0070 - val_loss: 0.1918 - val_mean_squared_error: 0.0534\n",
      "Epoch 244/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1457 - mean_squared_error: 0.0077 - val_loss: 0.1907 - val_mean_squared_error: 0.0532\n",
      "Epoch 245/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1440 - mean_squared_error: 0.0070 - val_loss: 0.1893 - val_mean_squared_error: 0.0528\n",
      "Epoch 246/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1433 - mean_squared_error: 0.0072 - val_loss: 0.1883 - val_mean_squared_error: 0.0526\n",
      "Epoch 247/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1421 - mean_squared_error: 0.0069 - val_loss: 0.1874 - val_mean_squared_error: 0.0526\n",
      "Epoch 248/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1414 - mean_squared_error: 0.0070 - val_loss: 0.1864 - val_mean_squared_error: 0.0525\n",
      "Epoch 249/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1403 - mean_squared_error: 0.0068 - val_loss: 0.1857 - val_mean_squared_error: 0.0526\n",
      "Epoch 250/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1396 - mean_squared_error: 0.0069 - val_loss: 0.1850 - val_mean_squared_error: 0.0528\n",
      "Epoch 251/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1389 - mean_squared_error: 0.0071 - val_loss: 0.1845 - val_mean_squared_error: 0.0532\n",
      "Epoch 252/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1379 - mean_squared_error: 0.0069 - val_loss: 0.1832 - val_mean_squared_error: 0.0527\n",
      "Epoch 253/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1369 - mean_squared_error: 0.0068 - val_loss: 0.1822 - val_mean_squared_error: 0.0525\n",
      "Epoch 254/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1361 - mean_squared_error: 0.0069 - val_loss: 0.1822 - val_mean_squared_error: 0.0533\n",
      "Epoch 255/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1354 - mean_squared_error: 0.0070 - val_loss: 0.1808 - val_mean_squared_error: 0.0528\n",
      "Epoch 256/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1346 - mean_squared_error: 0.0069 - val_loss: 0.1795 - val_mean_squared_error: 0.0523\n",
      "Epoch 257/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1340 - mean_squared_error: 0.0071 - val_loss: 0.1791 - val_mean_squared_error: 0.0526\n",
      "Epoch 258/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1332 - mean_squared_error: 0.0071 - val_loss: 0.1805 - val_mean_squared_error: 0.0549\n",
      "Epoch 259/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1321 - mean_squared_error: 0.0068 - val_loss: 0.1787 - val_mean_squared_error: 0.0538\n",
      "Epoch 260/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1315 - mean_squared_error: 0.0070 - val_loss: 0.1768 - val_mean_squared_error: 0.0527\n",
      "Epoch 261/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1305 - mean_squared_error: 0.0068 - val_loss: 0.1754 - val_mean_squared_error: 0.0521\n",
      "Epoch 262/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1297 - mean_squared_error: 0.0067 - val_loss: 0.1749 - val_mean_squared_error: 0.0523\n",
      "Epoch 263/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1290 - mean_squared_error: 0.0067 - val_loss: 0.1747 - val_mean_squared_error: 0.0528\n",
      "Epoch 264/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1282 - mean_squared_error: 0.0066 - val_loss: 0.1734 - val_mean_squared_error: 0.0523\n",
      "Epoch 265/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1277 - mean_squared_error: 0.0069 - val_loss: 0.1728 - val_mean_squared_error: 0.0524\n",
      "Epoch 266/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1270 - mean_squared_error: 0.0070 - val_loss: 0.1738 - val_mean_squared_error: 0.0541\n",
      "Epoch 267/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1266 - mean_squared_error: 0.0072 - val_loss: 0.1710 - val_mean_squared_error: 0.0520\n",
      "Epoch 268/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1252 - mean_squared_error: 0.0066 - val_loss: 0.1716 - val_mean_squared_error: 0.0533\n",
      "Epoch 269/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1249 - mean_squared_error: 0.0070 - val_loss: 0.1702 - val_mean_squared_error: 0.0526\n",
      "Epoch 270/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1238 - mean_squared_error: 0.0065 - val_loss: 0.1691 - val_mean_squared_error: 0.0522\n",
      "Epoch 271/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1230 - mean_squared_error: 0.0064 - val_loss: 0.1683 - val_mean_squared_error: 0.0521\n",
      "Epoch 272/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1224 - mean_squared_error: 0.0065 - val_loss: 0.1676 - val_mean_squared_error: 0.0521\n",
      "Epoch 273/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1217 - mean_squared_error: 0.0065 - val_loss: 0.1672 - val_mean_squared_error: 0.0523\n",
      "Epoch 274/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1212 - mean_squared_error: 0.0066 - val_loss: 0.1664 - val_mean_squared_error: 0.0521\n",
      "Epoch 275/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1204 - mean_squared_error: 0.0065 - val_loss: 0.1662 - val_mean_squared_error: 0.0526\n",
      "Epoch 276/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1198 - mean_squared_error: 0.0065 - val_loss: 0.1650 - val_mean_squared_error: 0.0520\n",
      "Epoch 277/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1190 - mean_squared_error: 0.0064 - val_loss: 0.1646 - val_mean_squared_error: 0.0523\n",
      "Epoch 278/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1183 - mean_squared_error: 0.0062 - val_loss: 0.1639 - val_mean_squared_error: 0.0522\n",
      "Epoch 279/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1182 - mean_squared_error: 0.0068 - val_loss: 0.1641 - val_mean_squared_error: 0.0530\n",
      "Epoch 280/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1172 - mean_squared_error: 0.0064 - val_loss: 0.1625 - val_mean_squared_error: 0.0520\n",
      "Epoch 281/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1167 - mean_squared_error: 0.0065 - val_loss: 0.1631 - val_mean_squared_error: 0.0532\n",
      "Epoch 282/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1161 - mean_squared_error: 0.0065 - val_loss: 0.1616 - val_mean_squared_error: 0.0524\n",
      "Epoch 283/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1151 - mean_squared_error: 0.0061 - val_loss: 0.1613 - val_mean_squared_error: 0.0527\n",
      "Epoch 284/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1147 - mean_squared_error: 0.0063 - val_loss: 0.1602 - val_mean_squared_error: 0.0522\n",
      "Epoch 285/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1141 - mean_squared_error: 0.0063 - val_loss: 0.1598 - val_mean_squared_error: 0.0523\n",
      "Epoch 286/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1136 - mean_squared_error: 0.0064 - val_loss: 0.1594 - val_mean_squared_error: 0.0525\n",
      "Epoch 287/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1127 - mean_squared_error: 0.0061 - val_loss: 0.1585 - val_mean_squared_error: 0.0522\n",
      "Epoch 288/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1121 - mean_squared_error: 0.0061 - val_loss: 0.1583 - val_mean_squared_error: 0.0526\n",
      "Epoch 289/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1117 - mean_squared_error: 0.0062 - val_loss: 0.1578 - val_mean_squared_error: 0.0527\n",
      "Epoch 290/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1109 - mean_squared_error: 0.0060 - val_loss: 0.1570 - val_mean_squared_error: 0.0524\n",
      "Epoch 291/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1106 - mean_squared_error: 0.0063 - val_loss: 0.1566 - val_mean_squared_error: 0.0526\n",
      "Epoch 292/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1099 - mean_squared_error: 0.0061 - val_loss: 0.1566 - val_mean_squared_error: 0.0531\n",
      "Epoch 293/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1094 - mean_squared_error: 0.0061 - val_loss: 0.1557 - val_mean_squared_error: 0.0528\n",
      "Epoch 294/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1087 - mean_squared_error: 0.0060 - val_loss: 0.1552 - val_mean_squared_error: 0.0528\n",
      "Epoch 295/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1080 - mean_squared_error: 0.0059 - val_loss: 0.1544 - val_mean_squared_error: 0.0526\n",
      "Epoch 296/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1080 - mean_squared_error: 0.0063 - val_loss: 0.1576 - val_mean_squared_error: 0.0562\n",
      "Epoch 297/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1077 - mean_squared_error: 0.0066 - val_loss: 0.1535 - val_mean_squared_error: 0.0526\n",
      "Epoch 298/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.1064 - mean_squared_error: 0.0059 - val_loss: 0.1531 - val_mean_squared_error: 0.0528\n",
      "Epoch 299/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1060 - mean_squared_error: 0.0059 - val_loss: 0.1526 - val_mean_squared_error: 0.0529\n",
      "Epoch 300/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1054 - mean_squared_error: 0.0058 - val_loss: 0.1522 - val_mean_squared_error: 0.0529\n",
      "Epoch 301/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1050 - mean_squared_error: 0.0060 - val_loss: 0.1518 - val_mean_squared_error: 0.0530\n",
      "Epoch 302/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1043 - mean_squared_error: 0.0057 - val_loss: 0.1510 - val_mean_squared_error: 0.0527\n",
      "Epoch 303/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1037 - mean_squared_error: 0.0057 - val_loss: 0.1510 - val_mean_squared_error: 0.0533\n",
      "Epoch 304/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1036 - mean_squared_error: 0.0060 - val_loss: 0.1505 - val_mean_squared_error: 0.0532\n",
      "Epoch 305/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1027 - mean_squared_error: 0.0057 - val_loss: 0.1498 - val_mean_squared_error: 0.0530\n",
      "Epoch 306/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1024 - mean_squared_error: 0.0059 - val_loss: 0.1493 - val_mean_squared_error: 0.0530\n",
      "Epoch 307/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1018 - mean_squared_error: 0.0058 - val_loss: 0.1494 - val_mean_squared_error: 0.0536\n",
      "Epoch 308/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1013 - mean_squared_error: 0.0057 - val_loss: 0.1483 - val_mean_squared_error: 0.0530\n",
      "Epoch 309/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.1007 - mean_squared_error: 0.0056 - val_loss: 0.1476 - val_mean_squared_error: 0.0528\n",
      "Epoch 310/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.1003 - mean_squared_error: 0.0057 - val_loss: 0.1473 - val_mean_squared_error: 0.0530\n",
      "Epoch 311/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0998 - mean_squared_error: 0.0057 - val_loss: 0.1469 - val_mean_squared_error: 0.0531\n",
      "Epoch 312/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0994 - mean_squared_error: 0.0058 - val_loss: 0.1474 - val_mean_squared_error: 0.0540\n",
      "Epoch 313/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0992 - mean_squared_error: 0.0060 - val_loss: 0.1460 - val_mean_squared_error: 0.0530\n",
      "Epoch 314/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0985 - mean_squared_error: 0.0057 - val_loss: 0.1467 - val_mean_squared_error: 0.0542\n",
      "Epoch 315/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0981 - mean_squared_error: 0.0058 - val_loss: 0.1455 - val_mean_squared_error: 0.0534\n",
      "Epoch 316/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0980 - mean_squared_error: 0.0061 - val_loss: 0.1449 - val_mean_squared_error: 0.0533\n",
      "Epoch 317/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.0971 - mean_squared_error: 0.0056 - val_loss: 0.1443 - val_mean_squared_error: 0.0530\n",
      "Epoch 318/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0964 - mean_squared_error: 0.0054 - val_loss: 0.1443 - val_mean_squared_error: 0.0535\n",
      "Epoch 319/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0961 - mean_squared_error: 0.0055 - val_loss: 0.1435 - val_mean_squared_error: 0.0531\n",
      "Epoch 320/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0955 - mean_squared_error: 0.0054 - val_loss: 0.1433 - val_mean_squared_error: 0.0534\n",
      "Epoch 321/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0953 - mean_squared_error: 0.0056 - val_loss: 0.1426 - val_mean_squared_error: 0.0531\n",
      "Epoch 322/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0947 - mean_squared_error: 0.0054 - val_loss: 0.1425 - val_mean_squared_error: 0.0534\n",
      "Epoch 323/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0943 - mean_squared_error: 0.0054 - val_loss: 0.1417 - val_mean_squared_error: 0.0531\n",
      "Epoch 324/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0941 - mean_squared_error: 0.0056 - val_loss: 0.1425 - val_mean_squared_error: 0.0542\n",
      "Epoch 325/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0936 - mean_squared_error: 0.0055 - val_loss: 0.1413 - val_mean_squared_error: 0.0534\n",
      "Epoch 326/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0929 - mean_squared_error: 0.0052 - val_loss: 0.1422 - val_mean_squared_error: 0.0547\n",
      "Epoch 327/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0926 - mean_squared_error: 0.0054 - val_loss: 0.1409 - val_mean_squared_error: 0.0538\n",
      "Epoch 328/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0923 - mean_squared_error: 0.0054 - val_loss: 0.1399 - val_mean_squared_error: 0.0533\n",
      "Epoch 329/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0919 - mean_squared_error: 0.0054 - val_loss: 0.1403 - val_mean_squared_error: 0.0540\n",
      "Epoch 330/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0914 - mean_squared_error: 0.0053 - val_loss: 0.1395 - val_mean_squared_error: 0.0537\n",
      "Epoch 331/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0913 - mean_squared_error: 0.0056 - val_loss: 0.1393 - val_mean_squared_error: 0.0538\n",
      "Epoch 332/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0906 - mean_squared_error: 0.0052 - val_loss: 0.1389 - val_mean_squared_error: 0.0538\n",
      "Epoch 333/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0903 - mean_squared_error: 0.0054 - val_loss: 0.1388 - val_mean_squared_error: 0.0541\n",
      "Epoch 334/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0898 - mean_squared_error: 0.0052 - val_loss: 0.1387 - val_mean_squared_error: 0.0543\n",
      "Epoch 335/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0896 - mean_squared_error: 0.0054 - val_loss: 0.1385 - val_mean_squared_error: 0.0545\n",
      "Epoch 336/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0892 - mean_squared_error: 0.0053 - val_loss: 0.1379 - val_mean_squared_error: 0.0543\n",
      "Epoch 337/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0891 - mean_squared_error: 0.0057 - val_loss: 0.1371 - val_mean_squared_error: 0.0538\n",
      "Epoch 338/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0884 - mean_squared_error: 0.0052 - val_loss: 0.1365 - val_mean_squared_error: 0.0536\n",
      "Epoch 339/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0880 - mean_squared_error: 0.0052 - val_loss: 0.1370 - val_mean_squared_error: 0.0545\n",
      "Epoch 340/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0877 - mean_squared_error: 0.0053 - val_loss: 0.1361 - val_mean_squared_error: 0.0539\n",
      "Epoch 341/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0870 - mean_squared_error: 0.0050 - val_loss: 0.1361 - val_mean_squared_error: 0.0542\n",
      "Epoch 342/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0869 - mean_squared_error: 0.0052 - val_loss: 0.1362 - val_mean_squared_error: 0.0547\n",
      "Epoch 343/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0863 - mean_squared_error: 0.0050 - val_loss: 0.1362 - val_mean_squared_error: 0.0551\n",
      "Epoch 344/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0860 - mean_squared_error: 0.0051 - val_loss: 0.1350 - val_mean_squared_error: 0.0542\n",
      "Epoch 345/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0857 - mean_squared_error: 0.0050 - val_loss: 0.1346 - val_mean_squared_error: 0.0541\n",
      "Epoch 346/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0854 - mean_squared_error: 0.0051 - val_loss: 0.1341 - val_mean_squared_error: 0.0540\n",
      "Epoch 347/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0850 - mean_squared_error: 0.0050 - val_loss: 0.1341 - val_mean_squared_error: 0.0544\n",
      "Epoch 348/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0845 - mean_squared_error: 0.0049 - val_loss: 0.1338 - val_mean_squared_error: 0.0544\n",
      "Epoch 349/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0841 - mean_squared_error: 0.0049 - val_loss: 0.1331 - val_mean_squared_error: 0.0540\n",
      "Epoch 350/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0837 - mean_squared_error: 0.0047 - val_loss: 0.1328 - val_mean_squared_error: 0.0540\n",
      "Epoch 351/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0834 - mean_squared_error: 0.0048 - val_loss: 0.1333 - val_mean_squared_error: 0.0548\n",
      "Epoch 352/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.0831 - mean_squared_error: 0.0048 - val_loss: 0.1326 - val_mean_squared_error: 0.0545\n",
      "Epoch 353/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0827 - mean_squared_error: 0.0047 - val_loss: 0.1325 - val_mean_squared_error: 0.0547\n",
      "Epoch 354/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0826 - mean_squared_error: 0.0050 - val_loss: 0.1325 - val_mean_squared_error: 0.0551\n",
      "Epoch 355/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0821 - mean_squared_error: 0.0048 - val_loss: 0.1321 - val_mean_squared_error: 0.0550\n",
      "Epoch 356/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0817 - mean_squared_error: 0.0048 - val_loss: 0.1311 - val_mean_squared_error: 0.0543\n",
      "Epoch 357/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0817 - mean_squared_error: 0.0050 - val_loss: 0.1313 - val_mean_squared_error: 0.0548\n",
      "Epoch 358/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0811 - mean_squared_error: 0.0048 - val_loss: 0.1308 - val_mean_squared_error: 0.0546\n",
      "Epoch 359/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0809 - mean_squared_error: 0.0049 - val_loss: 0.1312 - val_mean_squared_error: 0.0553\n",
      "Epoch 360/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0805 - mean_squared_error: 0.0048 - val_loss: 0.1308 - val_mean_squared_error: 0.0552\n",
      "Epoch 361/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0804 - mean_squared_error: 0.0049 - val_loss: 0.1304 - val_mean_squared_error: 0.0552\n",
      "Epoch 362/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0799 - mean_squared_error: 0.0048 - val_loss: 0.1299 - val_mean_squared_error: 0.0550\n",
      "Epoch 363/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0794 - mean_squared_error: 0.0046 - val_loss: 0.1294 - val_mean_squared_error: 0.0548\n",
      "Epoch 364/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0791 - mean_squared_error: 0.0047 - val_loss: 0.1292 - val_mean_squared_error: 0.0549\n",
      "Epoch 365/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0788 - mean_squared_error: 0.0046 - val_loss: 0.1288 - val_mean_squared_error: 0.0548\n",
      "Epoch 366/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0785 - mean_squared_error: 0.0046 - val_loss: 0.1289 - val_mean_squared_error: 0.0552\n",
      "Epoch 367/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0783 - mean_squared_error: 0.0047 - val_loss: 0.1286 - val_mean_squared_error: 0.0552\n",
      "Epoch 368/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0781 - mean_squared_error: 0.0048 - val_loss: 0.1287 - val_mean_squared_error: 0.0555\n",
      "Epoch 369/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0778 - mean_squared_error: 0.0048 - val_loss: 0.1273 - val_mean_squared_error: 0.0544\n",
      "Epoch 370/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0773 - mean_squared_error: 0.0046 - val_loss: 0.1283 - val_mean_squared_error: 0.0558\n",
      "Epoch 371/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0771 - mean_squared_error: 0.0047 - val_loss: 0.1271 - val_mean_squared_error: 0.0548\n",
      "Epoch 372/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0769 - mean_squared_error: 0.0048 - val_loss: 0.1264 - val_mean_squared_error: 0.0544\n",
      "Epoch 373/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0770 - mean_squared_error: 0.0051 - val_loss: 0.1263 - val_mean_squared_error: 0.0546\n",
      "Epoch 374/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0761 - mean_squared_error: 0.0045 - val_loss: 0.1265 - val_mean_squared_error: 0.0551\n",
      "Epoch 375/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0762 - mean_squared_error: 0.0049 - val_loss: 0.1263 - val_mean_squared_error: 0.0551\n",
      "Epoch 376/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0755 - mean_squared_error: 0.0045 - val_loss: 0.1264 - val_mean_squared_error: 0.0555\n",
      "Epoch 377/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0755 - mean_squared_error: 0.0047 - val_loss: 0.1262 - val_mean_squared_error: 0.0555\n",
      "Epoch 378/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0752 - mean_squared_error: 0.0047 - val_loss: 0.1256 - val_mean_squared_error: 0.0552\n",
      "Epoch 379/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0748 - mean_squared_error: 0.0045 - val_loss: 0.1251 - val_mean_squared_error: 0.0550\n",
      "Epoch 380/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0746 - mean_squared_error: 0.0047 - val_loss: 0.1249 - val_mean_squared_error: 0.0551\n",
      "Epoch 381/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0741 - mean_squared_error: 0.0044 - val_loss: 0.1251 - val_mean_squared_error: 0.0555\n",
      "Epoch 382/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0736 - mean_squared_error: 0.0042 - val_loss: 0.1244 - val_mean_squared_error: 0.0551\n",
      "Epoch 383/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0736 - mean_squared_error: 0.0045 - val_loss: 0.1248 - val_mean_squared_error: 0.0557\n",
      "Epoch 384/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0734 - mean_squared_error: 0.0045 - val_loss: 0.1239 - val_mean_squared_error: 0.0551\n",
      "Epoch 385/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0730 - mean_squared_error: 0.0043 - val_loss: 0.1239 - val_mean_squared_error: 0.0554\n",
      "Epoch 386/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0729 - mean_squared_error: 0.0045 - val_loss: 0.1243 - val_mean_squared_error: 0.0560\n",
      "Epoch 387/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0725 - mean_squared_error: 0.0043 - val_loss: 0.1238 - val_mean_squared_error: 0.0558\n",
      "Epoch 388/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0722 - mean_squared_error: 0.0043 - val_loss: 0.1238 - val_mean_squared_error: 0.0560\n",
      "Epoch 389/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0721 - mean_squared_error: 0.0044 - val_loss: 0.1230 - val_mean_squared_error: 0.0555\n",
      "Epoch 390/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0719 - mean_squared_error: 0.0045 - val_loss: 0.1235 - val_mean_squared_error: 0.0562\n",
      "Epoch 391/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0716 - mean_squared_error: 0.0044 - val_loss: 0.1226 - val_mean_squared_error: 0.0555\n",
      "Epoch 392/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0713 - mean_squared_error: 0.0044 - val_loss: 0.1237 - val_mean_squared_error: 0.0569\n",
      "Epoch 393/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0711 - mean_squared_error: 0.0044 - val_loss: 0.1221 - val_mean_squared_error: 0.0555\n",
      "Epoch 394/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0706 - mean_squared_error: 0.0041 - val_loss: 0.1221 - val_mean_squared_error: 0.0558\n",
      "Epoch 395/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0708 - mean_squared_error: 0.0046 - val_loss: 0.1220 - val_mean_squared_error: 0.0558\n",
      "Epoch 396/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0704 - mean_squared_error: 0.0044 - val_loss: 0.1213 - val_mean_squared_error: 0.0555\n",
      "Epoch 397/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0703 - mean_squared_error: 0.0045 - val_loss: 0.1219 - val_mean_squared_error: 0.0562\n",
      "Epoch 398/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0697 - mean_squared_error: 0.0042 - val_loss: 0.1220 - val_mean_squared_error: 0.0566\n",
      "Epoch 399/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0695 - mean_squared_error: 0.0042 - val_loss: 0.1210 - val_mean_squared_error: 0.0559\n",
      "Epoch 400/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0694 - mean_squared_error: 0.0044 - val_loss: 0.1211 - val_mean_squared_error: 0.0562\n",
      "Epoch 401/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0693 - mean_squared_error: 0.0044 - val_loss: 0.1206 - val_mean_squared_error: 0.0559\n",
      "Epoch 402/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0686 - mean_squared_error: 0.0040 - val_loss: 0.1211 - val_mean_squared_error: 0.0567\n",
      "Epoch 403/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0684 - mean_squared_error: 0.0041 - val_loss: 0.1198 - val_mean_squared_error: 0.0556\n",
      "Epoch 404/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0683 - mean_squared_error: 0.0042 - val_loss: 0.1198 - val_mean_squared_error: 0.0557\n",
      "Epoch 405/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0685 - mean_squared_error: 0.0046 - val_loss: 0.1205 - val_mean_squared_error: 0.0567\n",
      "Epoch 406/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0684 - mean_squared_error: 0.0046 - val_loss: 0.1196 - val_mean_squared_error: 0.0559\n",
      "Epoch 407/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0675 - mean_squared_error: 0.0040 - val_loss: 0.1193 - val_mean_squared_error: 0.0559\n",
      "Epoch 408/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0672 - mean_squared_error: 0.0039 - val_loss: 0.1189 - val_mean_squared_error: 0.0557\n",
      "Epoch 409/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0669 - mean_squared_error: 0.0039 - val_loss: 0.1190 - val_mean_squared_error: 0.0561\n",
      "Epoch 410/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0669 - mean_squared_error: 0.0041 - val_loss: 0.1193 - val_mean_squared_error: 0.0565\n",
      "Epoch 411/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0669 - mean_squared_error: 0.0043 - val_loss: 0.1188 - val_mean_squared_error: 0.0562\n",
      "Epoch 412/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0665 - mean_squared_error: 0.0041 - val_loss: 0.1187 - val_mean_squared_error: 0.0563\n",
      "Epoch 413/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0666 - mean_squared_error: 0.0044 - val_loss: 0.1179 - val_mean_squared_error: 0.0558\n",
      "Epoch 414/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0662 - mean_squared_error: 0.0042 - val_loss: 0.1182 - val_mean_squared_error: 0.0562\n",
      "Epoch 415/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0659 - mean_squared_error: 0.0041 - val_loss: 0.1180 - val_mean_squared_error: 0.0563\n",
      "Epoch 416/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0654 - mean_squared_error: 0.0038 - val_loss: 0.1181 - val_mean_squared_error: 0.0566\n",
      "Epoch 417/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0653 - mean_squared_error: 0.0039 - val_loss: 0.1174 - val_mean_squared_error: 0.0561\n",
      "Epoch 418/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0652 - mean_squared_error: 0.0040 - val_loss: 0.1176 - val_mean_squared_error: 0.0565\n",
      "Epoch 419/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0649 - mean_squared_error: 0.0040 - val_loss: 0.1173 - val_mean_squared_error: 0.0564\n",
      "Epoch 420/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0650 - mean_squared_error: 0.0042 - val_loss: 0.1168 - val_mean_squared_error: 0.0562\n",
      "Epoch 421/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0647 - mean_squared_error: 0.0041 - val_loss: 0.1167 - val_mean_squared_error: 0.0562\n",
      "Epoch 422/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0643 - mean_squared_error: 0.0039 - val_loss: 0.1165 - val_mean_squared_error: 0.0562\n",
      "Epoch 423/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0638 - mean_squared_error: 0.0037 - val_loss: 0.1165 - val_mean_squared_error: 0.0564\n",
      "Epoch 424/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0639 - mean_squared_error: 0.0039 - val_loss: 0.1169 - val_mean_squared_error: 0.0570\n",
      "Epoch 425/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0637 - mean_squared_error: 0.0039 - val_loss: 0.1165 - val_mean_squared_error: 0.0568\n",
      "Epoch 426/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0634 - mean_squared_error: 0.0039 - val_loss: 0.1158 - val_mean_squared_error: 0.0564\n",
      "Epoch 427/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0634 - mean_squared_error: 0.0040 - val_loss: 0.1155 - val_mean_squared_error: 0.0562\n",
      "Epoch 428/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0635 - mean_squared_error: 0.0042 - val_loss: 0.1156 - val_mean_squared_error: 0.0565\n",
      "Epoch 429/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0627 - mean_squared_error: 0.0037 - val_loss: 0.1157 - val_mean_squared_error: 0.0569\n",
      "Epoch 430/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0625 - mean_squared_error: 0.0038 - val_loss: 0.1155 - val_mean_squared_error: 0.0568\n",
      "Epoch 431/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0624 - mean_squared_error: 0.0038 - val_loss: 0.1150 - val_mean_squared_error: 0.0566\n",
      "Epoch 432/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0623 - mean_squared_error: 0.0039 - val_loss: 0.1159 - val_mean_squared_error: 0.0576\n",
      "Epoch 433/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0629 - mean_squared_error: 0.0047 - val_loss: 0.1154 - val_mean_squared_error: 0.0572\n",
      "Epoch 434/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0623 - mean_squared_error: 0.0042 - val_loss: 0.1145 - val_mean_squared_error: 0.0565\n",
      "Epoch 435/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0615 - mean_squared_error: 0.0037 - val_loss: 0.1143 - val_mean_squared_error: 0.0566\n",
      "Epoch 436/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0614 - mean_squared_error: 0.0038 - val_loss: 0.1151 - val_mean_squared_error: 0.0575\n",
      "Epoch 437/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0615 - mean_squared_error: 0.0040 - val_loss: 0.1140 - val_mean_squared_error: 0.0566\n",
      "Epoch 438/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0611 - mean_squared_error: 0.0038 - val_loss: 0.1145 - val_mean_squared_error: 0.0573\n",
      "Epoch 439/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0610 - mean_squared_error: 0.0039 - val_loss: 0.1141 - val_mean_squared_error: 0.0570\n",
      "Epoch 440/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0609 - mean_squared_error: 0.0040 - val_loss: 0.1133 - val_mean_squared_error: 0.0565\n",
      "Epoch 441/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0608 - mean_squared_error: 0.0040 - val_loss: 0.1142 - val_mean_squared_error: 0.0576\n",
      "Epoch 442/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0608 - mean_squared_error: 0.0042 - val_loss: 0.1130 - val_mean_squared_error: 0.0565\n",
      "Epoch 443/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0601 - mean_squared_error: 0.0037 - val_loss: 0.1134 - val_mean_squared_error: 0.0571\n",
      "Epoch 444/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0602 - mean_squared_error: 0.0040 - val_loss: 0.1132 - val_mean_squared_error: 0.0570\n",
      "Epoch 445/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0602 - mean_squared_error: 0.0042 - val_loss: 0.1127 - val_mean_squared_error: 0.0567\n",
      "Epoch 446/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0599 - mean_squared_error: 0.0040 - val_loss: 0.1126 - val_mean_squared_error: 0.0568\n",
      "Epoch 447/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0596 - mean_squared_error: 0.0039 - val_loss: 0.1125 - val_mean_squared_error: 0.0569\n",
      "Epoch 448/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0599 - mean_squared_error: 0.0044 - val_loss: 0.1132 - val_mean_squared_error: 0.0577\n",
      "Epoch 449/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0591 - mean_squared_error: 0.0037 - val_loss: 0.1126 - val_mean_squared_error: 0.0573\n",
      "Epoch 450/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0590 - mean_squared_error: 0.0037 - val_loss: 0.1122 - val_mean_squared_error: 0.0571\n",
      "Epoch 451/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0586 - mean_squared_error: 0.0036 - val_loss: 0.1121 - val_mean_squared_error: 0.0571\n",
      "Epoch 452/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0586 - mean_squared_error: 0.0037 - val_loss: 0.1115 - val_mean_squared_error: 0.0567\n",
      "Epoch 453/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0584 - mean_squared_error: 0.0037 - val_loss: 0.1116 - val_mean_squared_error: 0.0570\n",
      "Epoch 454/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0581 - mean_squared_error: 0.0035 - val_loss: 0.1109 - val_mean_squared_error: 0.0565\n",
      "Epoch 455/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0581 - mean_squared_error: 0.0038 - val_loss: 0.1122 - val_mean_squared_error: 0.0579\n",
      "Epoch 456/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0581 - mean_squared_error: 0.0039 - val_loss: 0.1112 - val_mean_squared_error: 0.0571\n",
      "Epoch 457/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0577 - mean_squared_error: 0.0037 - val_loss: 0.1109 - val_mean_squared_error: 0.0569\n",
      "Epoch 458/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0575 - mean_squared_error: 0.0036 - val_loss: 0.1107 - val_mean_squared_error: 0.0569\n",
      "Epoch 459/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0575 - mean_squared_error: 0.0038 - val_loss: 0.1104 - val_mean_squared_error: 0.0567\n",
      "Epoch 460/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0571 - mean_squared_error: 0.0035 - val_loss: 0.1103 - val_mean_squared_error: 0.0568\n",
      "Epoch 461/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0576 - mean_squared_error: 0.0041 - val_loss: 0.1106 - val_mean_squared_error: 0.0572\n",
      "Epoch 462/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0569 - mean_squared_error: 0.0036 - val_loss: 0.1104 - val_mean_squared_error: 0.0572\n",
      "Epoch 463/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0566 - mean_squared_error: 0.0035 - val_loss: 0.1096 - val_mean_squared_error: 0.0566\n",
      "Epoch 464/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0566 - mean_squared_error: 0.0036 - val_loss: 0.1097 - val_mean_squared_error: 0.0568\n",
      "Epoch 465/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0568 - mean_squared_error: 0.0040 - val_loss: 0.1100 - val_mean_squared_error: 0.0572\n",
      "Epoch 466/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0561 - mean_squared_error: 0.0034 - val_loss: 0.1100 - val_mean_squared_error: 0.0574\n",
      "Epoch 467/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0565 - mean_squared_error: 0.0040 - val_loss: 0.1106 - val_mean_squared_error: 0.0581\n",
      "Epoch 468/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0563 - mean_squared_error: 0.0038 - val_loss: 0.1091 - val_mean_squared_error: 0.0568\n",
      "Epoch 469/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0557 - mean_squared_error: 0.0035 - val_loss: 0.1091 - val_mean_squared_error: 0.0570\n",
      "Epoch 470/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0555 - mean_squared_error: 0.0034 - val_loss: 0.1095 - val_mean_squared_error: 0.0575\n",
      "Epoch 471/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0554 - mean_squared_error: 0.0034 - val_loss: 0.1090 - val_mean_squared_error: 0.0572\n",
      "Epoch 472/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0552 - mean_squared_error: 0.0035 - val_loss: 0.1096 - val_mean_squared_error: 0.0579\n",
      "Epoch 473/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0552 - mean_squared_error: 0.0036 - val_loss: 0.1082 - val_mean_squared_error: 0.0566\n",
      "Epoch 474/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0555 - mean_squared_error: 0.0039 - val_loss: 0.1096 - val_mean_squared_error: 0.0581\n",
      "Epoch 475/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0556 - mean_squared_error: 0.0042 - val_loss: 0.1085 - val_mean_squared_error: 0.0572\n",
      "Epoch 476/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0549 - mean_squared_error: 0.0036 - val_loss: 0.1085 - val_mean_squared_error: 0.0573\n",
      "Epoch 477/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0546 - mean_squared_error: 0.0035 - val_loss: 0.1080 - val_mean_squared_error: 0.0570\n",
      "Epoch 478/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0544 - mean_squared_error: 0.0035 - val_loss: 0.1077 - val_mean_squared_error: 0.0568\n",
      "Epoch 479/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0541 - mean_squared_error: 0.0034 - val_loss: 0.1074 - val_mean_squared_error: 0.0568\n",
      "Epoch 480/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0540 - mean_squared_error: 0.0033 - val_loss: 0.1078 - val_mean_squared_error: 0.0573\n",
      "Epoch 481/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0537 - mean_squared_error: 0.0032 - val_loss: 0.1081 - val_mean_squared_error: 0.0577\n",
      "Epoch 482/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0539 - mean_squared_error: 0.0036 - val_loss: 0.1081 - val_mean_squared_error: 0.0578\n",
      "Epoch 483/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0538 - mean_squared_error: 0.0035 - val_loss: 0.1078 - val_mean_squared_error: 0.0576\n",
      "Epoch 484/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0535 - mean_squared_error: 0.0034 - val_loss: 0.1071 - val_mean_squared_error: 0.0571\n",
      "Epoch 485/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0532 - mean_squared_error: 0.0032 - val_loss: 0.1069 - val_mean_squared_error: 0.0571\n",
      "Epoch 486/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0531 - mean_squared_error: 0.0033 - val_loss: 0.1069 - val_mean_squared_error: 0.0572\n",
      "Epoch 487/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0531 - mean_squared_error: 0.0034 - val_loss: 0.1071 - val_mean_squared_error: 0.0575\n",
      "Epoch 488/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0530 - mean_squared_error: 0.0035 - val_loss: 0.1066 - val_mean_squared_error: 0.0572\n",
      "Epoch 489/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0529 - mean_squared_error: 0.0035 - val_loss: 0.1067 - val_mean_squared_error: 0.0574\n",
      "Epoch 490/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0528 - mean_squared_error: 0.0036 - val_loss: 0.1066 - val_mean_squared_error: 0.0575\n",
      "Epoch 491/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0524 - mean_squared_error: 0.0033 - val_loss: 0.1070 - val_mean_squared_error: 0.0580\n",
      "Epoch 492/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0524 - mean_squared_error: 0.0034 - val_loss: 0.1062 - val_mean_squared_error: 0.0573\n",
      "Epoch 493/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0524 - mean_squared_error: 0.0036 - val_loss: 0.1061 - val_mean_squared_error: 0.0573\n",
      "Epoch 494/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0521 - mean_squared_error: 0.0034 - val_loss: 0.1066 - val_mean_squared_error: 0.0580\n",
      "Epoch 495/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0520 - mean_squared_error: 0.0034 - val_loss: 0.1062 - val_mean_squared_error: 0.0577\n",
      "Epoch 496/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0518 - mean_squared_error: 0.0034 - val_loss: 0.1059 - val_mean_squared_error: 0.0575\n",
      "Epoch 497/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0516 - mean_squared_error: 0.0033 - val_loss: 0.1063 - val_mean_squared_error: 0.0581\n",
      "Epoch 498/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0514 - mean_squared_error: 0.0032 - val_loss: 0.1054 - val_mean_squared_error: 0.0573\n",
      "Epoch 499/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0513 - mean_squared_error: 0.0033 - val_loss: 0.1055 - val_mean_squared_error: 0.0575\n",
      "Epoch 500/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0512 - mean_squared_error: 0.0033 - val_loss: 0.1053 - val_mean_squared_error: 0.0575\n",
      "Epoch 501/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0511 - mean_squared_error: 0.0033 - val_loss: 0.1061 - val_mean_squared_error: 0.0584\n",
      "Epoch 502/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0509 - mean_squared_error: 0.0033 - val_loss: 0.1054 - val_mean_squared_error: 0.0578\n",
      "Epoch 503/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0508 - mean_squared_error: 0.0033 - val_loss: 0.1055 - val_mean_squared_error: 0.0580\n",
      "Epoch 504/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0506 - mean_squared_error: 0.0032 - val_loss: 0.1050 - val_mean_squared_error: 0.0577\n",
      "Epoch 505/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0505 - mean_squared_error: 0.0033 - val_loss: 0.1050 - val_mean_squared_error: 0.0579\n",
      "Epoch 506/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0505 - mean_squared_error: 0.0034 - val_loss: 0.1052 - val_mean_squared_error: 0.0581\n",
      "Epoch 507/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0506 - mean_squared_error: 0.0036 - val_loss: 0.1045 - val_mean_squared_error: 0.0575\n",
      "Epoch 508/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0502 - mean_squared_error: 0.0033 - val_loss: 0.1048 - val_mean_squared_error: 0.0580\n",
      "Epoch 509/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0504 - mean_squared_error: 0.0036 - val_loss: 0.1051 - val_mean_squared_error: 0.0584\n",
      "Epoch 510/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0499 - mean_squared_error: 0.0033 - val_loss: 0.1050 - val_mean_squared_error: 0.0585\n",
      "Epoch 511/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0497 - mean_squared_error: 0.0032 - val_loss: 0.1042 - val_mean_squared_error: 0.0578\n",
      "Epoch 512/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0494 - mean_squared_error: 0.0031 - val_loss: 0.1044 - val_mean_squared_error: 0.0582\n",
      "Epoch 513/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0494 - mean_squared_error: 0.0032 - val_loss: 0.1048 - val_mean_squared_error: 0.0586\n",
      "Epoch 514/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0494 - mean_squared_error: 0.0033 - val_loss: 0.1040 - val_mean_squared_error: 0.0580\n",
      "Epoch 515/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0492 - mean_squared_error: 0.0032 - val_loss: 0.1045 - val_mean_squared_error: 0.0586\n",
      "Epoch 516/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0490 - mean_squared_error: 0.0032 - val_loss: 0.1053 - val_mean_squared_error: 0.0595\n",
      "Epoch 517/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0499 - mean_squared_error: 0.0041 - val_loss: 0.1038 - val_mean_squared_error: 0.0581\n",
      "Epoch 518/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0490 - mean_squared_error: 0.0034 - val_loss: 0.1045 - val_mean_squared_error: 0.0589\n",
      "Epoch 519/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0495 - mean_squared_error: 0.0039 - val_loss: 0.1043 - val_mean_squared_error: 0.0588\n",
      "Epoch 520/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0485 - mean_squared_error: 0.0031 - val_loss: 0.1037 - val_mean_squared_error: 0.0584\n",
      "Epoch 521/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0483 - mean_squared_error: 0.0030 - val_loss: 0.1030 - val_mean_squared_error: 0.0578\n",
      "Epoch 522/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0481 - mean_squared_error: 0.0030 - val_loss: 0.1029 - val_mean_squared_error: 0.0579\n",
      "Epoch 523/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0482 - mean_squared_error: 0.0032 - val_loss: 0.1027 - val_mean_squared_error: 0.0577\n",
      "Epoch 524/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0485 - mean_squared_error: 0.0036 - val_loss: 0.1037 - val_mean_squared_error: 0.0588\n",
      "Epoch 525/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0483 - mean_squared_error: 0.0035 - val_loss: 0.1031 - val_mean_squared_error: 0.0584\n",
      "Epoch 526/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0477 - mean_squared_error: 0.0030 - val_loss: 0.1032 - val_mean_squared_error: 0.0586\n",
      "Epoch 527/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0477 - mean_squared_error: 0.0031 - val_loss: 0.1028 - val_mean_squared_error: 0.0583\n",
      "Epoch 528/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0475 - mean_squared_error: 0.0030 - val_loss: 0.1030 - val_mean_squared_error: 0.0586\n",
      "Epoch 529/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0473 - mean_squared_error: 0.0030 - val_loss: 0.1024 - val_mean_squared_error: 0.0582\n",
      "Epoch 530/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0476 - mean_squared_error: 0.0033 - val_loss: 0.1023 - val_mean_squared_error: 0.0581\n",
      "Epoch 531/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0475 - mean_squared_error: 0.0033 - val_loss: 0.1028 - val_mean_squared_error: 0.0587\n",
      "Epoch 532/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0471 - mean_squared_error: 0.0031 - val_loss: 0.1021 - val_mean_squared_error: 0.0581\n",
      "Epoch 533/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0470 - mean_squared_error: 0.0031 - val_loss: 0.1023 - val_mean_squared_error: 0.0584\n",
      "Epoch 534/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0469 - mean_squared_error: 0.0031 - val_loss: 0.1025 - val_mean_squared_error: 0.0588\n",
      "Epoch 535/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0467 - mean_squared_error: 0.0031 - val_loss: 0.1035 - val_mean_squared_error: 0.0599\n",
      "Epoch 536/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0469 - mean_squared_error: 0.0033 - val_loss: 0.1017 - val_mean_squared_error: 0.0582\n",
      "Epoch 537/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0468 - mean_squared_error: 0.0033 - val_loss: 0.1027 - val_mean_squared_error: 0.0592\n",
      "Epoch 538/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0466 - mean_squared_error: 0.0032 - val_loss: 0.1017 - val_mean_squared_error: 0.0584\n",
      "Epoch 539/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0465 - mean_squared_error: 0.0032 - val_loss: 0.1037 - val_mean_squared_error: 0.0605\n",
      "Epoch 540/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0470 - mean_squared_error: 0.0038 - val_loss: 0.1024 - val_mean_squared_error: 0.0592\n",
      "Epoch 541/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0466 - mean_squared_error: 0.0035 - val_loss: 0.1022 - val_mean_squared_error: 0.0592\n",
      "Epoch 542/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0462 - mean_squared_error: 0.0032 - val_loss: 0.1015 - val_mean_squared_error: 0.0586\n",
      "Epoch 543/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0458 - mean_squared_error: 0.0029 - val_loss: 0.1015 - val_mean_squared_error: 0.0587\n",
      "Epoch 544/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0458 - mean_squared_error: 0.0031 - val_loss: 0.1023 - val_mean_squared_error: 0.0596\n",
      "Epoch 545/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0458 - mean_squared_error: 0.0031 - val_loss: 0.1012 - val_mean_squared_error: 0.0586\n",
      "Epoch 546/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0456 - mean_squared_error: 0.0030 - val_loss: 0.1008 - val_mean_squared_error: 0.0583\n",
      "Epoch 547/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0453 - mean_squared_error: 0.0029 - val_loss: 0.1014 - val_mean_squared_error: 0.0591\n",
      "Epoch 548/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0454 - mean_squared_error: 0.0031 - val_loss: 0.1011 - val_mean_squared_error: 0.0588\n",
      "Epoch 549/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0452 - mean_squared_error: 0.0029 - val_loss: 0.1009 - val_mean_squared_error: 0.0587\n",
      "Epoch 550/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0449 - mean_squared_error: 0.0028 - val_loss: 0.1005 - val_mean_squared_error: 0.0585\n",
      "Epoch 551/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0449 - mean_squared_error: 0.0029 - val_loss: 0.1002 - val_mean_squared_error: 0.0582\n",
      "Epoch 552/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0452 - mean_squared_error: 0.0032 - val_loss: 0.1009 - val_mean_squared_error: 0.0590\n",
      "Epoch 553/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0449 - mean_squared_error: 0.0031 - val_loss: 0.1023 - val_mean_squared_error: 0.0605\n",
      "Epoch 554/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0449 - mean_squared_error: 0.0031 - val_loss: 0.1003 - val_mean_squared_error: 0.0586\n",
      "Epoch 555/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0444 - mean_squared_error: 0.0028 - val_loss: 0.1003 - val_mean_squared_error: 0.0587\n",
      "Epoch 556/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0447 - mean_squared_error: 0.0032 - val_loss: 0.1009 - val_mean_squared_error: 0.0594\n",
      "Epoch 557/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0448 - mean_squared_error: 0.0033 - val_loss: 0.1001 - val_mean_squared_error: 0.0586\n",
      "Epoch 558/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0444 - mean_squared_error: 0.0030 - val_loss: 0.0999 - val_mean_squared_error: 0.0587\n",
      "Epoch 559/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0445 - mean_squared_error: 0.0032 - val_loss: 0.0998 - val_mean_squared_error: 0.0586\n",
      "Epoch 560/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0448 - mean_squared_error: 0.0036 - val_loss: 0.0997 - val_mean_squared_error: 0.0586\n",
      "Epoch 561/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0442 - mean_squared_error: 0.0031 - val_loss: 0.1000 - val_mean_squared_error: 0.0590\n",
      "Epoch 562/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0445 - mean_squared_error: 0.0035 - val_loss: 0.0998 - val_mean_squared_error: 0.0589\n",
      "Epoch 563/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0444 - mean_squared_error: 0.0035 - val_loss: 0.0998 - val_mean_squared_error: 0.0590\n",
      "Epoch 564/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0438 - mean_squared_error: 0.0030 - val_loss: 0.0995 - val_mean_squared_error: 0.0588\n",
      "Epoch 565/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0436 - mean_squared_error: 0.0029 - val_loss: 0.0990 - val_mean_squared_error: 0.0584\n",
      "Epoch 566/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0432 - mean_squared_error: 0.0026 - val_loss: 0.0996 - val_mean_squared_error: 0.0591\n",
      "Epoch 567/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0433 - mean_squared_error: 0.0028 - val_loss: 0.0990 - val_mean_squared_error: 0.0586\n",
      "Epoch 568/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0432 - mean_squared_error: 0.0028 - val_loss: 0.0993 - val_mean_squared_error: 0.0590\n",
      "Epoch 569/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0433 - mean_squared_error: 0.0030 - val_loss: 0.0999 - val_mean_squared_error: 0.0597\n",
      "Epoch 570/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0429 - mean_squared_error: 0.0027 - val_loss: 0.0996 - val_mean_squared_error: 0.0595\n",
      "Epoch 571/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0430 - mean_squared_error: 0.0029 - val_loss: 0.0987 - val_mean_squared_error: 0.0586\n",
      "Epoch 572/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0430 - mean_squared_error: 0.0030 - val_loss: 0.0988 - val_mean_squared_error: 0.0588\n",
      "Epoch 573/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0430 - mean_squared_error: 0.0031 - val_loss: 0.0988 - val_mean_squared_error: 0.0589\n",
      "Epoch 574/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0431 - mean_squared_error: 0.0032 - val_loss: 0.0983 - val_mean_squared_error: 0.0585\n",
      "Epoch 575/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0425 - mean_squared_error: 0.0028 - val_loss: 0.0982 - val_mean_squared_error: 0.0585\n",
      "Epoch 576/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0427 - mean_squared_error: 0.0031 - val_loss: 0.0997 - val_mean_squared_error: 0.0600\n",
      "Epoch 577/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0426 - mean_squared_error: 0.0030 - val_loss: 0.0990 - val_mean_squared_error: 0.0595\n",
      "Epoch 578/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0426 - mean_squared_error: 0.0031 - val_loss: 0.0979 - val_mean_squared_error: 0.0585\n",
      "Epoch 579/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0425 - mean_squared_error: 0.0030 - val_loss: 0.0987 - val_mean_squared_error: 0.0594\n",
      "Epoch 580/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0421 - mean_squared_error: 0.0028 - val_loss: 0.0992 - val_mean_squared_error: 0.0600\n",
      "Epoch 581/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0421 - mean_squared_error: 0.0029 - val_loss: 0.0981 - val_mean_squared_error: 0.0589\n",
      "Epoch 582/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0421 - mean_squared_error: 0.0030 - val_loss: 0.0977 - val_mean_squared_error: 0.0586\n",
      "Epoch 583/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0418 - mean_squared_error: 0.0028 - val_loss: 0.0983 - val_mean_squared_error: 0.0593\n",
      "Epoch 584/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0417 - mean_squared_error: 0.0028 - val_loss: 0.0989 - val_mean_squared_error: 0.0600\n",
      "Epoch 585/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0417 - mean_squared_error: 0.0028 - val_loss: 0.0985 - val_mean_squared_error: 0.0597\n",
      "Epoch 586/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0414 - mean_squared_error: 0.0027 - val_loss: 0.0985 - val_mean_squared_error: 0.0598\n",
      "Epoch 587/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0416 - mean_squared_error: 0.0029 - val_loss: 0.0993 - val_mean_squared_error: 0.0606\n",
      "Epoch 588/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0416 - mean_squared_error: 0.0030 - val_loss: 0.0974 - val_mean_squared_error: 0.0588\n",
      "Epoch 589/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0415 - mean_squared_error: 0.0030 - val_loss: 0.0976 - val_mean_squared_error: 0.0592\n",
      "Epoch 590/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0411 - mean_squared_error: 0.0026 - val_loss: 0.0975 - val_mean_squared_error: 0.0592\n",
      "Epoch 591/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0409 - mean_squared_error: 0.0026 - val_loss: 0.0973 - val_mean_squared_error: 0.0590\n",
      "Epoch 592/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0409 - mean_squared_error: 0.0027 - val_loss: 0.0978 - val_mean_squared_error: 0.0596\n",
      "Epoch 593/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0411 - mean_squared_error: 0.0029 - val_loss: 0.0978 - val_mean_squared_error: 0.0597\n",
      "Epoch 594/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0407 - mean_squared_error: 0.0027 - val_loss: 0.0974 - val_mean_squared_error: 0.0593\n",
      "Epoch 595/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0406 - mean_squared_error: 0.0026 - val_loss: 0.0971 - val_mean_squared_error: 0.0592\n",
      "Epoch 596/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0405 - mean_squared_error: 0.0026 - val_loss: 0.0985 - val_mean_squared_error: 0.0607\n",
      "Epoch 597/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0409 - mean_squared_error: 0.0031 - val_loss: 0.0978 - val_mean_squared_error: 0.0600\n",
      "Epoch 598/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0404 - mean_squared_error: 0.0027 - val_loss: 0.0977 - val_mean_squared_error: 0.0600\n",
      "Epoch 599/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0405 - mean_squared_error: 0.0029 - val_loss: 0.0971 - val_mean_squared_error: 0.0595\n",
      "Epoch 600/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0408 - mean_squared_error: 0.0032 - val_loss: 0.0973 - val_mean_squared_error: 0.0597\n",
      "Epoch 601/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0402 - mean_squared_error: 0.0027 - val_loss: 0.0970 - val_mean_squared_error: 0.0596\n",
      "Epoch 602/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0400 - mean_squared_error: 0.0026 - val_loss: 0.0981 - val_mean_squared_error: 0.0608\n",
      "Epoch 603/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0405 - mean_squared_error: 0.0031 - val_loss: 0.0980 - val_mean_squared_error: 0.0607\n",
      "Epoch 604/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0402 - mean_squared_error: 0.0029 - val_loss: 0.0972 - val_mean_squared_error: 0.0600\n",
      "Epoch 605/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0399 - mean_squared_error: 0.0028 - val_loss: 0.0974 - val_mean_squared_error: 0.0603\n",
      "Epoch 606/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0397 - mean_squared_error: 0.0027 - val_loss: 0.0972 - val_mean_squared_error: 0.0602\n",
      "Epoch 607/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0395 - mean_squared_error: 0.0026 - val_loss: 0.0968 - val_mean_squared_error: 0.0599\n",
      "Epoch 608/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0395 - mean_squared_error: 0.0026 - val_loss: 0.0969 - val_mean_squared_error: 0.0601\n",
      "Epoch 609/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0395 - mean_squared_error: 0.0027 - val_loss: 0.0969 - val_mean_squared_error: 0.0602\n",
      "Epoch 610/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0395 - mean_squared_error: 0.0027 - val_loss: 0.0968 - val_mean_squared_error: 0.0601\n",
      "Epoch 611/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0394 - mean_squared_error: 0.0028 - val_loss: 0.0969 - val_mean_squared_error: 0.0603\n",
      "Epoch 612/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0397 - mean_squared_error: 0.0031 - val_loss: 0.0967 - val_mean_squared_error: 0.0602\n",
      "Epoch 613/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0392 - mean_squared_error: 0.0027 - val_loss: 0.0963 - val_mean_squared_error: 0.0599\n",
      "Epoch 614/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0393 - mean_squared_error: 0.0029 - val_loss: 0.0968 - val_mean_squared_error: 0.0604\n",
      "Epoch 615/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0395 - mean_squared_error: 0.0032 - val_loss: 0.0982 - val_mean_squared_error: 0.0619\n",
      "Epoch 616/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0394 - mean_squared_error: 0.0031 - val_loss: 0.0967 - val_mean_squared_error: 0.0605\n",
      "Epoch 617/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0390 - mean_squared_error: 0.0029 - val_loss: 0.0965 - val_mean_squared_error: 0.0604\n",
      "Epoch 618/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0389 - mean_squared_error: 0.0028 - val_loss: 0.0957 - val_mean_squared_error: 0.0597\n",
      "Epoch 619/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0386 - mean_squared_error: 0.0026 - val_loss: 0.0966 - val_mean_squared_error: 0.0607\n",
      "Epoch 620/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0386 - mean_squared_error: 0.0028 - val_loss: 0.0976 - val_mean_squared_error: 0.0617\n",
      "Epoch 621/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0389 - mean_squared_error: 0.0031 - val_loss: 0.0966 - val_mean_squared_error: 0.0608\n",
      "Epoch 622/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0385 - mean_squared_error: 0.0027 - val_loss: 0.0965 - val_mean_squared_error: 0.0608\n",
      "Epoch 623/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0382 - mean_squared_error: 0.0025 - val_loss: 0.0959 - val_mean_squared_error: 0.0603\n",
      "Epoch 624/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0380 - mean_squared_error: 0.0024 - val_loss: 0.0956 - val_mean_squared_error: 0.0601\n",
      "Epoch 625/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0380 - mean_squared_error: 0.0026 - val_loss: 0.0964 - val_mean_squared_error: 0.0609\n",
      "Epoch 626/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0389 - mean_squared_error: 0.0034 - val_loss: 0.0963 - val_mean_squared_error: 0.0608\n",
      "Epoch 627/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0390 - mean_squared_error: 0.0035 - val_loss: 0.0957 - val_mean_squared_error: 0.0603\n",
      "Epoch 628/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0384 - mean_squared_error: 0.0030 - val_loss: 0.0957 - val_mean_squared_error: 0.0604\n",
      "Epoch 629/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0383 - mean_squared_error: 0.0030 - val_loss: 0.0954 - val_mean_squared_error: 0.0602\n",
      "Epoch 630/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0386 - mean_squared_error: 0.0033 - val_loss: 0.0954 - val_mean_squared_error: 0.0602\n",
      "Epoch 631/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0382 - mean_squared_error: 0.0031 - val_loss: 0.0970 - val_mean_squared_error: 0.0618\n",
      "Epoch 632/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0381 - mean_squared_error: 0.0030 - val_loss: 0.0953 - val_mean_squared_error: 0.0603\n",
      "Epoch 633/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0375 - mean_squared_error: 0.0026 - val_loss: 0.0956 - val_mean_squared_error: 0.0607\n",
      "Epoch 634/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0376 - mean_squared_error: 0.0027 - val_loss: 0.0957 - val_mean_squared_error: 0.0608\n",
      "Epoch 635/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0378 - mean_squared_error: 0.0029 - val_loss: 0.0955 - val_mean_squared_error: 0.0607\n",
      "Epoch 636/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0385 - mean_squared_error: 0.0037 - val_loss: 0.0948 - val_mean_squared_error: 0.0600\n",
      "Epoch 637/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0377 - mean_squared_error: 0.0029 - val_loss: 0.0952 - val_mean_squared_error: 0.0605\n",
      "Epoch 638/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0373 - mean_squared_error: 0.0027 - val_loss: 0.0949 - val_mean_squared_error: 0.0603\n",
      "Epoch 639/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0373 - mean_squared_error: 0.0028 - val_loss: 0.0958 - val_mean_squared_error: 0.0613\n",
      "Epoch 640/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0373 - mean_squared_error: 0.0029 - val_loss: 0.0954 - val_mean_squared_error: 0.0610\n",
      "Epoch 641/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0370 - mean_squared_error: 0.0026 - val_loss: 0.0948 - val_mean_squared_error: 0.0604\n",
      "Epoch 642/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0370 - mean_squared_error: 0.0026 - val_loss: 0.0952 - val_mean_squared_error: 0.0609\n",
      "Epoch 643/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0369 - mean_squared_error: 0.0026 - val_loss: 0.0946 - val_mean_squared_error: 0.0604\n",
      "Epoch 644/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0367 - mean_squared_error: 0.0025 - val_loss: 0.0948 - val_mean_squared_error: 0.0607\n",
      "Epoch 645/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0365 - mean_squared_error: 0.0024 - val_loss: 0.0947 - val_mean_squared_error: 0.0607\n",
      "Epoch 646/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0366 - mean_squared_error: 0.0026 - val_loss: 0.0944 - val_mean_squared_error: 0.0604\n",
      "Epoch 647/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0366 - mean_squared_error: 0.0027 - val_loss: 0.0956 - val_mean_squared_error: 0.0616\n",
      "Epoch 648/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0367 - mean_squared_error: 0.0027 - val_loss: 0.0964 - val_mean_squared_error: 0.0625\n",
      "Epoch 649/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0368 - mean_squared_error: 0.0029 - val_loss: 0.0948 - val_mean_squared_error: 0.0610\n",
      "Epoch 650/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0364 - mean_squared_error: 0.0026 - val_loss: 0.0948 - val_mean_squared_error: 0.0610\n",
      "Epoch 651/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0364 - mean_squared_error: 0.0027 - val_loss: 0.0956 - val_mean_squared_error: 0.0619\n",
      "Epoch 652/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0363 - mean_squared_error: 0.0027 - val_loss: 0.0945 - val_mean_squared_error: 0.0608\n",
      "Epoch 653/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0361 - mean_squared_error: 0.0025 - val_loss: 0.0944 - val_mean_squared_error: 0.0608\n",
      "Epoch 654/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0362 - mean_squared_error: 0.0027 - val_loss: 0.0942 - val_mean_squared_error: 0.0607\n",
      "Epoch 655/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0364 - mean_squared_error: 0.0030 - val_loss: 0.0942 - val_mean_squared_error: 0.0607\n",
      "Epoch 656/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0365 - mean_squared_error: 0.0030 - val_loss: 0.0942 - val_mean_squared_error: 0.0608\n",
      "Epoch 657/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0362 - mean_squared_error: 0.0028 - val_loss: 0.0948 - val_mean_squared_error: 0.0615\n",
      "Epoch 658/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0364 - mean_squared_error: 0.0031 - val_loss: 0.0947 - val_mean_squared_error: 0.0614\n",
      "Epoch 659/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0360 - mean_squared_error: 0.0027 - val_loss: 0.0936 - val_mean_squared_error: 0.0604\n",
      "Epoch 660/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0358 - mean_squared_error: 0.0026 - val_loss: 0.0948 - val_mean_squared_error: 0.0618\n",
      "Epoch 661/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0363 - mean_squared_error: 0.0032 - val_loss: 0.0940 - val_mean_squared_error: 0.0609\n",
      "Epoch 662/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0362 - mean_squared_error: 0.0032 - val_loss: 0.0941 - val_mean_squared_error: 0.0610\n",
      "Epoch 663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0357 - mean_squared_error: 0.0028 - val_loss: 0.0943 - val_mean_squared_error: 0.0614\n",
      "Epoch 664/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0353 - mean_squared_error: 0.0024 - val_loss: 0.0943 - val_mean_squared_error: 0.0615\n",
      "Epoch 665/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0353 - mean_squared_error: 0.0025 - val_loss: 0.0939 - val_mean_squared_error: 0.0612\n",
      "Epoch 666/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0352 - mean_squared_error: 0.0024 - val_loss: 0.0940 - val_mean_squared_error: 0.0613\n",
      "Epoch 667/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0353 - mean_squared_error: 0.0026 - val_loss: 0.0940 - val_mean_squared_error: 0.0614\n",
      "Epoch 668/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0351 - mean_squared_error: 0.0025 - val_loss: 0.0936 - val_mean_squared_error: 0.0610\n",
      "Epoch 669/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0349 - mean_squared_error: 0.0023 - val_loss: 0.0939 - val_mean_squared_error: 0.0614\n",
      "Epoch 670/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0348 - mean_squared_error: 0.0024 - val_loss: 0.0939 - val_mean_squared_error: 0.0615\n",
      "Epoch 671/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0350 - mean_squared_error: 0.0026 - val_loss: 0.0940 - val_mean_squared_error: 0.0616\n",
      "Epoch 672/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0352 - mean_squared_error: 0.0028 - val_loss: 0.0945 - val_mean_squared_error: 0.0622\n",
      "Epoch 673/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0352 - mean_squared_error: 0.0029 - val_loss: 0.0946 - val_mean_squared_error: 0.0623\n",
      "Epoch 674/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0349 - mean_squared_error: 0.0026 - val_loss: 0.0935 - val_mean_squared_error: 0.0612\n",
      "Epoch 675/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0347 - mean_squared_error: 0.0025 - val_loss: 0.0936 - val_mean_squared_error: 0.0614\n",
      "Epoch 676/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0349 - mean_squared_error: 0.0028 - val_loss: 0.0938 - val_mean_squared_error: 0.0617\n",
      "Epoch 677/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0348 - mean_squared_error: 0.0027 - val_loss: 0.0939 - val_mean_squared_error: 0.0618\n",
      "Epoch 678/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0347 - mean_squared_error: 0.0027 - val_loss: 0.0942 - val_mean_squared_error: 0.0622\n",
      "Epoch 679/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0345 - mean_squared_error: 0.0026 - val_loss: 0.0942 - val_mean_squared_error: 0.0622\n",
      "Epoch 680/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0350 - mean_squared_error: 0.0030 - val_loss: 0.0931 - val_mean_squared_error: 0.0612\n",
      "Epoch 681/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0344 - mean_squared_error: 0.0026 - val_loss: 0.0935 - val_mean_squared_error: 0.0617\n",
      "Epoch 682/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0347 - mean_squared_error: 0.0029 - val_loss: 0.0934 - val_mean_squared_error: 0.0616\n",
      "Epoch 683/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0342 - mean_squared_error: 0.0025 - val_loss: 0.0932 - val_mean_squared_error: 0.0615\n",
      "Epoch 684/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0342 - mean_squared_error: 0.0025 - val_loss: 0.0931 - val_mean_squared_error: 0.0615\n",
      "Epoch 685/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0341 - mean_squared_error: 0.0025 - val_loss: 0.0936 - val_mean_squared_error: 0.0620\n",
      "Epoch 686/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0341 - mean_squared_error: 0.0026 - val_loss: 0.0927 - val_mean_squared_error: 0.0612\n",
      "Epoch 687/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0345 - mean_squared_error: 0.0030 - val_loss: 0.0929 - val_mean_squared_error: 0.0614\n",
      "Epoch 688/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0344 - mean_squared_error: 0.0029 - val_loss: 0.0927 - val_mean_squared_error: 0.0612\n",
      "Epoch 689/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0340 - mean_squared_error: 0.0026 - val_loss: 0.0926 - val_mean_squared_error: 0.0613\n",
      "Epoch 690/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0337 - mean_squared_error: 0.0024 - val_loss: 0.0930 - val_mean_squared_error: 0.0617\n",
      "Epoch 691/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0341 - mean_squared_error: 0.0028 - val_loss: 0.0923 - val_mean_squared_error: 0.0610\n",
      "Epoch 692/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0339 - mean_squared_error: 0.0027 - val_loss: 0.0929 - val_mean_squared_error: 0.0618\n",
      "Epoch 693/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0337 - mean_squared_error: 0.0025 - val_loss: 0.0931 - val_mean_squared_error: 0.0620\n",
      "Epoch 694/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0336 - mean_squared_error: 0.0025 - val_loss: 0.0931 - val_mean_squared_error: 0.0620\n",
      "Epoch 695/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0337 - mean_squared_error: 0.0027 - val_loss: 0.0924 - val_mean_squared_error: 0.0614\n",
      "Epoch 696/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0336 - mean_squared_error: 0.0026 - val_loss: 0.0920 - val_mean_squared_error: 0.0611\n",
      "Epoch 697/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0335 - mean_squared_error: 0.0026 - val_loss: 0.0926 - val_mean_squared_error: 0.0617\n",
      "Epoch 698/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0335 - mean_squared_error: 0.0027 - val_loss: 0.0927 - val_mean_squared_error: 0.0619\n",
      "Epoch 699/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0334 - mean_squared_error: 0.0026 - val_loss: 0.0943 - val_mean_squared_error: 0.0635\n",
      "Epoch 700/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0339 - mean_squared_error: 0.0031 - val_loss: 0.0929 - val_mean_squared_error: 0.0621\n",
      "Epoch 701/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0337 - mean_squared_error: 0.0030 - val_loss: 0.0918 - val_mean_squared_error: 0.0611\n",
      "Epoch 702/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0333 - mean_squared_error: 0.0026 - val_loss: 0.0921 - val_mean_squared_error: 0.0615\n",
      "Epoch 703/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0330 - mean_squared_error: 0.0024 - val_loss: 0.0923 - val_mean_squared_error: 0.0618\n",
      "Epoch 704/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0331 - mean_squared_error: 0.0026 - val_loss: 0.0921 - val_mean_squared_error: 0.0616\n",
      "Epoch 705/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0333 - mean_squared_error: 0.0028 - val_loss: 0.0920 - val_mean_squared_error: 0.0615\n",
      "Epoch 706/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0334 - mean_squared_error: 0.0030 - val_loss: 0.0919 - val_mean_squared_error: 0.0615\n",
      "Epoch 707/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0332 - mean_squared_error: 0.0028 - val_loss: 0.0918 - val_mean_squared_error: 0.0614\n",
      "Epoch 708/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0328 - mean_squared_error: 0.0025 - val_loss: 0.0919 - val_mean_squared_error: 0.0616\n",
      "Epoch 709/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0328 - mean_squared_error: 0.0025 - val_loss: 0.0923 - val_mean_squared_error: 0.0621\n",
      "Epoch 710/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0330 - mean_squared_error: 0.0028 - val_loss: 0.0921 - val_mean_squared_error: 0.0619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 711/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0325 - mean_squared_error: 0.0024 - val_loss: 0.0916 - val_mean_squared_error: 0.0615\n",
      "Epoch 712/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0323 - mean_squared_error: 0.0023 - val_loss: 0.0913 - val_mean_squared_error: 0.0613\n",
      "Epoch 713/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0323 - mean_squared_error: 0.0023 - val_loss: 0.0923 - val_mean_squared_error: 0.0624\n",
      "Epoch 714/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0323 - mean_squared_error: 0.0024 - val_loss: 0.0920 - val_mean_squared_error: 0.0621\n",
      "Epoch 715/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0324 - mean_squared_error: 0.0025 - val_loss: 0.0920 - val_mean_squared_error: 0.0622\n",
      "Epoch 716/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0330 - mean_squared_error: 0.0031 - val_loss: 0.0915 - val_mean_squared_error: 0.0616\n",
      "Epoch 717/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0328 - mean_squared_error: 0.0030 - val_loss: 0.0920 - val_mean_squared_error: 0.0621\n",
      "Epoch 718/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0327 - mean_squared_error: 0.0029 - val_loss: 0.0920 - val_mean_squared_error: 0.0622\n",
      "Epoch 719/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0323 - mean_squared_error: 0.0025 - val_loss: 0.0920 - val_mean_squared_error: 0.0623\n",
      "Epoch 720/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0322 - mean_squared_error: 0.0026 - val_loss: 0.0909 - val_mean_squared_error: 0.0613\n",
      "Epoch 721/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0320 - mean_squared_error: 0.0024 - val_loss: 0.0912 - val_mean_squared_error: 0.0617\n",
      "Epoch 722/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0322 - mean_squared_error: 0.0026 - val_loss: 0.0913 - val_mean_squared_error: 0.0618\n",
      "Epoch 723/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0324 - mean_squared_error: 0.0028 - val_loss: 0.0909 - val_mean_squared_error: 0.0614\n",
      "Epoch 724/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0318 - mean_squared_error: 0.0023 - val_loss: 0.0909 - val_mean_squared_error: 0.0615\n",
      "Epoch 725/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0319 - mean_squared_error: 0.0025 - val_loss: 0.0910 - val_mean_squared_error: 0.0616\n",
      "Epoch 726/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0318 - mean_squared_error: 0.0024 - val_loss: 0.0908 - val_mean_squared_error: 0.0615\n",
      "Epoch 727/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0320 - mean_squared_error: 0.0027 - val_loss: 0.0906 - val_mean_squared_error: 0.0614\n",
      "Epoch 728/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0315 - mean_squared_error: 0.0023 - val_loss: 0.0909 - val_mean_squared_error: 0.0617\n",
      "Epoch 729/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0315 - mean_squared_error: 0.0024 - val_loss: 0.0913 - val_mean_squared_error: 0.0621\n",
      "Epoch 730/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0316 - mean_squared_error: 0.0024 - val_loss: 0.0919 - val_mean_squared_error: 0.0628\n",
      "Epoch 731/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0319 - mean_squared_error: 0.0028 - val_loss: 0.0916 - val_mean_squared_error: 0.0625\n",
      "Epoch 732/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0317 - mean_squared_error: 0.0027 - val_loss: 0.0909 - val_mean_squared_error: 0.0618\n",
      "Epoch 733/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0315 - mean_squared_error: 0.0025 - val_loss: 0.0911 - val_mean_squared_error: 0.0621\n",
      "Epoch 734/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0315 - mean_squared_error: 0.0026 - val_loss: 0.0912 - val_mean_squared_error: 0.0623\n",
      "Epoch 735/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0316 - mean_squared_error: 0.0027 - val_loss: 0.0907 - val_mean_squared_error: 0.0618\n",
      "Epoch 736/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0317 - mean_squared_error: 0.0028 - val_loss: 0.0906 - val_mean_squared_error: 0.0617\n",
      "Epoch 737/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0313 - mean_squared_error: 0.0025 - val_loss: 0.0907 - val_mean_squared_error: 0.0619\n",
      "Epoch 738/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0312 - mean_squared_error: 0.0024 - val_loss: 0.0905 - val_mean_squared_error: 0.0618\n",
      "Epoch 739/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0314 - mean_squared_error: 0.0027 - val_loss: 0.0908 - val_mean_squared_error: 0.0621\n",
      "Epoch 740/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0316 - mean_squared_error: 0.0029 - val_loss: 0.0904 - val_mean_squared_error: 0.0617\n",
      "Epoch 741/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0312 - mean_squared_error: 0.0026 - val_loss: 0.0903 - val_mean_squared_error: 0.0617\n",
      "Epoch 742/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0309 - mean_squared_error: 0.0023 - val_loss: 0.0910 - val_mean_squared_error: 0.0625\n",
      "Epoch 743/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0313 - mean_squared_error: 0.0028 - val_loss: 0.0905 - val_mean_squared_error: 0.0620\n",
      "Epoch 744/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0309 - mean_squared_error: 0.0025 - val_loss: 0.0908 - val_mean_squared_error: 0.0624\n",
      "Epoch 745/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0308 - mean_squared_error: 0.0024 - val_loss: 0.0900 - val_mean_squared_error: 0.0617\n",
      "Epoch 746/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0315 - mean_squared_error: 0.0031 - val_loss: 0.0905 - val_mean_squared_error: 0.0621\n",
      "Epoch 747/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0316 - mean_squared_error: 0.0032 - val_loss: 0.0907 - val_mean_squared_error: 0.0623\n",
      "Epoch 748/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0308 - mean_squared_error: 0.0024 - val_loss: 0.0899 - val_mean_squared_error: 0.0616\n",
      "Epoch 749/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0303 - mean_squared_error: 0.0021 - val_loss: 0.0899 - val_mean_squared_error: 0.0617\n",
      "Epoch 750/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0304 - mean_squared_error: 0.0023 - val_loss: 0.0893 - val_mean_squared_error: 0.0612\n",
      "Epoch 751/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0305 - mean_squared_error: 0.0024 - val_loss: 0.0899 - val_mean_squared_error: 0.0618\n",
      "Epoch 752/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0308 - mean_squared_error: 0.0027 - val_loss: 0.0899 - val_mean_squared_error: 0.0618\n",
      "Epoch 753/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0305 - mean_squared_error: 0.0025 - val_loss: 0.0901 - val_mean_squared_error: 0.0621\n",
      "Epoch 754/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0302 - mean_squared_error: 0.0022 - val_loss: 0.0904 - val_mean_squared_error: 0.0625\n",
      "Epoch 755/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0308 - mean_squared_error: 0.0028 - val_loss: 0.0899 - val_mean_squared_error: 0.0620\n",
      "Epoch 756/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0305 - mean_squared_error: 0.0026 - val_loss: 0.0897 - val_mean_squared_error: 0.0618\n",
      "Epoch 757/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0312 - mean_squared_error: 0.0033 - val_loss: 0.0896 - val_mean_squared_error: 0.0616\n",
      "Epoch 758/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0307 - mean_squared_error: 0.0028 - val_loss: 0.0897 - val_mean_squared_error: 0.0618\n",
      "Epoch 759/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0304 - mean_squared_error: 0.0026 - val_loss: 0.0903 - val_mean_squared_error: 0.0625\n",
      "Epoch 760/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0306 - mean_squared_error: 0.0028 - val_loss: 0.0905 - val_mean_squared_error: 0.0627\n",
      "Epoch 761/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0307 - mean_squared_error: 0.0029 - val_loss: 0.0892 - val_mean_squared_error: 0.0614\n",
      "Epoch 762/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0299 - mean_squared_error: 0.0022 - val_loss: 0.0896 - val_mean_squared_error: 0.0619\n",
      "Epoch 763/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0301 - mean_squared_error: 0.0025 - val_loss: 0.0891 - val_mean_squared_error: 0.0615\n",
      "Epoch 764/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0304 - mean_squared_error: 0.0028 - val_loss: 0.0899 - val_mean_squared_error: 0.0623\n",
      "Epoch 765/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0299 - mean_squared_error: 0.0023 - val_loss: 0.0896 - val_mean_squared_error: 0.0621\n",
      "Epoch 766/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0302 - mean_squared_error: 0.0027 - val_loss: 0.0933 - val_mean_squared_error: 0.0658\n",
      "Epoch 767/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0305 - mean_squared_error: 0.0029 - val_loss: 0.0894 - val_mean_squared_error: 0.0619\n",
      "Epoch 768/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0297 - mean_squared_error: 0.0023 - val_loss: 0.0890 - val_mean_squared_error: 0.0617\n",
      "Epoch 769/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0295 - mean_squared_error: 0.0022 - val_loss: 0.0898 - val_mean_squared_error: 0.0625\n",
      "Epoch 770/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0296 - mean_squared_error: 0.0024 - val_loss: 0.0890 - val_mean_squared_error: 0.0617\n",
      "Epoch 771/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0294 - mean_squared_error: 0.0022 - val_loss: 0.0890 - val_mean_squared_error: 0.0618\n",
      "Epoch 772/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0295 - mean_squared_error: 0.0023 - val_loss: 0.0890 - val_mean_squared_error: 0.0618\n",
      "Epoch 773/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0297 - mean_squared_error: 0.0025 - val_loss: 0.0890 - val_mean_squared_error: 0.0618\n",
      "Epoch 774/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0296 - mean_squared_error: 0.0025 - val_loss: 0.0891 - val_mean_squared_error: 0.0620\n",
      "Epoch 775/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0296 - mean_squared_error: 0.0025 - val_loss: 0.0894 - val_mean_squared_error: 0.0623\n",
      "Epoch 776/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0301 - mean_squared_error: 0.0030 - val_loss: 0.0887 - val_mean_squared_error: 0.0616\n",
      "Epoch 777/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0294 - mean_squared_error: 0.0023 - val_loss: 0.0888 - val_mean_squared_error: 0.0617\n",
      "Epoch 778/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0292 - mean_squared_error: 0.0023 - val_loss: 0.0892 - val_mean_squared_error: 0.0622\n",
      "Epoch 779/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0291 - mean_squared_error: 0.0022 - val_loss: 0.0889 - val_mean_squared_error: 0.0620\n",
      "Epoch 780/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0290 - mean_squared_error: 0.0022 - val_loss: 0.0891 - val_mean_squared_error: 0.0623\n",
      "Epoch 781/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0293 - mean_squared_error: 0.0025 - val_loss: 0.0894 - val_mean_squared_error: 0.0626\n",
      "Epoch 782/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0295 - mean_squared_error: 0.0026 - val_loss: 0.0885 - val_mean_squared_error: 0.0617\n",
      "Epoch 783/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0293 - mean_squared_error: 0.0025 - val_loss: 0.0884 - val_mean_squared_error: 0.0616\n",
      "Epoch 784/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0292 - mean_squared_error: 0.0024 - val_loss: 0.0890 - val_mean_squared_error: 0.0622\n",
      "Epoch 785/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0290 - mean_squared_error: 0.0023 - val_loss: 0.0897 - val_mean_squared_error: 0.0630\n",
      "Epoch 786/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0291 - mean_squared_error: 0.0024 - val_loss: 0.0884 - val_mean_squared_error: 0.0618\n",
      "Epoch 787/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0291 - mean_squared_error: 0.0025 - val_loss: 0.0891 - val_mean_squared_error: 0.0625\n",
      "Epoch 788/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0296 - mean_squared_error: 0.0029 - val_loss: 0.0882 - val_mean_squared_error: 0.0615\n",
      "Epoch 789/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0291 - mean_squared_error: 0.0025 - val_loss: 0.0877 - val_mean_squared_error: 0.0612\n",
      "Epoch 790/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0290 - mean_squared_error: 0.0025 - val_loss: 0.0908 - val_mean_squared_error: 0.0643\n",
      "Epoch 791/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0300 - mean_squared_error: 0.0034 - val_loss: 0.0895 - val_mean_squared_error: 0.0630\n",
      "Epoch 792/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0294 - mean_squared_error: 0.0029 - val_loss: 0.0883 - val_mean_squared_error: 0.0618\n",
      "Epoch 793/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0292 - mean_squared_error: 0.0027 - val_loss: 0.0882 - val_mean_squared_error: 0.0618\n",
      "Epoch 794/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0287 - mean_squared_error: 0.0023 - val_loss: 0.0885 - val_mean_squared_error: 0.0622\n",
      "Epoch 795/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0287 - mean_squared_error: 0.0024 - val_loss: 0.0886 - val_mean_squared_error: 0.0623\n",
      "Epoch 796/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0287 - mean_squared_error: 0.0025 - val_loss: 0.0883 - val_mean_squared_error: 0.0620\n",
      "Epoch 797/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0287 - mean_squared_error: 0.0025 - val_loss: 0.0882 - val_mean_squared_error: 0.0620\n",
      "Epoch 798/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0286 - mean_squared_error: 0.0024 - val_loss: 0.0877 - val_mean_squared_error: 0.0615\n",
      "Epoch 799/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0283 - mean_squared_error: 0.0021 - val_loss: 0.0876 - val_mean_squared_error: 0.0615\n",
      "Epoch 800/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0283 - mean_squared_error: 0.0022 - val_loss: 0.0875 - val_mean_squared_error: 0.0614\n",
      "Epoch 801/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0284 - mean_squared_error: 0.0023 - val_loss: 0.0875 - val_mean_squared_error: 0.0615\n",
      "Epoch 802/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0283 - mean_squared_error: 0.0023 - val_loss: 0.0875 - val_mean_squared_error: 0.0614\n",
      "Epoch 803/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0284 - mean_squared_error: 0.0024 - val_loss: 0.0880 - val_mean_squared_error: 0.0620\n",
      "Epoch 804/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0285 - mean_squared_error: 0.0025 - val_loss: 0.0883 - val_mean_squared_error: 0.0623\n",
      "Epoch 805/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0290 - mean_squared_error: 0.0030 - val_loss: 0.0883 - val_mean_squared_error: 0.0623\n",
      "Epoch 806/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0285 - mean_squared_error: 0.0025 - val_loss: 0.0876 - val_mean_squared_error: 0.0617\n",
      "Epoch 807/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0283 - mean_squared_error: 0.0024 - val_loss: 0.0880 - val_mean_squared_error: 0.0622\n",
      "Epoch 808/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0281 - mean_squared_error: 0.0023 - val_loss: 0.0869 - val_mean_squared_error: 0.0611\n",
      "Epoch 809/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0280 - mean_squared_error: 0.0022 - val_loss: 0.0877 - val_mean_squared_error: 0.0620\n",
      "Epoch 810/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0284 - mean_squared_error: 0.0026 - val_loss: 0.0878 - val_mean_squared_error: 0.0621\n",
      "Epoch 811/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0297 - mean_squared_error: 0.0039 - val_loss: 0.0874 - val_mean_squared_error: 0.0615\n",
      "Epoch 812/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0284 - mean_squared_error: 0.0026 - val_loss: 0.0869 - val_mean_squared_error: 0.0612\n",
      "Epoch 813/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0280 - mean_squared_error: 0.0023 - val_loss: 0.0874 - val_mean_squared_error: 0.0617\n",
      "Epoch 814/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0281 - mean_squared_error: 0.0025 - val_loss: 0.0878 - val_mean_squared_error: 0.0622\n",
      "Epoch 815/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0283 - mean_squared_error: 0.0027 - val_loss: 0.0879 - val_mean_squared_error: 0.0623\n",
      "Epoch 816/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0279 - mean_squared_error: 0.0024 - val_loss: 0.0877 - val_mean_squared_error: 0.0622\n",
      "Epoch 817/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0282 - mean_squared_error: 0.0027 - val_loss: 0.0871 - val_mean_squared_error: 0.0616\n",
      "Epoch 818/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0278 - mean_squared_error: 0.0023 - val_loss: 0.0875 - val_mean_squared_error: 0.0621\n",
      "Epoch 819/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0278 - mean_squared_error: 0.0024 - val_loss: 0.0870 - val_mean_squared_error: 0.0616\n",
      "Epoch 820/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0276 - mean_squared_error: 0.0022 - val_loss: 0.0873 - val_mean_squared_error: 0.0619\n",
      "Epoch 821/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0279 - mean_squared_error: 0.0025 - val_loss: 0.0870 - val_mean_squared_error: 0.0617\n",
      "Epoch 822/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0278 - mean_squared_error: 0.0025 - val_loss: 0.0875 - val_mean_squared_error: 0.0622\n",
      "Epoch 823/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0278 - mean_squared_error: 0.0025 - val_loss: 0.0873 - val_mean_squared_error: 0.0620\n",
      "Epoch 824/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0283 - mean_squared_error: 0.0029 - val_loss: 0.0868 - val_mean_squared_error: 0.0615\n",
      "Epoch 825/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0278 - mean_squared_error: 0.0025 - val_loss: 0.0872 - val_mean_squared_error: 0.0619\n",
      "Epoch 826/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0277 - mean_squared_error: 0.0025 - val_loss: 0.0874 - val_mean_squared_error: 0.0622\n",
      "Epoch 827/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0273 - mean_squared_error: 0.0022 - val_loss: 0.0866 - val_mean_squared_error: 0.0615\n",
      "Epoch 828/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0274 - mean_squared_error: 0.0023 - val_loss: 0.0873 - val_mean_squared_error: 0.0622\n",
      "Epoch 829/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0276 - mean_squared_error: 0.0025 - val_loss: 0.0867 - val_mean_squared_error: 0.0617\n",
      "Epoch 830/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0276 - mean_squared_error: 0.0025 - val_loss: 0.0872 - val_mean_squared_error: 0.0622\n",
      "Epoch 831/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.0277 - mean_squared_error: 0.0026 - val_loss: 0.0865 - val_mean_squared_error: 0.0614\n",
      "Epoch 832/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0272 - mean_squared_error: 0.0022 - val_loss: 0.0865 - val_mean_squared_error: 0.0616\n",
      "Epoch 833/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0270 - mean_squared_error: 0.0021 - val_loss: 0.0864 - val_mean_squared_error: 0.0615\n",
      "Epoch 834/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0272 - mean_squared_error: 0.0023 - val_loss: 0.0883 - val_mean_squared_error: 0.0634\n",
      "Epoch 835/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0277 - mean_squared_error: 0.0028 - val_loss: 0.0884 - val_mean_squared_error: 0.0634\n",
      "Epoch 836/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0281 - mean_squared_error: 0.0031 - val_loss: 0.0874 - val_mean_squared_error: 0.0624\n",
      "Epoch 837/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0272 - mean_squared_error: 0.0023 - val_loss: 0.0870 - val_mean_squared_error: 0.0621\n",
      "Epoch 838/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0269 - mean_squared_error: 0.0021 - val_loss: 0.0863 - val_mean_squared_error: 0.0615\n",
      "Epoch 839/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0274 - mean_squared_error: 0.0026 - val_loss: 0.0861 - val_mean_squared_error: 0.0613\n",
      "Epoch 840/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0273 - mean_squared_error: 0.0025 - val_loss: 0.0870 - val_mean_squared_error: 0.0622\n",
      "Epoch 841/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0270 - mean_squared_error: 0.0023 - val_loss: 0.0863 - val_mean_squared_error: 0.0616\n",
      "Epoch 842/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0271 - mean_squared_error: 0.0025 - val_loss: 0.0865 - val_mean_squared_error: 0.0618\n",
      "Epoch 843/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0275 - mean_squared_error: 0.0028 - val_loss: 0.0876 - val_mean_squared_error: 0.0629\n",
      "Epoch 844/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0272 - mean_squared_error: 0.0025 - val_loss: 0.0866 - val_mean_squared_error: 0.0620\n",
      "Epoch 845/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0268 - mean_squared_error: 0.0022 - val_loss: 0.0857 - val_mean_squared_error: 0.0612\n",
      "Epoch 846/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0268 - mean_squared_error: 0.0023 - val_loss: 0.0860 - val_mean_squared_error: 0.0615\n",
      "Epoch 847/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0267 - mean_squared_error: 0.0022 - val_loss: 0.0860 - val_mean_squared_error: 0.0616\n",
      "Epoch 848/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0265 - mean_squared_error: 0.0021 - val_loss: 0.0862 - val_mean_squared_error: 0.0618\n",
      "Epoch 849/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0268 - mean_squared_error: 0.0024 - val_loss: 0.0863 - val_mean_squared_error: 0.0619\n",
      "Epoch 850/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0272 - mean_squared_error: 0.0027 - val_loss: 0.0867 - val_mean_squared_error: 0.0623\n",
      "Epoch 851/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0270 - mean_squared_error: 0.0026 - val_loss: 0.0868 - val_mean_squared_error: 0.0624\n",
      "Epoch 852/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0268 - mean_squared_error: 0.0024 - val_loss: 0.0857 - val_mean_squared_error: 0.0614\n",
      "Epoch 853/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0267 - mean_squared_error: 0.0024 - val_loss: 0.0865 - val_mean_squared_error: 0.0621\n",
      "Epoch 854/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0270 - mean_squared_error: 0.0027 - val_loss: 0.0861 - val_mean_squared_error: 0.0618\n",
      "Epoch 855/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0266 - mean_squared_error: 0.0023 - val_loss: 0.0861 - val_mean_squared_error: 0.0619\n",
      "Epoch 856/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0263 - mean_squared_error: 0.0021 - val_loss: 0.0856 - val_mean_squared_error: 0.0614\n",
      "Epoch 857/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0263 - mean_squared_error: 0.0021 - val_loss: 0.0858 - val_mean_squared_error: 0.0617\n",
      "Epoch 858/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0263 - mean_squared_error: 0.0022 - val_loss: 0.0853 - val_mean_squared_error: 0.0611\n",
      "Epoch 859/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0271 - mean_squared_error: 0.0029 - val_loss: 0.0866 - val_mean_squared_error: 0.0624\n",
      "Epoch 860/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0272 - mean_squared_error: 0.0030 - val_loss: 0.0857 - val_mean_squared_error: 0.0615\n",
      "Epoch 861/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0265 - mean_squared_error: 0.0024 - val_loss: 0.0857 - val_mean_squared_error: 0.0617\n",
      "Epoch 862/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0270 - mean_squared_error: 0.0029 - val_loss: 0.0857 - val_mean_squared_error: 0.0616\n",
      "Epoch 863/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0265 - mean_squared_error: 0.0025 - val_loss: 0.0851 - val_mean_squared_error: 0.0611\n",
      "Epoch 864/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0263 - mean_squared_error: 0.0023 - val_loss: 0.0860 - val_mean_squared_error: 0.0620\n",
      "Epoch 865/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0262 - mean_squared_error: 0.0023 - val_loss: 0.0861 - val_mean_squared_error: 0.0622\n",
      "Epoch 866/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0264 - mean_squared_error: 0.0025 - val_loss: 0.0874 - val_mean_squared_error: 0.0635\n",
      "Epoch 867/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0269 - mean_squared_error: 0.0030 - val_loss: 0.0857 - val_mean_squared_error: 0.0618\n",
      "Epoch 868/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0264 - mean_squared_error: 0.0025 - val_loss: 0.0858 - val_mean_squared_error: 0.0619\n",
      "Epoch 869/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0263 - mean_squared_error: 0.0024 - val_loss: 0.0856 - val_mean_squared_error: 0.0618\n",
      "Epoch 870/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0261 - mean_squared_error: 0.0023 - val_loss: 0.0872 - val_mean_squared_error: 0.0634\n",
      "Epoch 871/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0265 - mean_squared_error: 0.0027 - val_loss: 0.0856 - val_mean_squared_error: 0.0619\n",
      "Epoch 872/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0264 - mean_squared_error: 0.0026 - val_loss: 0.0850 - val_mean_squared_error: 0.0613\n",
      "Epoch 873/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0260 - mean_squared_error: 0.0023 - val_loss: 0.0855 - val_mean_squared_error: 0.0618\n",
      "Epoch 874/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0258 - mean_squared_error: 0.0022 - val_loss: 0.0851 - val_mean_squared_error: 0.0614\n",
      "Epoch 875/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0259 - mean_squared_error: 0.0023 - val_loss: 0.0851 - val_mean_squared_error: 0.0614\n",
      "Epoch 876/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0259 - mean_squared_error: 0.0023 - val_loss: 0.0853 - val_mean_squared_error: 0.0617\n",
      "Epoch 877/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0262 - mean_squared_error: 0.0026 - val_loss: 0.0887 - val_mean_squared_error: 0.0651\n",
      "Epoch 878/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0276 - mean_squared_error: 0.0039 - val_loss: 0.0859 - val_mean_squared_error: 0.0622\n",
      "Epoch 879/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.0854 - val_mean_squared_error: 0.0618\n",
      "Epoch 880/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0257 - mean_squared_error: 0.0022 - val_loss: 0.0850 - val_mean_squared_error: 0.0615\n",
      "Epoch 881/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0254 - mean_squared_error: 0.0020 - val_loss: 0.0852 - val_mean_squared_error: 0.0617\n",
      "Epoch 882/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0255 - mean_squared_error: 0.0021 - val_loss: 0.0858 - val_mean_squared_error: 0.0624\n",
      "Epoch 883/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0255 - mean_squared_error: 0.0022 - val_loss: 0.0847 - val_mean_squared_error: 0.0614\n",
      "Epoch 884/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0259 - mean_squared_error: 0.0025 - val_loss: 0.0848 - val_mean_squared_error: 0.0614\n",
      "Epoch 885/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0257 - mean_squared_error: 0.0023 - val_loss: 0.0858 - val_mean_squared_error: 0.0624\n",
      "Epoch 886/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0254 - mean_squared_error: 0.0021 - val_loss: 0.0846 - val_mean_squared_error: 0.0614\n",
      "Epoch 887/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0253 - mean_squared_error: 0.0021 - val_loss: 0.0844 - val_mean_squared_error: 0.0611\n",
      "Epoch 888/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0256 - mean_squared_error: 0.0024 - val_loss: 0.0860 - val_mean_squared_error: 0.0627\n",
      "Epoch 889/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0257 - mean_squared_error: 0.0024 - val_loss: 0.0856 - val_mean_squared_error: 0.0624\n",
      "Epoch 890/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0257 - mean_squared_error: 0.0024 - val_loss: 0.0854 - val_mean_squared_error: 0.0622\n",
      "Epoch 891/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0256 - mean_squared_error: 0.0024 - val_loss: 0.0842 - val_mean_squared_error: 0.0610\n",
      "Epoch 892/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0262 - mean_squared_error: 0.0030 - val_loss: 0.0852 - val_mean_squared_error: 0.0620\n",
      "Epoch 893/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0266 - mean_squared_error: 0.0033 - val_loss: 0.0847 - val_mean_squared_error: 0.0614\n",
      "Epoch 894/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0258 - mean_squared_error: 0.0026 - val_loss: 0.0840 - val_mean_squared_error: 0.0608\n",
      "Epoch 895/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0254 - mean_squared_error: 0.0023 - val_loss: 0.0844 - val_mean_squared_error: 0.0613\n",
      "Epoch 896/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0252 - mean_squared_error: 0.0021 - val_loss: 0.0847 - val_mean_squared_error: 0.0616\n",
      "Epoch 897/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0255 - mean_squared_error: 0.0024 - val_loss: 0.0841 - val_mean_squared_error: 0.0610\n",
      "Epoch 898/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0252 - mean_squared_error: 0.0022 - val_loss: 0.0845 - val_mean_squared_error: 0.0615\n",
      "Epoch 899/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0253 - mean_squared_error: 0.0023 - val_loss: 0.0845 - val_mean_squared_error: 0.0616\n",
      "Epoch 900/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0251 - mean_squared_error: 0.0022 - val_loss: 0.0849 - val_mean_squared_error: 0.0620\n",
      "Epoch 901/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0252 - mean_squared_error: 0.0023 - val_loss: 0.0857 - val_mean_squared_error: 0.0628\n",
      "Epoch 902/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0259 - mean_squared_error: 0.0029 - val_loss: 0.0850 - val_mean_squared_error: 0.0621\n",
      "Epoch 903/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0253 - mean_squared_error: 0.0024 - val_loss: 0.0844 - val_mean_squared_error: 0.0615\n",
      "Epoch 904/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0254 - mean_squared_error: 0.0026 - val_loss: 0.0846 - val_mean_squared_error: 0.0617\n",
      "Epoch 905/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0256 - mean_squared_error: 0.0028 - val_loss: 0.0851 - val_mean_squared_error: 0.0623\n",
      "Epoch 906/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0255 - mean_squared_error: 0.0026 - val_loss: 0.0851 - val_mean_squared_error: 0.0623\n",
      "Epoch 907/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0250 - mean_squared_error: 0.0023 - val_loss: 0.0847 - val_mean_squared_error: 0.0620\n",
      "Epoch 908/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0251 - mean_squared_error: 0.0024 - val_loss: 0.0844 - val_mean_squared_error: 0.0617\n",
      "Epoch 909/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0249 - mean_squared_error: 0.0022 - val_loss: 0.0847 - val_mean_squared_error: 0.0620\n",
      "Epoch 910/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0252 - mean_squared_error: 0.0025 - val_loss: 0.0849 - val_mean_squared_error: 0.0622\n",
      "Epoch 911/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0249 - mean_squared_error: 0.0022 - val_loss: 0.0845 - val_mean_squared_error: 0.0619\n",
      "Epoch 912/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0249 - mean_squared_error: 0.0023 - val_loss: 0.0866 - val_mean_squared_error: 0.0640\n",
      "Epoch 913/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0253 - mean_squared_error: 0.0026 - val_loss: 0.0849 - val_mean_squared_error: 0.0623\n",
      "Epoch 914/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0249 - mean_squared_error: 0.0023 - val_loss: 0.0847 - val_mean_squared_error: 0.0621\n",
      "Epoch 915/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0248 - mean_squared_error: 0.0023 - val_loss: 0.0849 - val_mean_squared_error: 0.0624\n",
      "Epoch 916/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0256 - mean_squared_error: 0.0030 - val_loss: 0.0847 - val_mean_squared_error: 0.0621\n",
      "Epoch 917/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0249 - mean_squared_error: 0.0024 - val_loss: 0.0843 - val_mean_squared_error: 0.0618\n",
      "Epoch 918/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0245 - mean_squared_error: 0.0021 - val_loss: 0.0842 - val_mean_squared_error: 0.0618\n",
      "Epoch 919/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0250 - mean_squared_error: 0.0026 - val_loss: 0.0850 - val_mean_squared_error: 0.0625\n",
      "Epoch 920/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0248 - mean_squared_error: 0.0024 - val_loss: 0.0847 - val_mean_squared_error: 0.0623\n",
      "Epoch 921/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0246 - mean_squared_error: 0.0022 - val_loss: 0.0846 - val_mean_squared_error: 0.0622\n",
      "Epoch 922/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0245 - mean_squared_error: 0.0022 - val_loss: 0.0847 - val_mean_squared_error: 0.0624\n",
      "Epoch 923/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0248 - mean_squared_error: 0.0025 - val_loss: 0.0836 - val_mean_squared_error: 0.0613\n",
      "Epoch 924/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0245 - mean_squared_error: 0.0022 - val_loss: 0.0838 - val_mean_squared_error: 0.0616\n",
      "Epoch 925/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0246 - mean_squared_error: 0.0023 - val_loss: 0.0837 - val_mean_squared_error: 0.0615\n",
      "Epoch 926/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0245 - mean_squared_error: 0.0023 - val_loss: 0.0835 - val_mean_squared_error: 0.0613\n",
      "Epoch 927/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0251 - mean_squared_error: 0.0029 - val_loss: 0.0843 - val_mean_squared_error: 0.0620\n",
      "Epoch 928/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0252 - mean_squared_error: 0.0029 - val_loss: 0.0836 - val_mean_squared_error: 0.0613\n",
      "Epoch 929/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0246 - mean_squared_error: 0.0024 - val_loss: 0.0842 - val_mean_squared_error: 0.0620\n",
      "Epoch 930/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0245 - mean_squared_error: 0.0023 - val_loss: 0.0836 - val_mean_squared_error: 0.0614\n",
      "Epoch 931/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0242 - mean_squared_error: 0.0021 - val_loss: 0.0839 - val_mean_squared_error: 0.0619\n",
      "Epoch 932/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0241 - mean_squared_error: 0.0021 - val_loss: 0.0835 - val_mean_squared_error: 0.0615\n",
      "Epoch 933/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0242 - mean_squared_error: 0.0022 - val_loss: 0.0841 - val_mean_squared_error: 0.0620\n",
      "Epoch 934/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0246 - mean_squared_error: 0.0026 - val_loss: 0.0867 - val_mean_squared_error: 0.0647\n",
      "Epoch 935/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0248 - mean_squared_error: 0.0028 - val_loss: 0.0835 - val_mean_squared_error: 0.0614\n",
      "Epoch 936/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0244 - mean_squared_error: 0.0024 - val_loss: 0.0841 - val_mean_squared_error: 0.0621\n",
      "Epoch 937/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0241 - mean_squared_error: 0.0021 - val_loss: 0.0835 - val_mean_squared_error: 0.0616\n",
      "Epoch 938/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0240 - mean_squared_error: 0.0021 - val_loss: 0.0836 - val_mean_squared_error: 0.0617\n",
      "Epoch 939/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0244 - mean_squared_error: 0.0025 - val_loss: 0.0837 - val_mean_squared_error: 0.0618\n",
      "Epoch 940/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0243 - mean_squared_error: 0.0024 - val_loss: 0.0836 - val_mean_squared_error: 0.0617\n",
      "Epoch 941/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0244 - mean_squared_error: 0.0026 - val_loss: 0.0840 - val_mean_squared_error: 0.0621\n",
      "Epoch 942/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0246 - mean_squared_error: 0.0027 - val_loss: 0.0834 - val_mean_squared_error: 0.0615\n",
      "Epoch 943/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0241 - mean_squared_error: 0.0023 - val_loss: 0.0837 - val_mean_squared_error: 0.0619\n",
      "Epoch 944/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0245 - mean_squared_error: 0.0027 - val_loss: 0.0839 - val_mean_squared_error: 0.0621\n",
      "Epoch 945/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0246 - mean_squared_error: 0.0027 - val_loss: 0.0834 - val_mean_squared_error: 0.0616\n",
      "Epoch 946/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0246 - mean_squared_error: 0.0028 - val_loss: 0.0839 - val_mean_squared_error: 0.0621\n",
      "Epoch 947/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0244 - mean_squared_error: 0.0026 - val_loss: 0.0825 - val_mean_squared_error: 0.0608\n",
      "Epoch 948/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0237 - mean_squared_error: 0.0020 - val_loss: 0.0828 - val_mean_squared_error: 0.0611\n",
      "Epoch 949/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0240 - mean_squared_error: 0.0024 - val_loss: 0.0828 - val_mean_squared_error: 0.0611\n",
      "Epoch 950/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0240 - mean_squared_error: 0.0023 - val_loss: 0.0832 - val_mean_squared_error: 0.0616\n",
      "Epoch 951/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0238 - mean_squared_error: 0.0022 - val_loss: 0.0833 - val_mean_squared_error: 0.0617\n",
      "Epoch 952/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0236 - mean_squared_error: 0.0021 - val_loss: 0.0828 - val_mean_squared_error: 0.0613\n",
      "Epoch 953/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0239 - mean_squared_error: 0.0024 - val_loss: 0.0842 - val_mean_squared_error: 0.0626\n",
      "Epoch 954/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0241 - mean_squared_error: 0.0026 - val_loss: 0.0824 - val_mean_squared_error: 0.0608\n",
      "Epoch 955/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0239 - mean_squared_error: 0.0024 - val_loss: 0.0839 - val_mean_squared_error: 0.0623\n",
      "Epoch 956/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0244 - mean_squared_error: 0.0029 - val_loss: 0.0833 - val_mean_squared_error: 0.0618\n",
      "Epoch 957/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0238 - mean_squared_error: 0.0023 - val_loss: 0.0834 - val_mean_squared_error: 0.0620\n",
      "Epoch 958/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0237 - mean_squared_error: 0.0022 - val_loss: 0.0832 - val_mean_squared_error: 0.0618\n",
      "Epoch 959/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0237 - mean_squared_error: 0.0023 - val_loss: 0.0829 - val_mean_squared_error: 0.0615\n",
      "Epoch 960/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0235 - mean_squared_error: 0.0021 - val_loss: 0.0830 - val_mean_squared_error: 0.0616\n",
      "Epoch 961/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0239 - mean_squared_error: 0.0025 - val_loss: 0.0832 - val_mean_squared_error: 0.0618\n",
      "Epoch 962/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0239 - mean_squared_error: 0.0025 - val_loss: 0.0835 - val_mean_squared_error: 0.0621\n",
      "Epoch 963/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0236 - mean_squared_error: 0.0022 - val_loss: 0.0827 - val_mean_squared_error: 0.0614\n",
      "Epoch 964/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0234 - mean_squared_error: 0.0021 - val_loss: 0.0822 - val_mean_squared_error: 0.0609\n",
      "Epoch 965/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0233 - mean_squared_error: 0.0021 - val_loss: 0.0825 - val_mean_squared_error: 0.0613\n",
      "Epoch 966/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0235 - mean_squared_error: 0.0022 - val_loss: 0.0825 - val_mean_squared_error: 0.0613\n",
      "Epoch 967/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0234 - mean_squared_error: 0.0022 - val_loss: 0.0826 - val_mean_squared_error: 0.0614\n",
      "Epoch 968/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0236 - mean_squared_error: 0.0024 - val_loss: 0.0834 - val_mean_squared_error: 0.0622\n",
      "Epoch 969/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0236 - mean_squared_error: 0.0024 - val_loss: 0.0832 - val_mean_squared_error: 0.0621\n",
      "Epoch 970/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0238 - mean_squared_error: 0.0026 - val_loss: 0.0825 - val_mean_squared_error: 0.0613\n",
      "Epoch 971/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0237 - mean_squared_error: 0.0026 - val_loss: 0.0836 - val_mean_squared_error: 0.0625\n",
      "Epoch 972/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0239 - mean_squared_error: 0.0027 - val_loss: 0.0825 - val_mean_squared_error: 0.0614\n",
      "Epoch 973/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0233 - mean_squared_error: 0.0022 - val_loss: 0.0828 - val_mean_squared_error: 0.0617\n",
      "Epoch 974/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0234 - mean_squared_error: 0.0024 - val_loss: 0.0813 - val_mean_squared_error: 0.0602\n",
      "Epoch 975/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0234 - mean_squared_error: 0.0024 - val_loss: 0.0837 - val_mean_squared_error: 0.0627\n",
      "Epoch 976/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0237 - mean_squared_error: 0.0027 - val_loss: 0.0820 - val_mean_squared_error: 0.0610\n",
      "Epoch 977/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0232 - mean_squared_error: 0.0023 - val_loss: 0.0824 - val_mean_squared_error: 0.0615\n",
      "Epoch 978/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0230 - mean_squared_error: 0.0020 - val_loss: 0.0824 - val_mean_squared_error: 0.0615\n",
      "Epoch 979/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0231 - mean_squared_error: 0.0022 - val_loss: 0.0829 - val_mean_squared_error: 0.0621\n",
      "Epoch 980/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0236 - mean_squared_error: 0.0027 - val_loss: 0.0831 - val_mean_squared_error: 0.0622\n",
      "Epoch 981/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0234 - mean_squared_error: 0.0024 - val_loss: 0.0830 - val_mean_squared_error: 0.0621\n",
      "Epoch 982/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0231 - mean_squared_error: 0.0022 - val_loss: 0.0825 - val_mean_squared_error: 0.0617\n",
      "Epoch 983/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0229 - mean_squared_error: 0.0021 - val_loss: 0.0826 - val_mean_squared_error: 0.0618\n",
      "Epoch 984/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0229 - mean_squared_error: 0.0022 - val_loss: 0.0822 - val_mean_squared_error: 0.0614\n",
      "Epoch 985/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0229 - mean_squared_error: 0.0022 - val_loss: 0.0828 - val_mean_squared_error: 0.0621\n",
      "Epoch 986/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0232 - mean_squared_error: 0.0024 - val_loss: 0.0828 - val_mean_squared_error: 0.0621\n",
      "Epoch 987/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0229 - mean_squared_error: 0.0022 - val_loss: 0.0830 - val_mean_squared_error: 0.0623\n",
      "Epoch 988/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0232 - mean_squared_error: 0.0025 - val_loss: 0.0825 - val_mean_squared_error: 0.0618\n",
      "Epoch 989/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0229 - mean_squared_error: 0.0022 - val_loss: 0.0827 - val_mean_squared_error: 0.0621\n",
      "Epoch 990/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0229 - mean_squared_error: 0.0022 - val_loss: 0.0821 - val_mean_squared_error: 0.0615\n",
      "Epoch 991/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0226 - mean_squared_error: 0.0020 - val_loss: 0.0827 - val_mean_squared_error: 0.0621\n",
      "Epoch 992/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0225 - mean_squared_error: 0.0019 - val_loss: 0.0821 - val_mean_squared_error: 0.0616\n",
      "Epoch 993/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0228 - mean_squared_error: 0.0023 - val_loss: 0.0823 - val_mean_squared_error: 0.0617\n",
      "Epoch 994/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0229 - mean_squared_error: 0.0023 - val_loss: 0.0823 - val_mean_squared_error: 0.0618\n",
      "Epoch 995/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0228 - mean_squared_error: 0.0022 - val_loss: 0.0828 - val_mean_squared_error: 0.0622\n",
      "Epoch 996/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0232 - mean_squared_error: 0.0027 - val_loss: 0.0828 - val_mean_squared_error: 0.0622\n",
      "Epoch 997/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0231 - mean_squared_error: 0.0026 - val_loss: 0.0828 - val_mean_squared_error: 0.0623\n",
      "Epoch 998/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0230 - mean_squared_error: 0.0025 - val_loss: 0.0826 - val_mean_squared_error: 0.0621\n",
      "Epoch 999/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0226 - mean_squared_error: 0.0021 - val_loss: 0.0823 - val_mean_squared_error: 0.0618\n",
      "Epoch 1000/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0230 - mean_squared_error: 0.0026 - val_loss: 0.0814 - val_mean_squared_error: 0.0609\n",
      "Epoch 1001/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0228 - mean_squared_error: 0.0024 - val_loss: 0.0828 - val_mean_squared_error: 0.0623\n",
      "Epoch 1002/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0227 - mean_squared_error: 0.0023 - val_loss: 0.0820 - val_mean_squared_error: 0.0616\n",
      "Epoch 1003/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0226 - mean_squared_error: 0.0022 - val_loss: 0.0816 - val_mean_squared_error: 0.0612\n",
      "Epoch 1004/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0227 - mean_squared_error: 0.0023 - val_loss: 0.0828 - val_mean_squared_error: 0.0624\n",
      "Epoch 1005/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0235 - mean_squared_error: 0.0031 - val_loss: 0.0827 - val_mean_squared_error: 0.0623\n",
      "Epoch 1006/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0228 - mean_squared_error: 0.0024 - val_loss: 0.0816 - val_mean_squared_error: 0.0613\n",
      "Epoch 1007/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0224 - mean_squared_error: 0.0021 - val_loss: 0.0819 - val_mean_squared_error: 0.0616\n",
      "Epoch 1008/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0228 - mean_squared_error: 0.0025 - val_loss: 0.0815 - val_mean_squared_error: 0.0612\n",
      "Epoch 1009/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0226 - mean_squared_error: 0.0024 - val_loss: 0.0815 - val_mean_squared_error: 0.0612\n",
      "Epoch 1010/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0224 - mean_squared_error: 0.0022 - val_loss: 0.0823 - val_mean_squared_error: 0.0621\n",
      "Epoch 1011/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0222 - mean_squared_error: 0.0021 - val_loss: 0.0815 - val_mean_squared_error: 0.0613\n",
      "Epoch 1012/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0223 - mean_squared_error: 0.0022 - val_loss: 0.0815 - val_mean_squared_error: 0.0613\n",
      "Epoch 1013/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0225 - mean_squared_error: 0.0023 - val_loss: 0.0823 - val_mean_squared_error: 0.0621\n",
      "Epoch 1014/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0222 - mean_squared_error: 0.0021 - val_loss: 0.0813 - val_mean_squared_error: 0.0612\n",
      "Epoch 1015/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0224 - mean_squared_error: 0.0023 - val_loss: 0.0827 - val_mean_squared_error: 0.0626\n",
      "Epoch 1016/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0223 - mean_squared_error: 0.0022 - val_loss: 0.0821 - val_mean_squared_error: 0.0620\n",
      "Epoch 1017/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0223 - mean_squared_error: 0.0022 - val_loss: 0.0814 - val_mean_squared_error: 0.0613\n",
      "Epoch 1018/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0231 - mean_squared_error: 0.0031 - val_loss: 0.0821 - val_mean_squared_error: 0.0619\n",
      "Epoch 1019/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0229 - mean_squared_error: 0.0027 - val_loss: 0.0819 - val_mean_squared_error: 0.0618\n",
      "Epoch 1020/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0226 - mean_squared_error: 0.0025 - val_loss: 0.0815 - val_mean_squared_error: 0.0614\n",
      "Epoch 1021/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0223 - mean_squared_error: 0.0023 - val_loss: 0.0816 - val_mean_squared_error: 0.0615\n",
      "Epoch 1022/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0222 - mean_squared_error: 0.0022 - val_loss: 0.0818 - val_mean_squared_error: 0.0618\n",
      "Epoch 1023/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0222 - mean_squared_error: 0.0022 - val_loss: 0.0808 - val_mean_squared_error: 0.0609\n",
      "Epoch 1024/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0226 - mean_squared_error: 0.0026 - val_loss: 0.0808 - val_mean_squared_error: 0.0608\n",
      "Epoch 1025/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0230 - mean_squared_error: 0.0029 - val_loss: 0.0813 - val_mean_squared_error: 0.0613\n",
      "Epoch 1026/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0228 - mean_squared_error: 0.0028 - val_loss: 0.0814 - val_mean_squared_error: 0.0614\n",
      "Epoch 1027/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0225 - mean_squared_error: 0.0025 - val_loss: 0.0813 - val_mean_squared_error: 0.0613\n",
      "Epoch 1028/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0222 - mean_squared_error: 0.0023 - val_loss: 0.0816 - val_mean_squared_error: 0.0617\n",
      "Epoch 1029/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0222 - mean_squared_error: 0.0024 - val_loss: 0.0815 - val_mean_squared_error: 0.0616\n",
      "Epoch 1030/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0227 - mean_squared_error: 0.0028 - val_loss: 0.0819 - val_mean_squared_error: 0.0620\n",
      "Epoch 1031/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0220 - mean_squared_error: 0.0021 - val_loss: 0.0809 - val_mean_squared_error: 0.0611\n",
      "Epoch 1032/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0218 - mean_squared_error: 0.0020 - val_loss: 0.0826 - val_mean_squared_error: 0.0629\n",
      "Epoch 1033/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0219 - mean_squared_error: 0.0021 - val_loss: 0.0810 - val_mean_squared_error: 0.0613\n",
      "Epoch 1034/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0225 - mean_squared_error: 0.0028 - val_loss: 0.0816 - val_mean_squared_error: 0.0618\n",
      "Epoch 1035/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0224 - mean_squared_error: 0.0026 - val_loss: 0.0814 - val_mean_squared_error: 0.0616\n",
      "Epoch 1036/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0219 - mean_squared_error: 0.0021 - val_loss: 0.0814 - val_mean_squared_error: 0.0617\n",
      "Epoch 1037/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0220 - mean_squared_error: 0.0023 - val_loss: 0.0815 - val_mean_squared_error: 0.0618\n",
      "Epoch 1038/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0218 - mean_squared_error: 0.0021 - val_loss: 0.0816 - val_mean_squared_error: 0.0620\n",
      "Epoch 1039/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0219 - mean_squared_error: 0.0023 - val_loss: 0.0824 - val_mean_squared_error: 0.0627\n",
      "Epoch 1040/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0225 - mean_squared_error: 0.0028 - val_loss: 0.0826 - val_mean_squared_error: 0.0629\n",
      "Epoch 1041/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0224 - mean_squared_error: 0.0027 - val_loss: 0.0828 - val_mean_squared_error: 0.0631\n",
      "Epoch 1042/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0222 - mean_squared_error: 0.0025 - val_loss: 0.0809 - val_mean_squared_error: 0.0612\n",
      "Epoch 1043/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0218 - mean_squared_error: 0.0022 - val_loss: 0.0814 - val_mean_squared_error: 0.0618\n",
      "Epoch 1044/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0218 - mean_squared_error: 0.0022 - val_loss: 0.0808 - val_mean_squared_error: 0.0612\n",
      "Epoch 1045/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0221 - mean_squared_error: 0.0025 - val_loss: 0.0812 - val_mean_squared_error: 0.0616\n",
      "Epoch 1046/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0214 - mean_squared_error: 0.0019 - val_loss: 0.0810 - val_mean_squared_error: 0.0615\n",
      "Epoch 1047/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0215 - mean_squared_error: 0.0020 - val_loss: 0.0808 - val_mean_squared_error: 0.0613\n",
      "Epoch 1048/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0217 - mean_squared_error: 0.0022 - val_loss: 0.0823 - val_mean_squared_error: 0.0628\n",
      "Epoch 1049/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0217 - mean_squared_error: 0.0022 - val_loss: 0.0813 - val_mean_squared_error: 0.0619\n",
      "Epoch 1050/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0220 - mean_squared_error: 0.0025 - val_loss: 0.0824 - val_mean_squared_error: 0.0629\n",
      "Epoch 1051/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0220 - mean_squared_error: 0.0026 - val_loss: 0.0816 - val_mean_squared_error: 0.0622\n",
      "Epoch 1052/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0219 - mean_squared_error: 0.0024 - val_loss: 0.0815 - val_mean_squared_error: 0.0621\n",
      "Epoch 1053/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0223 - mean_squared_error: 0.0028 - val_loss: 0.0808 - val_mean_squared_error: 0.0613\n",
      "Epoch 1054/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0218 - mean_squared_error: 0.0024 - val_loss: 0.0810 - val_mean_squared_error: 0.0616\n",
      "Epoch 1055/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0215 - mean_squared_error: 0.0021 - val_loss: 0.0810 - val_mean_squared_error: 0.0616\n",
      "Epoch 1056/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0212 - mean_squared_error: 0.0019 - val_loss: 0.0811 - val_mean_squared_error: 0.0618\n",
      "Epoch 1057/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0220 - mean_squared_error: 0.0027 - val_loss: 0.0805 - val_mean_squared_error: 0.0611\n",
      "Epoch 1058/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0217 - mean_squared_error: 0.0023 - val_loss: 0.0815 - val_mean_squared_error: 0.0621\n",
      "Epoch 1059/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0219 - mean_squared_error: 0.0026 - val_loss: 0.0813 - val_mean_squared_error: 0.0619\n",
      "Epoch 1060/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0222 - mean_squared_error: 0.0028 - val_loss: 0.0818 - val_mean_squared_error: 0.0625\n",
      "Epoch 1061/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0218 - mean_squared_error: 0.0025 - val_loss: 0.0813 - val_mean_squared_error: 0.0620\n",
      "Epoch 1062/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0213 - mean_squared_error: 0.0021 - val_loss: 0.0805 - val_mean_squared_error: 0.0613\n",
      "Epoch 1063/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0211 - mean_squared_error: 0.0019 - val_loss: 0.0807 - val_mean_squared_error: 0.0616\n",
      "Epoch 1064/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0214 - mean_squared_error: 0.0022 - val_loss: 0.0806 - val_mean_squared_error: 0.0614\n",
      "Epoch 1065/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0213 - mean_squared_error: 0.0021 - val_loss: 0.0806 - val_mean_squared_error: 0.0614\n",
      "Epoch 1066/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0213 - mean_squared_error: 0.0021 - val_loss: 0.0809 - val_mean_squared_error: 0.0617\n",
      "Epoch 1067/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0215 - mean_squared_error: 0.0024 - val_loss: 0.0805 - val_mean_squared_error: 0.0613\n",
      "Epoch 1068/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0214 - mean_squared_error: 0.0022 - val_loss: 0.0806 - val_mean_squared_error: 0.0615\n",
      "Epoch 1069/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0218 - mean_squared_error: 0.0026 - val_loss: 0.0812 - val_mean_squared_error: 0.0621\n",
      "Epoch 1070/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0214 - mean_squared_error: 0.0023 - val_loss: 0.0809 - val_mean_squared_error: 0.0618\n",
      "Epoch 1071/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0219 - mean_squared_error: 0.0027 - val_loss: 0.0810 - val_mean_squared_error: 0.0618\n",
      "Epoch 1072/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0220 - mean_squared_error: 0.0029 - val_loss: 0.0812 - val_mean_squared_error: 0.0621\n",
      "Epoch 1073/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0218 - mean_squared_error: 0.0026 - val_loss: 0.0814 - val_mean_squared_error: 0.0623\n",
      "Epoch 1074/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0216 - mean_squared_error: 0.0026 - val_loss: 0.0809 - val_mean_squared_error: 0.0618\n",
      "Epoch 1075/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0216 - mean_squared_error: 0.0025 - val_loss: 0.0811 - val_mean_squared_error: 0.0620\n",
      "Epoch 1076/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0213 - mean_squared_error: 0.0023 - val_loss: 0.0799 - val_mean_squared_error: 0.0609\n",
      "Epoch 1077/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0215 - mean_squared_error: 0.0025 - val_loss: 0.0809 - val_mean_squared_error: 0.0619\n",
      "Epoch 1078/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0211 - mean_squared_error: 0.0021 - val_loss: 0.0799 - val_mean_squared_error: 0.0609\n",
      "Epoch 1079/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0211 - mean_squared_error: 0.0022 - val_loss: 0.0804 - val_mean_squared_error: 0.0615\n",
      "Epoch 1080/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0209 - mean_squared_error: 0.0020 - val_loss: 0.0802 - val_mean_squared_error: 0.0613\n",
      "Epoch 1081/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0207 - mean_squared_error: 0.0019 - val_loss: 0.0811 - val_mean_squared_error: 0.0622\n",
      "Epoch 1082/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0214 - mean_squared_error: 0.0025 - val_loss: 0.0802 - val_mean_squared_error: 0.0613\n",
      "Epoch 1083/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0214 - mean_squared_error: 0.0024 - val_loss: 0.0814 - val_mean_squared_error: 0.0625\n",
      "Epoch 1084/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0209 - mean_squared_error: 0.0021 - val_loss: 0.0806 - val_mean_squared_error: 0.0617\n",
      "Epoch 1085/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0209 - mean_squared_error: 0.0021 - val_loss: 0.0804 - val_mean_squared_error: 0.0616\n",
      "Epoch 1086/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0210 - mean_squared_error: 0.0022 - val_loss: 0.0805 - val_mean_squared_error: 0.0617\n",
      "Epoch 1087/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0208 - mean_squared_error: 0.0020 - val_loss: 0.0816 - val_mean_squared_error: 0.0628\n",
      "Epoch 1088/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0214 - mean_squared_error: 0.0026 - val_loss: 0.0812 - val_mean_squared_error: 0.0624\n",
      "Epoch 1089/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0212 - mean_squared_error: 0.0024 - val_loss: 0.0807 - val_mean_squared_error: 0.0619\n",
      "Epoch 1090/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0209 - mean_squared_error: 0.0021 - val_loss: 0.0802 - val_mean_squared_error: 0.0615\n",
      "Epoch 1091/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0019 - val_loss: 0.0805 - val_mean_squared_error: 0.0618\n",
      "Epoch 1092/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0209 - mean_squared_error: 0.0022 - val_loss: 0.0813 - val_mean_squared_error: 0.0626\n",
      "Epoch 1093/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0212 - mean_squared_error: 0.0025 - val_loss: 0.0807 - val_mean_squared_error: 0.0620\n",
      "Epoch 1094/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0214 - mean_squared_error: 0.0027 - val_loss: 0.0805 - val_mean_squared_error: 0.0618\n",
      "Epoch 1095/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0215 - mean_squared_error: 0.0028 - val_loss: 0.0806 - val_mean_squared_error: 0.0619\n",
      "Epoch 1096/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0222 - mean_squared_error: 0.0034 - val_loss: 0.0805 - val_mean_squared_error: 0.0617\n",
      "Epoch 1097/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0213 - mean_squared_error: 0.0026 - val_loss: 0.0805 - val_mean_squared_error: 0.0617\n",
      "Epoch 1098/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0209 - mean_squared_error: 0.0022 - val_loss: 0.0799 - val_mean_squared_error: 0.0613\n",
      "Epoch 1099/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0019 - val_loss: 0.0802 - val_mean_squared_error: 0.0616\n",
      "Epoch 1100/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0204 - mean_squared_error: 0.0019 - val_loss: 0.0811 - val_mean_squared_error: 0.0626\n",
      "Epoch 1101/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0206 - mean_squared_error: 0.0020 - val_loss: 0.0800 - val_mean_squared_error: 0.0614\n",
      "Epoch 1102/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0206 - mean_squared_error: 0.0021 - val_loss: 0.0810 - val_mean_squared_error: 0.0624\n",
      "Epoch 1103/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0208 - mean_squared_error: 0.0023 - val_loss: 0.0803 - val_mean_squared_error: 0.0618\n",
      "Epoch 1104/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0020 - val_loss: 0.0805 - val_mean_squared_error: 0.0620\n",
      "Epoch 1105/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0021 - val_loss: 0.0808 - val_mean_squared_error: 0.0623\n",
      "Epoch 1106/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0208 - mean_squared_error: 0.0023 - val_loss: 0.0809 - val_mean_squared_error: 0.0624\n",
      "Epoch 1107/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0022 - val_loss: 0.0805 - val_mean_squared_error: 0.0621\n",
      "Epoch 1108/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0021 - val_loss: 0.0804 - val_mean_squared_error: 0.0619\n",
      "Epoch 1109/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0209 - mean_squared_error: 0.0025 - val_loss: 0.0796 - val_mean_squared_error: 0.0611\n",
      "Epoch 1110/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0206 - mean_squared_error: 0.0022 - val_loss: 0.0807 - val_mean_squared_error: 0.0623\n",
      "Epoch 1111/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0022 - val_loss: 0.0796 - val_mean_squared_error: 0.0612\n",
      "Epoch 1112/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0204 - mean_squared_error: 0.0020 - val_loss: 0.0809 - val_mean_squared_error: 0.0626\n",
      "Epoch 1113/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0021 - val_loss: 0.0817 - val_mean_squared_error: 0.0633\n",
      "Epoch 1114/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0207 - mean_squared_error: 0.0023 - val_loss: 0.0805 - val_mean_squared_error: 0.0622\n",
      "Epoch 1115/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0210 - mean_squared_error: 0.0026 - val_loss: 0.0800 - val_mean_squared_error: 0.0616\n",
      "Epoch 1116/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0207 - mean_squared_error: 0.0023 - val_loss: 0.0803 - val_mean_squared_error: 0.0619\n",
      "Epoch 1117/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0022 - val_loss: 0.0798 - val_mean_squared_error: 0.0615\n",
      "Epoch 1118/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0207 - mean_squared_error: 0.0024 - val_loss: 0.0800 - val_mean_squared_error: 0.0616\n",
      "Epoch 1119/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0210 - mean_squared_error: 0.0027 - val_loss: 0.0804 - val_mean_squared_error: 0.0621\n",
      "Epoch 1120/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0023 - val_loss: 0.0812 - val_mean_squared_error: 0.0629\n",
      "Epoch 1121/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0024 - val_loss: 0.0801 - val_mean_squared_error: 0.0618\n",
      "Epoch 1122/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0206 - mean_squared_error: 0.0024 - val_loss: 0.0797 - val_mean_squared_error: 0.0614\n",
      "Epoch 1123/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0203 - mean_squared_error: 0.0021 - val_loss: 0.0796 - val_mean_squared_error: 0.0614\n",
      "Epoch 1124/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0207 - mean_squared_error: 0.0025 - val_loss: 0.0798 - val_mean_squared_error: 0.0616\n",
      "Epoch 1125/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0204 - mean_squared_error: 0.0022 - val_loss: 0.0797 - val_mean_squared_error: 0.0615\n",
      "Epoch 1126/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0203 - mean_squared_error: 0.0021 - val_loss: 0.0802 - val_mean_squared_error: 0.0621\n",
      "Epoch 1127/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0204 - mean_squared_error: 0.0023 - val_loss: 0.0800 - val_mean_squared_error: 0.0618\n",
      "Epoch 1128/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.0203 - mean_squared_error: 0.0022 - val_loss: 0.0793 - val_mean_squared_error: 0.0612\n",
      "Epoch 1129/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0024 - val_loss: 0.0797 - val_mean_squared_error: 0.0616\n",
      "Epoch 1130/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0204 - mean_squared_error: 0.0023 - val_loss: 0.0803 - val_mean_squared_error: 0.0622\n",
      "Epoch 1131/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0202 - mean_squared_error: 0.0022 - val_loss: 0.0810 - val_mean_squared_error: 0.0629\n",
      "Epoch 1132/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0213 - mean_squared_error: 0.0032 - val_loss: 0.0808 - val_mean_squared_error: 0.0627\n",
      "Epoch 1133/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0208 - mean_squared_error: 0.0027 - val_loss: 0.0800 - val_mean_squared_error: 0.0619\n",
      "Epoch 1134/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0213 - mean_squared_error: 0.0032 - val_loss: 0.0796 - val_mean_squared_error: 0.0614\n",
      "Epoch 1135/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0024 - val_loss: 0.0796 - val_mean_squared_error: 0.0616\n",
      "Epoch 1136/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0025 - val_loss: 0.0799 - val_mean_squared_error: 0.0618\n",
      "Epoch 1137/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0203 - mean_squared_error: 0.0023 - val_loss: 0.0797 - val_mean_squared_error: 0.0617\n",
      "Epoch 1138/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0202 - mean_squared_error: 0.0023 - val_loss: 0.0814 - val_mean_squared_error: 0.0634\n",
      "Epoch 1139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0206 - mean_squared_error: 0.0026 - val_loss: 0.0787 - val_mean_squared_error: 0.0607\n",
      "Epoch 1140/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0204 - mean_squared_error: 0.0025 - val_loss: 0.0798 - val_mean_squared_error: 0.0618\n",
      "Epoch 1141/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0203 - mean_squared_error: 0.0023 - val_loss: 0.0788 - val_mean_squared_error: 0.0609\n",
      "Epoch 1142/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0199 - mean_squared_error: 0.0020 - val_loss: 0.0799 - val_mean_squared_error: 0.0620\n",
      "Epoch 1143/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0198 - mean_squared_error: 0.0019 - val_loss: 0.0796 - val_mean_squared_error: 0.0617\n",
      "Epoch 1144/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0198 - mean_squared_error: 0.0020 - val_loss: 0.0796 - val_mean_squared_error: 0.0617\n",
      "Epoch 1145/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0201 - mean_squared_error: 0.0023 - val_loss: 0.0812 - val_mean_squared_error: 0.0633\n",
      "Epoch 1146/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0202 - mean_squared_error: 0.0023 - val_loss: 0.0800 - val_mean_squared_error: 0.0622\n",
      "Epoch 1147/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0200 - mean_squared_error: 0.0022 - val_loss: 0.0795 - val_mean_squared_error: 0.0617\n",
      "Epoch 1148/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0201 - mean_squared_error: 0.0023 - val_loss: 0.0792 - val_mean_squared_error: 0.0614\n",
      "Epoch 1149/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0026 - val_loss: 0.0801 - val_mean_squared_error: 0.0622\n",
      "Epoch 1150/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0200 - mean_squared_error: 0.0022 - val_loss: 0.0802 - val_mean_squared_error: 0.0624\n",
      "Epoch 1151/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0199 - mean_squared_error: 0.0022 - val_loss: 0.0801 - val_mean_squared_error: 0.0623\n",
      "Epoch 1152/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0203 - mean_squared_error: 0.0025 - val_loss: 0.0791 - val_mean_squared_error: 0.0613\n",
      "Epoch 1153/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0202 - mean_squared_error: 0.0024 - val_loss: 0.0796 - val_mean_squared_error: 0.0618\n",
      "Epoch 1154/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0199 - mean_squared_error: 0.0022 - val_loss: 0.0791 - val_mean_squared_error: 0.0613\n",
      "Epoch 1155/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0201 - mean_squared_error: 0.0024 - val_loss: 0.0801 - val_mean_squared_error: 0.0624\n",
      "Epoch 1156/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0199 - mean_squared_error: 0.0022 - val_loss: 0.0795 - val_mean_squared_error: 0.0618\n",
      "Epoch 1157/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0200 - mean_squared_error: 0.0023 - val_loss: 0.0792 - val_mean_squared_error: 0.0615\n",
      "Epoch 1158/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0200 - mean_squared_error: 0.0023 - val_loss: 0.0797 - val_mean_squared_error: 0.0620\n",
      "Epoch 1159/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0197 - mean_squared_error: 0.0021 - val_loss: 0.0790 - val_mean_squared_error: 0.0614\n",
      "Epoch 1160/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0197 - mean_squared_error: 0.0020 - val_loss: 0.0797 - val_mean_squared_error: 0.0620\n",
      "Epoch 1161/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0195 - mean_squared_error: 0.0019 - val_loss: 0.0791 - val_mean_squared_error: 0.0615\n",
      "Epoch 1162/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0198 - mean_squared_error: 0.0022 - val_loss: 0.0803 - val_mean_squared_error: 0.0626\n",
      "Epoch 1163/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0201 - mean_squared_error: 0.0025 - val_loss: 0.0806 - val_mean_squared_error: 0.0630\n",
      "Epoch 1164/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0199 - mean_squared_error: 0.0023 - val_loss: 0.0796 - val_mean_squared_error: 0.0620\n",
      "Epoch 1165/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0196 - mean_squared_error: 0.0021 - val_loss: 0.0793 - val_mean_squared_error: 0.0618\n",
      "Epoch 1166/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0196 - mean_squared_error: 0.0021 - val_loss: 0.0798 - val_mean_squared_error: 0.0622\n",
      "Epoch 1167/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0198 - mean_squared_error: 0.0023 - val_loss: 0.0791 - val_mean_squared_error: 0.0615\n",
      "Epoch 1168/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0195 - mean_squared_error: 0.0020 - val_loss: 0.0796 - val_mean_squared_error: 0.0621\n",
      "Epoch 1169/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0195 - mean_squared_error: 0.0020 - val_loss: 0.0790 - val_mean_squared_error: 0.0615\n",
      "Epoch 1170/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0195 - mean_squared_error: 0.0020 - val_loss: 0.0790 - val_mean_squared_error: 0.0615\n",
      "Epoch 1171/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0198 - mean_squared_error: 0.0024 - val_loss: 0.0795 - val_mean_squared_error: 0.0620\n",
      "Epoch 1172/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0199 - mean_squared_error: 0.0024 - val_loss: 0.0798 - val_mean_squared_error: 0.0623\n",
      "Epoch 1173/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0195 - mean_squared_error: 0.0020 - val_loss: 0.0791 - val_mean_squared_error: 0.0616\n",
      "Epoch 1174/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0197 - mean_squared_error: 0.0023 - val_loss: 0.0791 - val_mean_squared_error: 0.0617\n",
      "Epoch 1175/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0203 - mean_squared_error: 0.0028 - val_loss: 0.0787 - val_mean_squared_error: 0.0612\n",
      "Epoch 1176/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0207 - mean_squared_error: 0.0032 - val_loss: 0.0788 - val_mean_squared_error: 0.0613\n",
      "Epoch 1177/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0200 - mean_squared_error: 0.0026 - val_loss: 0.0785 - val_mean_squared_error: 0.0611\n",
      "Epoch 1178/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0196 - mean_squared_error: 0.0022 - val_loss: 0.0792 - val_mean_squared_error: 0.0618\n",
      "Epoch 1179/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0197 - mean_squared_error: 0.0023 - val_loss: 0.0786 - val_mean_squared_error: 0.0612\n",
      "Epoch 1180/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0196 - mean_squared_error: 0.0023 - val_loss: 0.0795 - val_mean_squared_error: 0.0622\n",
      "Epoch 1181/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0193 - mean_squared_error: 0.0020 - val_loss: 0.0784 - val_mean_squared_error: 0.0611\n",
      "Epoch 1182/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0190 - mean_squared_error: 0.0017 - val_loss: 0.0790 - val_mean_squared_error: 0.0617\n",
      "Epoch 1183/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0200 - mean_squared_error: 0.0028 - val_loss: 0.0795 - val_mean_squared_error: 0.0621\n",
      "Epoch 1184/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0199 - mean_squared_error: 0.0026 - val_loss: 0.0793 - val_mean_squared_error: 0.0619\n",
      "Epoch 1185/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0194 - mean_squared_error: 0.0021 - val_loss: 0.0804 - val_mean_squared_error: 0.0632\n",
      "Epoch 1186/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0196 - mean_squared_error: 0.0023 - val_loss: 0.0788 - val_mean_squared_error: 0.0615\n",
      "Epoch 1187/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0193 - mean_squared_error: 0.0021 - val_loss: 0.0790 - val_mean_squared_error: 0.0618\n",
      "Epoch 1188/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0196 - mean_squared_error: 0.0023 - val_loss: 0.0795 - val_mean_squared_error: 0.0622\n",
      "Epoch 1189/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0193 - mean_squared_error: 0.0021 - val_loss: 0.0801 - val_mean_squared_error: 0.0629\n",
      "Epoch 1190/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0191 - mean_squared_error: 0.0019 - val_loss: 0.0790 - val_mean_squared_error: 0.0619\n",
      "Epoch 1191/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0194 - mean_squared_error: 0.0023 - val_loss: 0.0796 - val_mean_squared_error: 0.0624\n",
      "Epoch 1192/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0196 - mean_squared_error: 0.0024 - val_loss: 0.0788 - val_mean_squared_error: 0.0616\n",
      "Epoch 1193/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0192 - mean_squared_error: 0.0020 - val_loss: 0.0789 - val_mean_squared_error: 0.0618\n",
      "Epoch 1194/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0190 - mean_squared_error: 0.0019 - val_loss: 0.0794 - val_mean_squared_error: 0.0623\n",
      "Epoch 1195/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0200 - mean_squared_error: 0.0028 - val_loss: 0.0796 - val_mean_squared_error: 0.0624\n",
      "Epoch 1196/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0205 - mean_squared_error: 0.0033 - val_loss: 0.0791 - val_mean_squared_error: 0.0619\n",
      "Epoch 1197/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0204 - mean_squared_error: 0.0032 - val_loss: 0.0790 - val_mean_squared_error: 0.0618\n",
      "Epoch 1198/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0196 - mean_squared_error: 0.0024 - val_loss: 0.0785 - val_mean_squared_error: 0.0614\n",
      "Epoch 1199/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0192 - mean_squared_error: 0.0021 - val_loss: 0.0787 - val_mean_squared_error: 0.0616\n",
      "Epoch 1200/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0190 - mean_squared_error: 0.0020 - val_loss: 0.0792 - val_mean_squared_error: 0.0621\n",
      "Epoch 1201/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0191 - mean_squared_error: 0.0021 - val_loss: 0.0790 - val_mean_squared_error: 0.0620\n",
      "Epoch 1202/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0188 - mean_squared_error: 0.0018 - val_loss: 0.0789 - val_mean_squared_error: 0.0620\n",
      "Epoch 1203/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0195 - mean_squared_error: 0.0025 - val_loss: 0.0790 - val_mean_squared_error: 0.0619\n",
      "Epoch 1204/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0202 - mean_squared_error: 0.0031 - val_loss: 0.0797 - val_mean_squared_error: 0.0626\n",
      "Epoch 1205/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0200 - mean_squared_error: 0.0029 - val_loss: 0.0794 - val_mean_squared_error: 0.0624\n",
      "Epoch 1206/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0198 - mean_squared_error: 0.0027 - val_loss: 0.0784 - val_mean_squared_error: 0.0614\n",
      "Epoch 1207/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0195 - mean_squared_error: 0.0025 - val_loss: 0.0784 - val_mean_squared_error: 0.0614\n",
      "Epoch 1208/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0191 - mean_squared_error: 0.0022 - val_loss: 0.0782 - val_mean_squared_error: 0.0613\n",
      "Epoch 1209/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0188 - mean_squared_error: 0.0019 - val_loss: 0.0787 - val_mean_squared_error: 0.0619\n",
      "Epoch 1210/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0188 - mean_squared_error: 0.0019 - val_loss: 0.0794 - val_mean_squared_error: 0.0626\n",
      "Epoch 1211/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0189 - mean_squared_error: 0.0021 - val_loss: 0.0784 - val_mean_squared_error: 0.0615\n",
      "Epoch 1212/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0193 - mean_squared_error: 0.0024 - val_loss: 0.0782 - val_mean_squared_error: 0.0613\n",
      "Epoch 1213/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0189 - mean_squared_error: 0.0021 - val_loss: 0.0787 - val_mean_squared_error: 0.0618\n",
      "Epoch 1214/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0192 - mean_squared_error: 0.0024 - val_loss: 0.0786 - val_mean_squared_error: 0.0618\n",
      "Epoch 1215/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0188 - mean_squared_error: 0.0020 - val_loss: 0.0778 - val_mean_squared_error: 0.0610\n",
      "Epoch 1216/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0188 - mean_squared_error: 0.0020 - val_loss: 0.0778 - val_mean_squared_error: 0.0610\n",
      "Epoch 1217/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0192 - mean_squared_error: 0.0024 - val_loss: 0.0781 - val_mean_squared_error: 0.0613\n",
      "Epoch 1218/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0199 - mean_squared_error: 0.0031 - val_loss: 0.0788 - val_mean_squared_error: 0.0619\n",
      "Epoch 1219/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0193 - mean_squared_error: 0.0024 - val_loss: 0.0781 - val_mean_squared_error: 0.0613\n",
      "Epoch 1220/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0020 - val_loss: 0.0807 - val_mean_squared_error: 0.0639\n",
      "Epoch 1221/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0193 - mean_squared_error: 0.0025 - val_loss: 0.0788 - val_mean_squared_error: 0.0620\n",
      "Epoch 1222/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0019 - val_loss: 0.0776 - val_mean_squared_error: 0.0608\n",
      "Epoch 1223/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0188 - mean_squared_error: 0.0021 - val_loss: 0.0784 - val_mean_squared_error: 0.0617\n",
      "Epoch 1224/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0192 - mean_squared_error: 0.0024 - val_loss: 0.0793 - val_mean_squared_error: 0.0626\n",
      "Epoch 1225/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0191 - mean_squared_error: 0.0024 - val_loss: 0.0789 - val_mean_squared_error: 0.0622\n",
      "Epoch 1226/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0020 - val_loss: 0.0782 - val_mean_squared_error: 0.0615\n",
      "Epoch 1227/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0188 - mean_squared_error: 0.0021 - val_loss: 0.0778 - val_mean_squared_error: 0.0612\n",
      "Epoch 1228/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0188 - mean_squared_error: 0.0021 - val_loss: 0.0785 - val_mean_squared_error: 0.0619\n",
      "Epoch 1229/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0191 - mean_squared_error: 0.0024 - val_loss: 0.0783 - val_mean_squared_error: 0.0616\n",
      "Epoch 1230/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0189 - mean_squared_error: 0.0022 - val_loss: 0.0791 - val_mean_squared_error: 0.0624\n",
      "Epoch 1231/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0188 - mean_squared_error: 0.0022 - val_loss: 0.0787 - val_mean_squared_error: 0.0621\n",
      "Epoch 1232/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0186 - mean_squared_error: 0.0020 - val_loss: 0.0790 - val_mean_squared_error: 0.0625\n",
      "Epoch 1233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0186 - mean_squared_error: 0.0020 - val_loss: 0.0783 - val_mean_squared_error: 0.0617\n",
      "Epoch 1234/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0188 - mean_squared_error: 0.0022 - val_loss: 0.0790 - val_mean_squared_error: 0.0624\n",
      "Epoch 1235/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0188 - mean_squared_error: 0.0023 - val_loss: 0.0788 - val_mean_squared_error: 0.0623\n",
      "Epoch 1236/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0192 - mean_squared_error: 0.0026 - val_loss: 0.0781 - val_mean_squared_error: 0.0615\n",
      "Epoch 1237/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0190 - mean_squared_error: 0.0024 - val_loss: 0.0778 - val_mean_squared_error: 0.0613\n",
      "Epoch 1238/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0022 - val_loss: 0.0790 - val_mean_squared_error: 0.0625\n",
      "Epoch 1239/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0191 - mean_squared_error: 0.0026 - val_loss: 0.0782 - val_mean_squared_error: 0.0617\n",
      "Epoch 1240/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0189 - mean_squared_error: 0.0023 - val_loss: 0.0791 - val_mean_squared_error: 0.0626\n",
      "Epoch 1241/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0197 - mean_squared_error: 0.0032 - val_loss: 0.0785 - val_mean_squared_error: 0.0619\n",
      "Epoch 1242/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0191 - mean_squared_error: 0.0025 - val_loss: 0.0787 - val_mean_squared_error: 0.0622\n",
      "Epoch 1243/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0196 - mean_squared_error: 0.0030 - val_loss: 0.0787 - val_mean_squared_error: 0.0621\n",
      "Epoch 1244/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0191 - mean_squared_error: 0.0025 - val_loss: 0.0777 - val_mean_squared_error: 0.0612\n",
      "Epoch 1245/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0023 - val_loss: 0.0781 - val_mean_squared_error: 0.0617\n",
      "Epoch 1246/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0183 - mean_squared_error: 0.0019 - val_loss: 0.0783 - val_mean_squared_error: 0.0619\n",
      "Epoch 1247/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0184 - mean_squared_error: 0.0020 - val_loss: 0.0790 - val_mean_squared_error: 0.0626\n",
      "Epoch 1248/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0183 - mean_squared_error: 0.0019 - val_loss: 0.0787 - val_mean_squared_error: 0.0624\n",
      "Epoch 1249/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0185 - mean_squared_error: 0.0021 - val_loss: 0.0783 - val_mean_squared_error: 0.0619\n",
      "Epoch 1250/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0185 - mean_squared_error: 0.0021 - val_loss: 0.0784 - val_mean_squared_error: 0.0621\n",
      "Epoch 1251/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0186 - mean_squared_error: 0.0022 - val_loss: 0.0780 - val_mean_squared_error: 0.0616\n",
      "Epoch 1252/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0189 - mean_squared_error: 0.0026 - val_loss: 0.0785 - val_mean_squared_error: 0.0621\n",
      "Epoch 1253/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0187 - mean_squared_error: 0.0023 - val_loss: 0.0784 - val_mean_squared_error: 0.0620\n",
      "Epoch 1254/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0185 - mean_squared_error: 0.0021 - val_loss: 0.0778 - val_mean_squared_error: 0.0615\n",
      "Epoch 1255/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0024 - val_loss: 0.0782 - val_mean_squared_error: 0.0619\n",
      "Epoch 1256/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0184 - mean_squared_error: 0.0021 - val_loss: 0.0777 - val_mean_squared_error: 0.0614\n",
      "Epoch 1257/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0186 - mean_squared_error: 0.0023 - val_loss: 0.0781 - val_mean_squared_error: 0.0618\n",
      "Epoch 1258/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0184 - mean_squared_error: 0.0021 - val_loss: 0.0776 - val_mean_squared_error: 0.0614\n",
      "Epoch 1259/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0020 - val_loss: 0.0784 - val_mean_squared_error: 0.0622\n",
      "Epoch 1260/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0020 - val_loss: 0.0776 - val_mean_squared_error: 0.0614\n",
      "Epoch 1261/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0183 - mean_squared_error: 0.0021 - val_loss: 0.0784 - val_mean_squared_error: 0.0622\n",
      "Epoch 1262/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0020 - val_loss: 0.0785 - val_mean_squared_error: 0.0623\n",
      "Epoch 1263/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0190 - mean_squared_error: 0.0028 - val_loss: 0.0783 - val_mean_squared_error: 0.0620\n",
      "Epoch 1264/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0197 - mean_squared_error: 0.0034 - val_loss: 0.0777 - val_mean_squared_error: 0.0614\n",
      "Epoch 1265/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0189 - mean_squared_error: 0.0026 - val_loss: 0.0775 - val_mean_squared_error: 0.0613\n",
      "Epoch 1266/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0185 - mean_squared_error: 0.0023 - val_loss: 0.0777 - val_mean_squared_error: 0.0615\n",
      "Epoch 1267/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0020 - val_loss: 0.0779 - val_mean_squared_error: 0.0617\n",
      "Epoch 1268/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0191 - mean_squared_error: 0.0029 - val_loss: 0.0788 - val_mean_squared_error: 0.0625\n",
      "Epoch 1269/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0194 - mean_squared_error: 0.0032 - val_loss: 0.0784 - val_mean_squared_error: 0.0622\n",
      "Epoch 1270/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0025 - val_loss: 0.0784 - val_mean_squared_error: 0.0623\n",
      "Epoch 1271/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0181 - mean_squared_error: 0.0020 - val_loss: 0.0785 - val_mean_squared_error: 0.0623\n",
      "Epoch 1272/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0183 - mean_squared_error: 0.0022 - val_loss: 0.0777 - val_mean_squared_error: 0.0616\n",
      "Epoch 1273/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0184 - mean_squared_error: 0.0023 - val_loss: 0.0782 - val_mean_squared_error: 0.0621\n",
      "Epoch 1274/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0021 - val_loss: 0.0778 - val_mean_squared_error: 0.0617\n",
      "Epoch 1275/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0182 - mean_squared_error: 0.0021 - val_loss: 0.0785 - val_mean_squared_error: 0.0625\n",
      "Epoch 1276/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0022 - val_loss: 0.0782 - val_mean_squared_error: 0.0621\n",
      "Epoch 1277/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0183 - mean_squared_error: 0.0022 - val_loss: 0.0770 - val_mean_squared_error: 0.0610\n",
      "Epoch 1278/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0183 - mean_squared_error: 0.0022 - val_loss: 0.0786 - val_mean_squared_error: 0.0625\n",
      "Epoch 1279/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0182 - mean_squared_error: 0.0021 - val_loss: 0.0794 - val_mean_squared_error: 0.0634\n",
      "Epoch 1280/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0184 - mean_squared_error: 0.0024 - val_loss: 0.0774 - val_mean_squared_error: 0.0614\n",
      "Epoch 1281/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0185 - mean_squared_error: 0.0025 - val_loss: 0.0770 - val_mean_squared_error: 0.0610\n",
      "Epoch 1282/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0183 - mean_squared_error: 0.0023 - val_loss: 0.0791 - val_mean_squared_error: 0.0631\n",
      "Epoch 1283/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0022 - val_loss: 0.0779 - val_mean_squared_error: 0.0619\n",
      "Epoch 1284/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0178 - mean_squared_error: 0.0019 - val_loss: 0.0777 - val_mean_squared_error: 0.0618\n",
      "Epoch 1285/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0178 - mean_squared_error: 0.0018 - val_loss: 0.0784 - val_mean_squared_error: 0.0625\n",
      "Epoch 1286/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0177 - mean_squared_error: 0.0018 - val_loss: 0.0778 - val_mean_squared_error: 0.0619\n",
      "Epoch 1287/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0178 - mean_squared_error: 0.0020 - val_loss: 0.0773 - val_mean_squared_error: 0.0614\n",
      "Epoch 1288/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0183 - mean_squared_error: 0.0024 - val_loss: 0.0787 - val_mean_squared_error: 0.0628\n",
      "Epoch 1289/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0192 - mean_squared_error: 0.0033 - val_loss: 0.0784 - val_mean_squared_error: 0.0624\n",
      "Epoch 1290/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0194 - mean_squared_error: 0.0034 - val_loss: 0.0779 - val_mean_squared_error: 0.0619\n",
      "Epoch 1291/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0184 - mean_squared_error: 0.0024 - val_loss: 0.0790 - val_mean_squared_error: 0.0631\n",
      "Epoch 1292/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0181 - mean_squared_error: 0.0022 - val_loss: 0.0773 - val_mean_squared_error: 0.0614\n",
      "Epoch 1293/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0176 - mean_squared_error: 0.0018 - val_loss: 0.0778 - val_mean_squared_error: 0.0620\n",
      "Epoch 1294/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0186 - mean_squared_error: 0.0028 - val_loss: 0.0800 - val_mean_squared_error: 0.0640\n",
      "Epoch 1295/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0187 - mean_squared_error: 0.0028 - val_loss: 0.0775 - val_mean_squared_error: 0.0616\n",
      "Epoch 1296/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0180 - mean_squared_error: 0.0021 - val_loss: 0.0775 - val_mean_squared_error: 0.0617\n",
      "Epoch 1297/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0181 - mean_squared_error: 0.0023 - val_loss: 0.0795 - val_mean_squared_error: 0.0637\n",
      "Epoch 1298/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0023 - val_loss: 0.0782 - val_mean_squared_error: 0.0624\n",
      "Epoch 1299/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0178 - mean_squared_error: 0.0020 - val_loss: 0.0781 - val_mean_squared_error: 0.0623\n",
      "Epoch 1300/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0180 - mean_squared_error: 0.0022 - val_loss: 0.0779 - val_mean_squared_error: 0.0621\n",
      "Epoch 1301/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0178 - mean_squared_error: 0.0020 - val_loss: 0.0773 - val_mean_squared_error: 0.0616\n",
      "Epoch 1302/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.0178 - mean_squared_error: 0.0020 - val_loss: 0.0777 - val_mean_squared_error: 0.0620\n",
      "Epoch 1303/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0179 - mean_squared_error: 0.0021 - val_loss: 0.0780 - val_mean_squared_error: 0.0623\n",
      "Epoch 1304/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0177 - mean_squared_error: 0.0020 - val_loss: 0.0778 - val_mean_squared_error: 0.0621\n",
      "Epoch 1305/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0175 - mean_squared_error: 0.0018 - val_loss: 0.0776 - val_mean_squared_error: 0.0619\n",
      "Epoch 1306/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0177 - mean_squared_error: 0.0020 - val_loss: 0.0774 - val_mean_squared_error: 0.0618\n",
      "Epoch 1307/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0175 - mean_squared_error: 0.0019 - val_loss: 0.0787 - val_mean_squared_error: 0.0631\n",
      "Epoch 1308/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0179 - mean_squared_error: 0.0022 - val_loss: 0.0794 - val_mean_squared_error: 0.0637\n",
      "Epoch 1309/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0184 - mean_squared_error: 0.0027 - val_loss: 0.0772 - val_mean_squared_error: 0.0615\n",
      "Epoch 1310/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0177 - mean_squared_error: 0.0021 - val_loss: 0.0779 - val_mean_squared_error: 0.0622\n",
      "Epoch 1311/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0178 - mean_squared_error: 0.0022 - val_loss: 0.0788 - val_mean_squared_error: 0.0632\n",
      "Epoch 1312/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0181 - mean_squared_error: 0.0025 - val_loss: 0.0776 - val_mean_squared_error: 0.0619\n",
      "Epoch 1313/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0190 - mean_squared_error: 0.0033 - val_loss: 0.0792 - val_mean_squared_error: 0.0635\n",
      "Epoch 1314/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0183 - mean_squared_error: 0.0025 - val_loss: 0.0785 - val_mean_squared_error: 0.0628\n",
      "Epoch 1315/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0181 - mean_squared_error: 0.0024 - val_loss: 0.0782 - val_mean_squared_error: 0.0626\n",
      "Epoch 1316/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0177 - mean_squared_error: 0.0020 - val_loss: 0.0784 - val_mean_squared_error: 0.0628\n",
      "Epoch 1317/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0175 - mean_squared_error: 0.0019 - val_loss: 0.0775 - val_mean_squared_error: 0.0620\n",
      "Epoch 1318/10000\n",
      "5000/5000 [==============================] - 0s 30us/sample - loss: 0.0177 - mean_squared_error: 0.0022 - val_loss: 0.0793 - val_mean_squared_error: 0.0638\n",
      "Epoch 1319/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0187 - mean_squared_error: 0.0031 - val_loss: 0.0778 - val_mean_squared_error: 0.0622\n",
      "Epoch 1320/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0181 - mean_squared_error: 0.0025 - val_loss: 0.0782 - val_mean_squared_error: 0.0626\n",
      "Epoch 1321/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0180 - mean_squared_error: 0.0024 - val_loss: 0.0787 - val_mean_squared_error: 0.0631\n",
      "Epoch 1322/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0179 - mean_squared_error: 0.0023 - val_loss: 0.0781 - val_mean_squared_error: 0.0625\n",
      "Epoch 1323/10000\n",
      "5000/5000 [==============================] - 0s 29us/sample - loss: 0.0174 - mean_squared_error: 0.0018 - val_loss: 0.0778 - val_mean_squared_error: 0.0623\n",
      "Epoch 1324/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0175 - mean_squared_error: 0.0020 - val_loss: 0.0774 - val_mean_squared_error: 0.0619\n",
      "Epoch 1325/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0182 - mean_squared_error: 0.0027 - val_loss: 0.0774 - val_mean_squared_error: 0.0618\n",
      "Epoch 1326/10000\n",
      "5000/5000 [==============================] - 0s 28us/sample - loss: 0.0179 - mean_squared_error: 0.0024 - val_loss: 0.0781 - val_mean_squared_error: 0.0626\n",
      "Epoch 1327/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/5000 [===========================>..] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0022Restoring model weights from the end of the best epoch.\n",
      "5000/5000 [==============================] - 0s 37us/sample - loss: 0.0177 - mean_squared_error: 0.0022 - val_loss: 0.0783 - val_mean_squared_error: 0.0628\n",
      "Epoch 01327: early stopping\n"
     ]
    }
   ],
   "source": [
    "if sys.version[0]==3:\n",
    "    pathlib.Path('{}'.format(pathtoNNmodels)).mkdir(parents=True, exist_ok=True) \n",
    "else:\n",
    "    if not os.path.exists('{}'.format(pathtoNNmodels)):\n",
    "        os.makedirs('{}'.format(pathtoNNmodels))\n",
    "\n",
    "if MPI_process == True:\n",
    "    !mpiexec -np 1 python NN.py\n",
    "else:\n",
    "    %run NN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./modules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range (1):\n",
    "    np.save('real_data_element',k)\n",
    "    %run STAN.py\n",
    "os.remove(\"real_data_element.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood free inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './modules/'\n",
      "/share/data1/fgerardi/code_github/example_selection/modules\n"
     ]
    }
   ],
   "source": [
    "%cd ./modules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version[0]==3:\n",
    "    pathlib.Path('{}'.format(pathtoLFIresults)).mkdir(parents=True, exist_ok=True) \n",
    "else:\n",
    "    if not os.path.exists('{}'.format(pathtoLFIresults)):\n",
    "        os.makedirs('{}'.format(pathtoLFIresults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 18:08:51.298647: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "2021-04-06 18:08:51.320295: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "1\n",
      "2021-04-06 18:08:51.898413: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "2021-04-06 18:08:51.898448: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "____PROCESS0 for NN_filename=MSE_ns5000_2LR0.1_128_128_bs100_lr0.0001_l10.0001have been set____\n",
      "[0.42920953 0.23262776]\n",
      "PYDELFI: APPLYING GAUSSIAN PRIOR\n",
      "____PROCESS0 for NN_filename=[array([0.0001]), array([100]), array([0.0001])]has set and started pydelfi____\n",
      "Using TensorFlow backend.\n",
      "Training:  47%|████▋     | 235/500 [01:33<00:14, 18.63it/s, train loss=0.788, val loss=0.875]\n",
      "Training:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   0%|          | 0/500 [00:00<?, ?it/s, train loss=0, val loss=0]\u001b[A\n",
      "Training:   0%|          | 1/500 [00:00<05:42,  1.46it/s, train loss=0, val loss=0]\u001b[A\n",
      "Training:   0%|          | 1/500 [00:00<05:42,  1.46it/s, train loss=4.28, val loss=4.38]\u001b[A\n",
      "Training:   0%|          | 2/500 [00:01<08:17,  1.00it/s, train loss=4.28, val loss=4.38]\u001b[A\n",
      "Training:   0%|          | 2/500 [00:01<08:17,  1.00it/s, train loss=3.55, val loss=3.61]\u001b[A\n",
      "Training:   1%|          | 3/500 [00:02<07:42,  1.08it/s, train loss=3.55, val loss=3.61]\u001b[A\n",
      "Training:   1%|          | 3/500 [00:02<07:42,  1.08it/s, train loss=3.25, val loss=3.3] \u001b[A\n",
      "Training:   1%|          | 4/500 [00:03<07:18,  1.13it/s, train loss=3.25, val loss=3.3]\u001b[A\n",
      "Training:   1%|          | 4/500 [00:03<07:18,  1.13it/s, train loss=3.07, val loss=3.14]\u001b[A\n",
      "Training:   1%|          | 5/500 [00:04<07:01,  1.17it/s, train loss=3.07, val loss=3.14]\u001b[A\n",
      "Training:   1%|          | 5/500 [00:04<07:01,  1.17it/s, train loss=2.92, val loss=2.99]\u001b[A\n",
      "Training:   1%|          | 6/500 [00:05<06:54,  1.19it/s, train loss=2.92, val loss=2.99]\u001b[A\n",
      "Training:   1%|          | 6/500 [00:05<06:54,  1.19it/s, train loss=2.77, val loss=2.83]\u001b[A\n",
      "Training:   1%|▏         | 7/500 [00:05<06:50,  1.20it/s, train loss=2.77, val loss=2.83]\u001b[A\n",
      "Training:   1%|▏         | 7/500 [00:05<06:50,  1.20it/s, train loss=2.58, val loss=2.64]\u001b[A\n",
      "Training:   2%|▏         | 8/500 [00:06<06:48,  1.21it/s, train loss=2.58, val loss=2.64]\u001b[A\n",
      "Training:   2%|▏         | 8/500 [00:06<06:48,  1.21it/s, train loss=2.42, val loss=2.45]\u001b[A\n",
      "Training:   2%|▏         | 9/500 [00:07<06:49,  1.20it/s, train loss=2.42, val loss=2.45]\u001b[A\n",
      "Training:   2%|▏         | 9/500 [00:07<06:49,  1.20it/s, train loss=2.3, val loss=2.32] \u001b[A\n",
      "Training:   2%|▏         | 10/500 [00:08<06:50,  1.19it/s, train loss=2.3, val loss=2.32]\u001b[A\n",
      "Training:   2%|▏         | 10/500 [00:08<06:50,  1.19it/s, train loss=2.19, val loss=2.22]\u001b[A\n",
      "Training:   2%|▏         | 11/500 [00:09<06:46,  1.20it/s, train loss=2.19, val loss=2.22]\u001b[A\n",
      "Training:   2%|▏         | 11/500 [00:09<06:46,  1.20it/s, train loss=2.08, val loss=2.12]\u001b[A\n",
      "Training:   2%|▏         | 12/500 [00:10<06:42,  1.21it/s, train loss=2.08, val loss=2.12]\u001b[A\n",
      "Training:   2%|▏         | 12/500 [00:10<06:42,  1.21it/s, train loss=1.99, val loss=2.03]\u001b[A\n",
      "Training:   3%|▎         | 13/500 [00:11<06:47,  1.20it/s, train loss=1.99, val loss=2.03]\u001b[A\n",
      "Training:   3%|▎         | 13/500 [00:11<06:47,  1.20it/s, train loss=1.89, val loss=1.94]\u001b[A\n",
      "Training:   3%|▎         | 14/500 [00:11<06:51,  1.18it/s, train loss=1.89, val loss=1.94]\u001b[A\n",
      "Training:   3%|▎         | 14/500 [00:11<06:51,  1.18it/s, train loss=1.8, val loss=1.85] \u001b[A\n",
      "Training:   3%|▎         | 15/500 [00:12<06:49,  1.18it/s, train loss=1.8, val loss=1.85]\u001b[A\n",
      "Training:   3%|▎         | 15/500 [00:12<06:49,  1.18it/s, train loss=1.72, val loss=1.77]\u001b[A\n",
      "Training:   3%|▎         | 16/500 [00:13<06:44,  1.20it/s, train loss=1.72, val loss=1.77]\u001b[A\n",
      "Training:   3%|▎         | 16/500 [00:13<06:44,  1.20it/s, train loss=1.64, val loss=1.7] \u001b[A\n",
      "Training:   3%|▎         | 17/500 [00:14<06:39,  1.21it/s, train loss=1.64, val loss=1.7]\u001b[A\n",
      "Training:   3%|▎         | 17/500 [00:14<06:39,  1.21it/s, train loss=1.58, val loss=1.65]\u001b[A\n",
      "Training:   4%|▎         | 18/500 [00:15<06:37,  1.21it/s, train loss=1.58, val loss=1.65]\u001b[A\n",
      "Training:  47%|████▋     | 235/500 [01:50<00:14, 18.63it/s, train loss=0.788, val loss=0.875]\n",
      "Training:   4%|▍         | 19/500 [00:15<06:34,  1.22it/s, train loss=1.52, val loss=1.59]\u001b[A\n",
      "Training:   4%|▍         | 19/500 [00:15<06:34,  1.22it/s, train loss=1.48, val loss=1.55]\u001b[A\n",
      "Training:   4%|▍         | 20/500 [00:16<06:38,  1.20it/s, train loss=1.48, val loss=1.55]\u001b[A\n",
      "Training:   4%|▍         | 20/500 [00:16<06:38,  1.20it/s, train loss=1.44, val loss=1.51]\u001b[A\n",
      "Training:   4%|▍         | 21/500 [00:17<06:39,  1.20it/s, train loss=1.44, val loss=1.51]\u001b[A\n",
      "Training:   4%|▍         | 21/500 [00:17<06:39,  1.20it/s, train loss=1.4, val loss=1.49] \u001b[A\n",
      "Training:   4%|▍         | 22/500 [00:18<06:35,  1.21it/s, train loss=1.4, val loss=1.49]\u001b[A\n",
      "Training:   4%|▍         | 22/500 [00:18<06:35,  1.21it/s, train loss=1.37, val loss=1.47]\u001b[A\n",
      "Training:   5%|▍         | 23/500 [00:19<06:27,  1.23it/s, train loss=1.37, val loss=1.47]\u001b[A\n",
      "Training:   5%|▍         | 23/500 [00:19<06:27,  1.23it/s, train loss=1.34, val loss=1.43]\u001b[A\n",
      "Training:   5%|▍         | 24/500 [00:20<06:35,  1.20it/s, train loss=1.34, val loss=1.43]\u001b[A\n",
      "Training:   5%|▍         | 24/500 [00:20<06:35,  1.20it/s, train loss=1.31, val loss=1.41]\u001b[A\n",
      "Training:   5%|▌         | 25/500 [00:20<06:32,  1.21it/s, train loss=1.31, val loss=1.41]\u001b[A\n",
      "Training:   5%|▌         | 25/500 [00:20<06:32,  1.21it/s, train loss=1.3, val loss=1.4]  \u001b[A\n",
      "Training:   5%|▌         | 26/500 [00:21<06:29,  1.22it/s, train loss=1.3, val loss=1.4]\u001b[A\n",
      "Training:   5%|▌         | 26/500 [00:21<06:29,  1.22it/s, train loss=1.27, val loss=1.37]\u001b[A\n",
      "Training:   5%|▌         | 27/500 [00:22<06:27,  1.22it/s, train loss=1.27, val loss=1.37]\u001b[A\n",
      "Training:   5%|▌         | 27/500 [00:22<06:27,  1.22it/s, train loss=1.25, val loss=1.36]\u001b[A\n",
      "Training:   6%|▌         | 28/500 [00:23<06:24,  1.23it/s, train loss=1.25, val loss=1.36]\u001b[A\n",
      "Training:   6%|▌         | 28/500 [00:23<06:24,  1.23it/s, train loss=1.23, val loss=1.33]\u001b[A\n",
      "Training:   6%|▌         | 29/500 [00:24<06:23,  1.23it/s, train loss=1.23, val loss=1.33]\u001b[A\n",
      "Training:   6%|▌         | 29/500 [00:24<06:23,  1.23it/s, train loss=1.21, val loss=1.31]\u001b[A\n",
      "Training:   6%|▌         | 30/500 [00:25<06:25,  1.22it/s, train loss=1.21, val loss=1.31]\u001b[A\n",
      "Training:   6%|▌         | 30/500 [00:25<06:25,  1.22it/s, train loss=1.19, val loss=1.29]\u001b[A\n",
      "Training:   6%|▌         | 31/500 [00:25<06:22,  1.23it/s, train loss=1.19, val loss=1.29]\u001b[A\n",
      "Training:   6%|▌         | 31/500 [00:25<06:22,  1.23it/s, train loss=1.18, val loss=1.3] \u001b[A\n",
      "Training:   6%|▋         | 32/500 [00:25<06:21,  1.23it/s, train loss=1.16, val loss=1.27]\u001b[A\n",
      "Training:   7%|▋         | 33/500 [00:26<04:56,  1.58it/s, train loss=1.16, val loss=1.27]\u001b[A\n",
      "Training:   7%|▋         | 33/500 [00:26<04:56,  1.58it/s, train loss=1.15, val loss=1.26]\u001b[A\n",
      "Training:   7%|▋         | 34/500 [00:27<05:17,  1.47it/s, train loss=1.15, val loss=1.26]\u001b[A\n",
      "Training:   7%|▋         | 34/500 [00:27<05:17,  1.47it/s, train loss=1.13, val loss=1.24]\u001b[A\n",
      "Training:   7%|▋         | 35/500 [00:28<05:33,  1.39it/s, train loss=1.13, val loss=1.24]\u001b[A\n",
      "Training:   7%|▋         | 35/500 [00:28<05:33,  1.39it/s, train loss=1.12, val loss=1.22]\u001b[A\n",
      "Training:   7%|▋         | 36/500 [00:29<05:43,  1.35it/s, train loss=1.12, val loss=1.22]\u001b[A\n",
      "Training:   7%|▋         | 36/500 [00:29<05:43,  1.35it/s, train loss=1.1, val loss=1.21] \u001b[A\n",
      "Training:   7%|▋         | 37/500 [00:29<05:55,  1.30it/s, train loss=1.1, val loss=1.21]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 37/500 [00:29<05:55,  1.30it/s, train loss=1.09, val loss=1.2]\u001b[A\n",
      "Training:   8%|▊         | 38/500 [00:30<06:04,  1.27it/s, train loss=1.09, val loss=1.2]\u001b[A\n",
      "Training:   8%|▊         | 38/500 [00:30<06:04,  1.27it/s, train loss=1.08, val loss=1.19]\u001b[A\n",
      "Training:   8%|▊         | 39/500 [00:31<06:08,  1.25it/s, train loss=1.08, val loss=1.19]\u001b[A\n",
      "Training:   8%|▊         | 39/500 [00:31<06:08,  1.25it/s, train loss=1.07, val loss=1.17]\u001b[A\n",
      "Training:   8%|▊         | 40/500 [00:32<06:12,  1.24it/s, train loss=1.07, val loss=1.17]\u001b[A\n",
      "Training:   8%|▊         | 40/500 [00:32<06:12,  1.24it/s, train loss=1.06, val loss=1.18]\u001b[A\n",
      "Training:   8%|▊         | 41/500 [00:32<06:11,  1.24it/s, train loss=1.05, val loss=1.16]\u001b[A\n",
      "Training:   8%|▊         | 42/500 [00:33<04:51,  1.57it/s, train loss=1.05, val loss=1.16]\u001b[A\n",
      "Training:   8%|▊         | 42/500 [00:33<04:51,  1.57it/s, train loss=1.04, val loss=1.15]\u001b[A\n",
      "Training:   9%|▊         | 43/500 [00:34<05:08,  1.48it/s, train loss=1.04, val loss=1.15]\u001b[A\n",
      "Training:   9%|▊         | 43/500 [00:34<05:08,  1.48it/s, train loss=1.03, val loss=1.13]\u001b[A\n",
      "Training:   9%|▉         | 44/500 [00:34<05:25,  1.40it/s, train loss=1.03, val loss=1.13]\u001b[A\n",
      "Training:   9%|▉         | 44/500 [00:34<05:25,  1.40it/s, train loss=1.02, val loss=1.12]\u001b[A\n",
      "Training:   9%|▉         | 45/500 [00:35<05:39,  1.34it/s, train loss=1.02, val loss=1.12]\u001b[A\n",
      "Training:   9%|▉         | 45/500 [00:35<05:39,  1.34it/s, train loss=1.01, val loss=1.12]\u001b[A\n",
      "Training:   9%|▉         | 46/500 [00:35<05:38,  1.34it/s, train loss=1, val loss=1.11]   \u001b[A\n",
      "Training:   9%|▉         | 47/500 [00:36<04:31,  1.67it/s, train loss=1, val loss=1.11]\u001b[A\n",
      "Training:   9%|▉         | 47/500 [00:36<04:31,  1.67it/s, train loss=0.999, val loss=1.11]\u001b[A\n",
      "Training:  10%|▉         | 48/500 [00:37<04:52,  1.54it/s, train loss=0.999, val loss=1.11]\u001b[A\n",
      "Training:  10%|▉         | 48/500 [00:37<04:52,  1.54it/s, train loss=0.986, val loss=1.1] \u001b[A\n",
      "Training:  10%|▉         | 49/500 [00:38<05:13,  1.44it/s, train loss=0.986, val loss=1.1]\u001b[A\n",
      "Training:  10%|▉         | 49/500 [00:38<05:13,  1.44it/s, train loss=0.978, val loss=1.08]\u001b[A\n",
      "Training:  10%|█         | 50/500 [00:39<05:27,  1.37it/s, train loss=0.978, val loss=1.08]\u001b[A\n",
      "Training:  10%|█         | 50/500 [00:39<05:27,  1.37it/s, train loss=0.971, val loss=1.08]\u001b[A\n",
      "Training:  10%|█         | 51/500 [00:39<05:26,  1.37it/s, train loss=0.965, val loss=1.07]\u001b[A\n",
      "Training:  10%|█         | 52/500 [00:39<04:27,  1.68it/s, train loss=0.965, val loss=1.07]\u001b[A\n",
      "Training:  10%|█         | 52/500 [00:39<04:27,  1.68it/s, train loss=0.962, val loss=1.07]\u001b[A\n",
      "Training:  11%|█         | 53/500 [00:39<04:26,  1.68it/s, train loss=0.958, val loss=1.06]\u001b[A\n",
      "Training:  11%|█         | 54/500 [00:40<04:01,  1.85it/s, train loss=0.958, val loss=1.06]\u001b[A\n",
      "Training:  11%|█         | 54/500 [00:40<04:01,  1.85it/s, train loss=0.949, val loss=1.05]\u001b[A\n",
      "Training:  11%|█         | 55/500 [00:41<04:29,  1.65it/s, train loss=0.949, val loss=1.05]\u001b[A\n",
      "Training:  11%|█         | 55/500 [00:41<04:29,  1.65it/s, train loss=0.945, val loss=1.05]\u001b[A\n",
      "Training:  11%|█         | 56/500 [00:42<04:50,  1.53it/s, train loss=0.945, val loss=1.05]\u001b[A\n",
      "Training:  11%|█         | 56/500 [00:42<04:50,  1.53it/s, train loss=0.94, val loss=1.04] \u001b[A\n",
      "Training:  11%|█▏        | 57/500 [00:43<05:09,  1.43it/s, train loss=0.94, val loss=1.04]\u001b[A\n",
      "Training:  11%|█▏        | 57/500 [00:43<05:09,  1.43it/s, train loss=0.931, val loss=1.03]\u001b[A\n",
      "Training:  12%|█▏        | 58/500 [00:44<05:21,  1.37it/s, train loss=0.931, val loss=1.03]\u001b[A\n",
      "Training:  12%|█▏        | 58/500 [00:44<05:21,  1.37it/s, train loss=0.926, val loss=1.03]\u001b[A\n",
      "Training:  12%|█▏        | 59/500 [00:44<05:36,  1.31it/s, train loss=0.926, val loss=1.03]\u001b[A\n",
      "Training:  12%|█▏        | 59/500 [00:44<05:36,  1.31it/s, train loss=0.936, val loss=1.04]\u001b[A\n",
      "Training:  12%|█▏        | 60/500 [00:44<05:35,  1.31it/s, train loss=0.922, val loss=1.02]\u001b[A\n",
      "Training:  12%|█▏        | 61/500 [00:45<04:30,  1.62it/s, train loss=0.922, val loss=1.02]\u001b[A\n",
      "Training:  12%|█▏        | 61/500 [00:45<04:30,  1.62it/s, train loss=0.914, val loss=1.01]\u001b[A\n",
      "Training:  12%|█▏        | 62/500 [00:46<04:53,  1.49it/s, train loss=0.914, val loss=1.01]\u001b[A\n",
      "Training:  12%|█▏        | 62/500 [00:46<04:53,  1.49it/s, train loss=0.911, val loss=1.01]\u001b[A\n",
      "Training:  13%|█▎        | 63/500 [00:47<05:05,  1.43it/s, train loss=0.911, val loss=1.01]\u001b[A\n",
      "Training:  13%|█▎        | 63/500 [00:47<05:05,  1.43it/s, train loss=0.909, val loss=1]   \u001b[A\n",
      "Training:  13%|█▎        | 64/500 [00:48<05:20,  1.36it/s, train loss=0.909, val loss=1]\u001b[A\n",
      "Training:  13%|█▎        | 64/500 [00:48<05:20,  1.36it/s, train loss=0.91, val loss=1.01]\u001b[A\n",
      "Training:  13%|█▎        | 65/500 [00:48<05:19,  1.36it/s, train loss=0.901, val loss=1]  \u001b[A\n",
      "Training:  13%|█▎        | 66/500 [00:49<04:34,  1.58it/s, train loss=0.901, val loss=1]\u001b[A\n",
      "Training:  13%|█▎        | 66/500 [00:49<04:34,  1.58it/s, train loss=0.897, val loss=0.991]\u001b[A\n",
      "Training:  13%|█▎        | 67/500 [00:50<05:02,  1.43it/s, train loss=0.897, val loss=0.991]\u001b[A\n",
      "Training:  13%|█▎        | 67/500 [00:50<05:02,  1.43it/s, train loss=0.901, val loss=1]    \u001b[A\n",
      "Training:  14%|█▎        | 68/500 [00:50<05:02,  1.43it/s, train loss=0.891, val loss=0.988]\u001b[A\n",
      "Training:  14%|█▍        | 69/500 [00:50<04:09,  1.73it/s, train loss=0.891, val loss=0.988]\u001b[A\n",
      "Training:  14%|█▍        | 69/500 [00:50<04:09,  1.73it/s, train loss=0.885, val loss=0.985]\u001b[A\n",
      "Training:  14%|█▍        | 70/500 [00:51<04:34,  1.56it/s, train loss=0.885, val loss=0.985]\u001b[A\n",
      "Training:  14%|█▍        | 70/500 [00:51<04:34,  1.56it/s, train loss=0.886, val loss=0.977]\u001b[A\n",
      "Training:  14%|█▍        | 71/500 [00:52<04:53,  1.46it/s, train loss=0.886, val loss=0.977]\u001b[A\n",
      "Training:  14%|█▍        | 71/500 [00:52<04:53,  1.46it/s, train loss=0.888, val loss=0.986]\u001b[A\n",
      "Training:  14%|█▍        | 72/500 [00:52<04:52,  1.46it/s, train loss=0.88, val loss=0.979] \u001b[A\n",
      "Training:  15%|█▍        | 73/500 [00:52<04:52,  1.46it/s, train loss=0.889, val loss=0.985]\u001b[A\n",
      "Training:  15%|█▍        | 74/500 [00:52<04:51,  1.46it/s, train loss=0.877, val loss=0.975]\u001b[A\n",
      "Training:  15%|█▌        | 75/500 [00:53<02:59,  2.37it/s, train loss=0.877, val loss=0.975]\u001b[A\n",
      "Training:  15%|█▌        | 75/500 [00:53<02:59,  2.37it/s, train loss=0.868, val loss=0.958]\u001b[A\n",
      "Training:  15%|█▌        | 76/500 [00:54<03:28,  2.04it/s, train loss=0.868, val loss=0.958]\u001b[A\n",
      "Training:  15%|█▌        | 76/500 [00:54<03:28,  2.04it/s, train loss=0.867, val loss=0.956]\u001b[A\n",
      "Training:  15%|█▌        | 77/500 [00:55<03:55,  1.79it/s, train loss=0.867, val loss=0.956]\u001b[A\n",
      "Training:  15%|█▌        | 77/500 [00:55<03:55,  1.79it/s, train loss=0.869, val loss=0.964]\u001b[A\n",
      "Training:  16%|█▌        | 78/500 [00:55<03:55,  1.79it/s, train loss=0.865, val loss=0.955]\u001b[A\n",
      "Training:  16%|█▌        | 79/500 [00:56<03:35,  1.95it/s, train loss=0.865, val loss=0.955]\u001b[A\n",
      "Training:  16%|█▌        | 79/500 [00:56<03:35,  1.95it/s, train loss=0.863, val loss=0.955]\u001b[A\n",
      "Training:  16%|█▌        | 80/500 [00:56<04:02,  1.73it/s, train loss=0.863, val loss=0.955]\u001b[A\n",
      "Training:  16%|█▌        | 80/500 [00:56<04:02,  1.73it/s, train loss=0.87, val loss=0.956] \u001b[A\n",
      "Training:  16%|█▌        | 81/500 [00:56<04:01,  1.73it/s, train loss=0.857, val loss=0.946]\u001b[A\n",
      "Training:  16%|█▋        | 82/500 [00:57<03:38,  1.91it/s, train loss=0.857, val loss=0.946]\u001b[A\n",
      "Training:  16%|█▋        | 82/500 [00:57<03:38,  1.91it/s, train loss=0.856, val loss=0.944]\u001b[A\n",
      "Training:  17%|█▋        | 83/500 [00:58<04:06,  1.69it/s, train loss=0.856, val loss=0.944]\u001b[A\n",
      "Training:  17%|█▋        | 83/500 [00:58<04:06,  1.69it/s, train loss=0.853, val loss=0.942]\u001b[A\n",
      "Training:  17%|█▋        | 84/500 [00:59<04:27,  1.56it/s, train loss=0.853, val loss=0.942]\u001b[A\n",
      "Training:  17%|█▋        | 84/500 [00:59<04:27,  1.56it/s, train loss=0.853, val loss=0.935]\u001b[A\n",
      "Training:  17%|█▋        | 85/500 [01:00<04:46,  1.45it/s, train loss=0.853, val loss=0.935]\u001b[A\n",
      "Training:  17%|█▋        | 85/500 [01:00<04:46,  1.45it/s, train loss=0.855, val loss=0.942]\u001b[A\n",
      "Training:  17%|█▋        | 86/500 [01:00<04:45,  1.45it/s, train loss=0.848, val loss=0.936]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 87/500 [01:00<04:45,  1.45it/s, train loss=0.858, val loss=0.93] \u001b[A\n",
      "Training:  18%|█▊        | 88/500 [01:01<03:18,  2.07it/s, train loss=0.858, val loss=0.93]\u001b[A\n",
      "Training:  18%|█▊        | 88/500 [01:01<03:18,  2.07it/s, train loss=0.848, val loss=0.941]\u001b[A\n",
      "Training:  18%|█▊        | 89/500 [01:01<03:18,  2.07it/s, train loss=0.845, val loss=0.919]\u001b[A\n",
      "Training:  18%|█▊        | 90/500 [01:01<03:10,  2.16it/s, train loss=0.845, val loss=0.919]\u001b[A\n",
      "Training:  18%|█▊        | 90/500 [01:01<03:10,  2.16it/s, train loss=0.853, val loss=0.938]\u001b[A\n",
      "Training:  18%|█▊        | 91/500 [01:02<03:09,  2.16it/s, train loss=0.839, val loss=0.922]\u001b[A\n",
      "Training:  18%|█▊        | 92/500 [01:02<03:09,  2.16it/s, train loss=0.839, val loss=0.922]\u001b[A\n",
      "Training:  19%|█▊        | 93/500 [01:02<03:08,  2.16it/s, train loss=0.838, val loss=0.915]\u001b[A\n",
      "Training:  19%|█▉        | 94/500 [01:02<02:20,  2.89it/s, train loss=0.838, val loss=0.915]\u001b[A\n",
      "Training:  19%|█▉        | 94/500 [01:02<02:20,  2.89it/s, train loss=0.837, val loss=0.923]\u001b[A\n",
      "Training:  19%|█▉        | 95/500 [01:02<02:20,  2.89it/s, train loss=0.835, val loss=0.907]\u001b[A\n",
      "Training:  19%|█▉        | 96/500 [01:03<02:27,  2.74it/s, train loss=0.835, val loss=0.907]\u001b[A\n",
      "Training:  19%|█▉        | 96/500 [01:03<02:27,  2.74it/s, train loss=0.836, val loss=0.915]\u001b[A\n",
      "Training:  19%|█▉        | 97/500 [01:03<02:27,  2.74it/s, train loss=0.833, val loss=0.911]\u001b[A\n",
      "Training:  20%|█▉        | 98/500 [01:03<02:26,  2.74it/s, train loss=0.835, val loss=0.904]\u001b[A\n",
      "Training:  20%|█▉        | 99/500 [01:04<02:17,  2.93it/s, train loss=0.835, val loss=0.904]\u001b[A\n",
      "Training:  20%|█▉        | 99/500 [01:04<02:17,  2.93it/s, train loss=0.832, val loss=0.908]\u001b[A\n",
      "Training:  20%|██        | 100/500 [01:04<02:16,  2.93it/s, train loss=0.832, val loss=0.914]\u001b[A\n",
      "Training:  20%|██        | 101/500 [01:04<02:16,  2.93it/s, train loss=0.828, val loss=0.906]\u001b[A\n",
      "Training:  20%|██        | 102/500 [01:04<02:16,  2.93it/s, train loss=0.828, val loss=0.905]\u001b[A\n",
      "Training:  21%|██        | 103/500 [01:04<02:15,  2.93it/s, train loss=0.826, val loss=0.901]\u001b[A\n",
      "Training:  21%|██        | 104/500 [01:05<01:47,  3.70it/s, train loss=0.826, val loss=0.901]\u001b[A\n",
      "Training:  21%|██        | 104/500 [01:05<01:47,  3.70it/s, train loss=0.827, val loss=0.907]\u001b[A\n",
      "Training:  21%|██        | 105/500 [01:05<01:46,  3.70it/s, train loss=0.828, val loss=0.898]\u001b[A\n",
      "Training:  21%|██        | 106/500 [01:06<01:57,  3.36it/s, train loss=0.828, val loss=0.898]\u001b[A\n",
      "Training:  21%|██        | 106/500 [01:06<01:57,  3.36it/s, train loss=0.829, val loss=0.906]\u001b[A\n",
      "Training:  21%|██▏       | 107/500 [01:06<01:56,  3.36it/s, train loss=0.829, val loss=0.896]\u001b[A\n",
      "Training:  22%|██▏       | 108/500 [01:07<02:08,  3.05it/s, train loss=0.829, val loss=0.896]\u001b[A\n",
      "Training:  22%|██▏       | 108/500 [01:07<02:08,  3.05it/s, train loss=0.828, val loss=0.901]\u001b[A\n",
      "Training:  22%|██▏       | 109/500 [01:07<02:08,  3.05it/s, train loss=0.832, val loss=0.907]\u001b[A\n",
      "Training:  22%|██▏       | 110/500 [01:07<02:07,  3.05it/s, train loss=0.832, val loss=0.911]\u001b[A\n",
      "Training:  22%|██▏       | 111/500 [01:07<02:07,  3.05it/s, train loss=0.823, val loss=0.898]\u001b[A\n",
      "Training:  22%|██▏       | 112/500 [01:07<02:07,  3.05it/s, train loss=0.819, val loss=0.898]\u001b[A\n",
      "Training:  23%|██▎       | 113/500 [01:07<01:13,  5.24it/s, train loss=0.819, val loss=0.898]\u001b[A\n",
      "Training:  23%|██▎       | 113/500 [01:07<01:13,  5.24it/s, train loss=0.837, val loss=0.915]\u001b[A\n",
      "Training:  23%|██▎       | 114/500 [01:07<01:13,  5.24it/s, train loss=0.818, val loss=0.886]\u001b[A\n",
      "Training:  23%|██▎       | 115/500 [01:08<01:32,  4.18it/s, train loss=0.818, val loss=0.886]\u001b[A\n",
      "Training:  23%|██▎       | 115/500 [01:08<01:32,  4.18it/s, train loss=0.82, val loss=0.897] \u001b[A\n",
      "Training:  23%|██▎       | 116/500 [01:08<01:31,  4.18it/s, train loss=0.816, val loss=0.886]\u001b[A\n",
      "Training:  23%|██▎       | 117/500 [01:09<01:48,  3.53it/s, train loss=0.816, val loss=0.886]\u001b[A\n",
      "Training:  23%|██▎       | 117/500 [01:09<01:48,  3.53it/s, train loss=0.822, val loss=0.89] \u001b[A\n",
      "Training:  24%|██▎       | 118/500 [01:09<01:48,  3.53it/s, train loss=0.815, val loss=0.88]\u001b[A\n",
      "Training:  24%|██▍       | 119/500 [01:09<01:59,  3.18it/s, train loss=0.815, val loss=0.88]\u001b[A\n",
      "Training:  24%|██▍       | 119/500 [01:09<01:59,  3.18it/s, train loss=0.831, val loss=0.898]\u001b[A\n",
      "Training:  24%|██▍       | 120/500 [01:09<01:59,  3.18it/s, train loss=0.811, val loss=0.873]\u001b[A\n",
      "Training:  24%|██▍       | 121/500 [01:10<02:11,  2.89it/s, train loss=0.811, val loss=0.873]\u001b[A\n",
      "Training:  24%|██▍       | 121/500 [01:10<02:11,  2.89it/s, train loss=0.809, val loss=0.887]\u001b[A\n",
      "Training:  24%|██▍       | 122/500 [01:10<02:10,  2.89it/s, train loss=0.808, val loss=0.879]\u001b[A\n",
      "Training:  25%|██▍       | 123/500 [01:10<02:10,  2.89it/s, train loss=0.811, val loss=0.882]\u001b[A\n",
      "Training:  25%|██▍       | 124/500 [01:10<02:10,  2.89it/s, train loss=0.806, val loss=0.878]\u001b[A\n",
      "Training:  25%|██▌       | 125/500 [01:10<02:09,  2.89it/s, train loss=0.813, val loss=0.879]\u001b[A\n",
      "Training:  25%|██▌       | 126/500 [01:10<01:11,  5.23it/s, train loss=0.813, val loss=0.879]\u001b[A\n",
      "Training:  25%|██▌       | 126/500 [01:10<01:11,  5.23it/s, train loss=0.808, val loss=0.887]\u001b[A\n",
      "Training:  25%|██▌       | 127/500 [01:10<01:11,  5.23it/s, train loss=0.811, val loss=0.877]\u001b[A\n",
      "Training:  26%|██▌       | 128/500 [01:10<01:11,  5.23it/s, train loss=0.825, val loss=0.894]\u001b[A\n",
      "Training:  26%|██▌       | 129/500 [01:10<01:10,  5.23it/s, train loss=0.813, val loss=0.887]\u001b[A\n",
      "Training:  26%|██▌       | 130/500 [01:10<01:10,  5.23it/s, train loss=0.804, val loss=0.869]\u001b[A\n",
      "Training:  26%|██▌       | 131/500 [01:11<01:09,  5.30it/s, train loss=0.804, val loss=0.869]\u001b[A\n",
      "Training:  26%|██▌       | 131/500 [01:11<01:09,  5.30it/s, train loss=0.805, val loss=0.877]\u001b[A\n",
      "Training:  26%|██▋       | 132/500 [01:11<01:09,  5.30it/s, train loss=0.804, val loss=0.876]\u001b[A\n",
      "Training:  27%|██▋       | 133/500 [01:11<01:09,  5.30it/s, train loss=0.806, val loss=0.878]\u001b[A\n",
      "Training:  27%|██▋       | 134/500 [01:11<01:09,  5.30it/s, train loss=0.809, val loss=0.879]\u001b[A\n",
      "Training:  27%|██▋       | 135/500 [01:11<01:08,  5.30it/s, train loss=0.804, val loss=0.874]\u001b[A\n",
      "Training:  27%|██▋       | 136/500 [01:11<00:46,  7.84it/s, train loss=0.804, val loss=0.874]\u001b[A\n",
      "Training:  27%|██▋       | 136/500 [01:11<00:46,  7.84it/s, train loss=0.8, val loss=0.871]  \u001b[A\n",
      "Training:  27%|██▋       | 137/500 [01:11<00:46,  7.84it/s, train loss=0.802, val loss=0.875]\u001b[A\n",
      "Training:  28%|██▊       | 138/500 [01:11<00:46,  7.84it/s, train loss=0.812, val loss=0.881]\u001b[A\n",
      "Training:  28%|██▊       | 139/500 [01:11<00:46,  7.84it/s, train loss=0.797, val loss=0.864]\u001b[A\n",
      "Training:  28%|██▊       | 140/500 [01:12<00:55,  6.51it/s, train loss=0.797, val loss=0.864]\u001b[A\n",
      "Training:  28%|██▊       | 140/500 [01:12<00:55,  6.51it/s, train loss=0.8, val loss=0.875]  \u001b[A\n",
      "Training:  28%|██▊       | 141/500 [01:12<00:55,  6.51it/s, train loss=0.797, val loss=0.869]\u001b[A\n",
      "Training:  28%|██▊       | 142/500 [01:12<00:55,  6.51it/s, train loss=0.8, val loss=0.868]  \u001b[A\n",
      "Training:  29%|██▊       | 143/500 [01:12<00:54,  6.51it/s, train loss=0.798, val loss=0.864]\u001b[A\n",
      "Training:  29%|██▉       | 144/500 [01:12<00:54,  6.51it/s, train loss=0.795, val loss=0.864]\u001b[A\n",
      "Training:  29%|██▉       | 145/500 [01:12<00:38,  9.20it/s, train loss=0.795, val loss=0.864]\u001b[A\n",
      "Training:  29%|██▉       | 145/500 [01:12<00:38,  9.20it/s, train loss=0.796, val loss=0.863]\u001b[A\n",
      "Training:  29%|██▉       | 146/500 [01:13<00:38,  9.20it/s, train loss=0.802, val loss=0.866]\u001b[A\n",
      "Training:  29%|██▉       | 147/500 [01:13<00:38,  9.20it/s, train loss=0.794, val loss=0.864]\u001b[A\n",
      "Training:  30%|██▉       | 148/500 [01:13<00:52,  6.68it/s, train loss=0.794, val loss=0.864]\u001b[A\n",
      "Training:  30%|██▉       | 148/500 [01:13<00:52,  6.68it/s, train loss=0.795, val loss=0.864]\u001b[A\n",
      "Training:  30%|██▉       | 149/500 [01:13<00:52,  6.68it/s, train loss=0.794, val loss=0.869]\u001b[A\n",
      "Training:  30%|███       | 150/500 [01:13<00:52,  6.68it/s, train loss=0.791, val loss=0.866]\u001b[A\n",
      "Training:  30%|███       | 151/500 [01:13<00:52,  6.68it/s, train loss=0.798, val loss=0.863]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 152/500 [01:13<00:52,  6.68it/s, train loss=0.796, val loss=0.862]\u001b[A\n",
      "Training:  31%|███       | 153/500 [01:14<00:56,  6.15it/s, train loss=0.796, val loss=0.862]\u001b[A\n",
      "Training:  31%|███       | 153/500 [01:14<00:56,  6.15it/s, train loss=0.793, val loss=0.862]\u001b[A\n",
      "Training:  31%|███       | 154/500 [01:15<00:56,  6.15it/s, train loss=0.794, val loss=0.865]\u001b[A\n",
      "Training:  31%|███       | 155/500 [01:15<01:11,  4.81it/s, train loss=0.794, val loss=0.865]\u001b[A\n",
      "Training:  31%|███       | 155/500 [01:15<01:11,  4.81it/s, train loss=0.793, val loss=0.866]\u001b[A\n",
      "Training:  31%|███       | 156/500 [01:15<01:11,  4.81it/s, train loss=0.8, val loss=0.868]  \u001b[A\n",
      "Training:  31%|███▏      | 157/500 [01:15<01:11,  4.81it/s, train loss=0.793, val loss=0.864]\u001b[A\n",
      "Training:  32%|███▏      | 158/500 [01:15<01:11,  4.81it/s, train loss=0.791, val loss=0.861]\u001b[A\n",
      "Training:  32%|███▏      | 159/500 [01:16<01:13,  4.67it/s, train loss=0.791, val loss=0.861]\u001b[A\n",
      "Training:  32%|███▏      | 159/500 [01:16<01:13,  4.67it/s, train loss=0.791, val loss=0.864]\u001b[A\n",
      "Training:  32%|███▏      | 160/500 [01:16<01:12,  4.67it/s, train loss=0.788, val loss=0.856]\u001b[A\n",
      "Training:  32%|███▏      | 161/500 [01:17<01:25,  3.97it/s, train loss=0.788, val loss=0.856]\u001b[A\n",
      "Training:  32%|███▏      | 161/500 [01:17<01:25,  3.97it/s, train loss=0.797, val loss=0.871]\u001b[A\n",
      "Training:  32%|███▏      | 162/500 [01:17<01:25,  3.97it/s, train loss=0.8, val loss=0.869]  \u001b[A\n",
      "Training:  33%|███▎      | 163/500 [01:17<01:24,  3.97it/s, train loss=0.787, val loss=0.851]\u001b[A\n",
      "Training:  33%|███▎      | 164/500 [01:18<01:28,  3.79it/s, train loss=0.787, val loss=0.851]\u001b[A\n",
      "Training:  33%|███▎      | 164/500 [01:18<01:28,  3.79it/s, train loss=0.788, val loss=0.86] \u001b[A\n",
      "Training:  33%|███▎      | 165/500 [01:18<01:28,  3.79it/s, train loss=0.789, val loss=0.862]\u001b[A\n",
      "Training:  33%|███▎      | 166/500 [01:18<01:28,  3.79it/s, train loss=0.786, val loss=0.859]\u001b[A\n",
      "Training:  33%|███▎      | 167/500 [01:18<01:27,  3.79it/s, train loss=0.785, val loss=0.848]\u001b[A\n",
      "Training:  34%|███▎      | 168/500 [01:19<01:23,  4.00it/s, train loss=0.785, val loss=0.848]\u001b[A\n",
      "Training:  34%|███▎      | 168/500 [01:19<01:23,  4.00it/s, train loss=0.786, val loss=0.854]\u001b[A\n",
      "Training:  34%|███▍      | 169/500 [01:19<01:22,  4.00it/s, train loss=0.786, val loss=0.854]\u001b[A\n",
      "Training:  34%|███▍      | 170/500 [01:19<01:22,  4.00it/s, train loss=0.787, val loss=0.861]\u001b[A\n",
      "Training:  34%|███▍      | 171/500 [01:19<01:22,  4.00it/s, train loss=0.788, val loss=0.856]\u001b[A\n",
      "Training:  34%|███▍      | 172/500 [01:19<01:22,  4.00it/s, train loss=0.787, val loss=0.854]\u001b[A\n",
      "Training:  35%|███▍      | 173/500 [01:19<00:53,  6.15it/s, train loss=0.787, val loss=0.854]\u001b[A\n",
      "Training:  35%|███▍      | 173/500 [01:19<00:53,  6.15it/s, train loss=0.784, val loss=0.858]\u001b[A\n",
      "Training:  35%|███▍      | 174/500 [01:19<00:52,  6.15it/s, train loss=0.792, val loss=0.869]\u001b[A\n",
      "Training:  35%|███▌      | 175/500 [01:19<00:52,  6.15it/s, train loss=0.799, val loss=0.87] \u001b[A\n",
      "Training:  35%|███▌      | 176/500 [01:19<00:52,  6.15it/s, train loss=0.782, val loss=0.852]\u001b[A\n",
      "Training:  35%|███▌      | 177/500 [01:19<00:52,  6.15it/s, train loss=0.785, val loss=0.854]\u001b[A\n",
      "Training:  36%|███▌      | 178/500 [01:19<00:36,  8.85it/s, train loss=0.785, val loss=0.854]\u001b[A\n",
      "Training:  36%|███▌      | 178/500 [01:19<00:36,  8.85it/s, train loss=0.782, val loss=0.852]\u001b[A\n",
      "Training:  36%|███▌      | 179/500 [01:19<00:36,  8.85it/s, train loss=0.793, val loss=0.862]\u001b[A\n",
      "Training:  36%|███▌      | 180/500 [01:19<00:36,  8.85it/s, train loss=0.797, val loss=0.871]\u001b[A\n",
      "Training:  36%|███▌      | 181/500 [01:19<00:36,  8.85it/s, train loss=0.78, val loss=0.85]  \u001b[A\n",
      "Training:  36%|███▋      | 182/500 [01:19<00:35,  8.85it/s, train loss=0.794, val loss=0.86]\u001b[A\n",
      "Training:  37%|███▋      | 183/500 [01:19<00:26, 12.08it/s, train loss=0.794, val loss=0.86]\u001b[A\n",
      "Training:  37%|███▋      | 183/500 [01:19<00:26, 12.08it/s, train loss=0.781, val loss=0.849]\u001b[A\n",
      "Training:  37%|███▋      | 184/500 [01:19<00:26, 12.08it/s, train loss=0.784, val loss=0.854]\u001b[A\n",
      "Training:  37%|███▋      | 185/500 [01:19<00:26, 12.08it/s, train loss=0.788, val loss=0.868]\u001b[A\n",
      "Training:  37%|███▋      | 186/500 [01:19<00:25, 12.08it/s, train loss=0.786, val loss=0.856]\u001b[A\n",
      "Training:  37%|███▋      | 187/500 [01:19<00:25, 12.08it/s, train loss=0.779, val loss=0.846]\u001b[A\n",
      "Training:  38%|███▊      | 188/500 [01:20<00:36,  8.64it/s, train loss=0.779, val loss=0.846]\u001b[A\n",
      "Training:  38%|███▊      | 188/500 [01:20<00:36,  8.64it/s, train loss=0.799, val loss=0.87] \u001b[A\n",
      "Training:  38%|███▊      | 189/500 [01:20<00:35,  8.64it/s, train loss=0.794, val loss=0.865]\u001b[A\n",
      "Training:  38%|███▊      | 190/500 [01:20<00:35,  8.64it/s, train loss=0.778, val loss=0.845]\u001b[A\n",
      "Training:  38%|███▊      | 191/500 [01:21<00:46,  6.64it/s, train loss=0.778, val loss=0.845]\u001b[A\n",
      "Training:  38%|███▊      | 191/500 [01:21<00:46,  6.64it/s, train loss=0.783, val loss=0.859]\u001b[A\n",
      "Training:  38%|███▊      | 192/500 [01:21<00:46,  6.64it/s, train loss=0.79, val loss=0.857] \u001b[A\n",
      "Training:  39%|███▊      | 193/500 [01:21<00:46,  6.64it/s, train loss=0.787, val loss=0.86]\u001b[A\n",
      "Training:  39%|███▉      | 194/500 [01:21<00:46,  6.64it/s, train loss=0.784, val loss=0.853]\u001b[A\n",
      "Training:  39%|███▉      | 195/500 [01:21<00:45,  6.64it/s, train loss=0.784, val loss=0.847]\u001b[A\n",
      "Training:  39%|███▉      | 196/500 [01:21<00:32,  9.36it/s, train loss=0.784, val loss=0.847]\u001b[A\n",
      "Training:  39%|███▉      | 196/500 [01:21<00:32,  9.36it/s, train loss=0.782, val loss=0.85] \u001b[A\n",
      "Training:  39%|███▉      | 197/500 [01:21<00:32,  9.36it/s, train loss=0.778, val loss=0.847]\u001b[A\n",
      "Training:  40%|███▉      | 198/500 [01:21<00:32,  9.36it/s, train loss=0.776, val loss=0.848]\u001b[A\n",
      "Training:  40%|███▉      | 199/500 [01:21<00:32,  9.36it/s, train loss=0.778, val loss=0.843]\u001b[A\n",
      "Training:  40%|████      | 200/500 [01:22<00:42,  7.03it/s, train loss=0.778, val loss=0.843]\u001b[A\n",
      "Training:  40%|████      | 200/500 [01:22<00:42,  7.03it/s, train loss=0.783, val loss=0.853]\u001b[A\n",
      "Training:  40%|████      | 201/500 [01:22<00:42,  7.03it/s, train loss=0.779, val loss=0.853]\u001b[A\n",
      "Training:  40%|████      | 202/500 [01:22<00:42,  7.03it/s, train loss=0.776, val loss=0.845]\u001b[A\n",
      "Training:  41%|████      | 203/500 [01:22<00:42,  7.03it/s, train loss=0.777, val loss=0.845]\u001b[A\n",
      "Training:  41%|████      | 204/500 [01:22<00:42,  7.03it/s, train loss=0.793, val loss=0.861]\u001b[A\n",
      "Training:  41%|████      | 205/500 [01:22<00:30,  9.77it/s, train loss=0.793, val loss=0.861]\u001b[A\n",
      "Training:  41%|████      | 205/500 [01:22<00:30,  9.77it/s, train loss=0.788, val loss=0.85] \u001b[A\n",
      "Training:  41%|████      | 206/500 [01:22<00:30,  9.77it/s, train loss=0.776, val loss=0.843]\u001b[A\n",
      "Training:  41%|████▏     | 207/500 [01:23<00:30,  9.77it/s, train loss=0.775, val loss=0.842]\u001b[A\n",
      "Training:  42%|████▏     | 208/500 [01:23<00:59,  4.89it/s, train loss=0.775, val loss=0.842]\u001b[A\n",
      "Training:  42%|████▏     | 208/500 [01:23<00:59,  4.89it/s, train loss=0.777, val loss=0.85] \u001b[A\n",
      "Training:  42%|████▏     | 209/500 [01:24<00:59,  4.89it/s, train loss=0.78, val loss=0.847]\u001b[A\n",
      "Training:  42%|████▏     | 210/500 [01:24<00:59,  4.89it/s, train loss=0.777, val loss=0.848]\u001b[A\n",
      "Training:  42%|████▏     | 211/500 [01:24<00:59,  4.89it/s, train loss=0.776, val loss=0.845]\u001b[A\n",
      "Training:  42%|████▏     | 212/500 [01:24<00:58,  4.89it/s, train loss=0.779, val loss=0.849]\u001b[A\n",
      "Training:  43%|████▎     | 213/500 [01:24<00:40,  7.06it/s, train loss=0.779, val loss=0.849]\u001b[A\n",
      "Training:  43%|████▎     | 213/500 [01:24<00:40,  7.06it/s, train loss=0.785, val loss=0.858]\u001b[A\n",
      "Training:  43%|████▎     | 214/500 [01:24<00:40,  7.06it/s, train loss=0.781, val loss=0.853]\u001b[A\n",
      "Training:  43%|████▎     | 215/500 [01:24<00:40,  7.06it/s, train loss=0.775, val loss=0.846]\u001b[A\n",
      "Training:  43%|████▎     | 216/500 [01:24<00:40,  7.06it/s, train loss=0.774, val loss=0.839]\u001b[A\n",
      "Training:  43%|████▎     | 217/500 [01:24<00:46,  6.09it/s, train loss=0.774, val loss=0.839]\u001b[A\n",
      "Training:  43%|████▎     | 217/500 [01:24<00:46,  6.09it/s, train loss=0.784, val loss=0.862]\u001b[A\n",
      "Training:  44%|████▎     | 218/500 [01:25<00:46,  6.09it/s, train loss=0.776, val loss=0.848]\u001b[A\n",
      "Training:  44%|████▍     | 219/500 [01:25<00:46,  6.09it/s, train loss=0.784, val loss=0.85] \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▍     | 220/500 [01:25<00:46,  6.09it/s, train loss=0.776, val loss=0.845]\u001b[A\n",
      "Training:  44%|████▍     | 221/500 [01:25<00:45,  6.09it/s, train loss=0.773, val loss=0.842]\u001b[A\n",
      "Training:  44%|████▍     | 222/500 [01:25<00:32,  8.57it/s, train loss=0.773, val loss=0.842]\u001b[A\n",
      "Training:  44%|████▍     | 222/500 [01:25<00:32,  8.57it/s, train loss=0.776, val loss=0.843]\u001b[A\n",
      "Training:  45%|████▍     | 223/500 [01:25<00:32,  8.57it/s, train loss=0.774, val loss=0.843]\u001b[A\n",
      "Training:  45%|████▍     | 224/500 [01:25<00:32,  8.57it/s, train loss=0.775, val loss=0.845]\u001b[A\n",
      "Training:  45%|████▌     | 225/500 [01:25<00:32,  8.57it/s, train loss=0.778, val loss=0.851]\u001b[A\n",
      "Training:  45%|████▌     | 226/500 [01:25<00:31,  8.57it/s, train loss=0.773, val loss=0.847]\u001b[A\n",
      "Training:  45%|████▌     | 227/500 [01:25<00:23, 11.60it/s, train loss=0.773, val loss=0.847]\u001b[A\n",
      "Training:  45%|████▌     | 227/500 [01:25<00:23, 11.60it/s, train loss=0.776, val loss=0.838]\u001b[A\n",
      "Training:  46%|████▌     | 228/500 [01:26<00:23, 11.60it/s, train loss=0.78, val loss=0.848] \u001b[A\n",
      "Training:  46%|████▌     | 229/500 [01:26<00:23, 11.60it/s, train loss=0.774, val loss=0.838]\u001b[A\n",
      "Training:  46%|████▌     | 230/500 [01:26<00:23, 11.60it/s, train loss=0.773, val loss=0.843]\u001b[A\n",
      "Training:  46%|████▌     | 231/500 [01:26<00:33,  7.98it/s, train loss=0.773, val loss=0.843]\u001b[A\n",
      "Training:  46%|████▌     | 231/500 [01:26<00:33,  7.98it/s, train loss=0.773, val loss=0.848]\u001b[A\n",
      "Training:  46%|████▋     | 232/500 [01:26<00:33,  7.98it/s, train loss=0.781, val loss=0.843]\u001b[A\n",
      "Training:  47%|████▋     | 233/500 [01:26<00:33,  7.98it/s, train loss=0.776, val loss=0.85] \u001b[A\n",
      "Training:  47%|████▋     | 234/500 [01:26<00:33,  7.98it/s, train loss=0.778, val loss=0.844]\u001b[A\n",
      "Training:  47%|████▋     | 235/500 [01:26<00:33,  7.98it/s, train loss=0.771, val loss=0.839]\u001b[A\n",
      "Training:  47%|████▋     | 236/500 [01:26<00:24, 10.87it/s, train loss=0.771, val loss=0.839]\u001b[A\n",
      "Training:  47%|████▋     | 236/500 [01:26<00:24, 10.87it/s, train loss=0.771, val loss=0.842]\u001b[A\n",
      "Training:  47%|████▋     | 237/500 [01:26<00:24, 10.87it/s, train loss=0.773, val loss=0.844]\u001b[A\n",
      "Training:  48%|████▊     | 238/500 [01:26<00:24, 10.87it/s, train loss=0.77, val loss=0.839] \u001b[A\n",
      "Training:  48%|████▊     | 239/500 [01:26<00:24, 10.87it/s, train loss=0.774, val loss=0.839]\u001b[A\n",
      "Training:  48%|████▊     | 240/500 [01:26<00:23, 10.87it/s, train loss=0.774, val loss=0.844]\u001b[A\n",
      "Training:  48%|████▊     | 241/500 [01:26<00:18, 14.28it/s, train loss=0.774, val loss=0.844]\u001b[A\n",
      "Training:  48%|████▊     | 241/500 [01:26<00:18, 14.28it/s, train loss=0.778, val loss=0.848]\u001b[A\n",
      "Training:  48%|████▊     | 242/500 [01:26<00:18, 14.28it/s, train loss=0.787, val loss=0.861]\u001b[A\n",
      "Training:  49%|████▊     | 243/500 [01:26<00:17, 14.28it/s, train loss=0.776, val loss=0.834]\u001b[A\n",
      "Training:  49%|████▉     | 244/500 [01:27<00:17, 14.28it/s, train loss=0.778, val loss=0.846]\u001b[A\n",
      "Training:  49%|████▉     | 245/500 [01:27<00:27,  9.14it/s, train loss=0.778, val loss=0.846]\u001b[A\n",
      "Training:  49%|████▉     | 245/500 [01:27<00:27,  9.14it/s, train loss=0.773, val loss=0.842]\u001b[A\n",
      "Training:  49%|████▉     | 246/500 [01:27<00:27,  9.14it/s, train loss=0.777, val loss=0.853]\u001b[A\n",
      "Training:  49%|████▉     | 247/500 [01:27<00:27,  9.14it/s, train loss=0.777, val loss=0.84] \u001b[A\n",
      "Training:  50%|████▉     | 248/500 [01:27<00:27,  9.14it/s, train loss=0.774, val loss=0.844]\u001b[A\n",
      "Training:  50%|████▉     | 249/500 [01:27<00:27,  9.14it/s, train loss=0.778, val loss=0.847]\u001b[A\n",
      "Training:  50%|█████     | 250/500 [01:27<00:20, 12.26it/s, train loss=0.778, val loss=0.847]\u001b[A\n",
      "Training:  50%|█████     | 250/500 [01:27<00:20, 12.26it/s, train loss=0.769, val loss=0.84] \u001b[A\n",
      "Training:  50%|█████     | 251/500 [01:27<00:20, 12.26it/s, train loss=0.771, val loss=0.837]\u001b[A\n",
      "Training:  50%|█████     | 252/500 [01:27<00:20, 12.26it/s, train loss=0.777, val loss=0.855]\u001b[A\n",
      "Training:  51%|█████     | 253/500 [01:27<00:20, 12.26it/s, train loss=0.769, val loss=0.837]\u001b[A\n",
      "Training:  51%|█████     | 254/500 [01:27<00:20, 12.26it/s, train loss=0.772, val loss=0.835]\u001b[A\n",
      "Training:  51%|█████     | 255/500 [01:27<00:15, 15.84it/s, train loss=0.772, val loss=0.835]\u001b[A\n",
      "Training:  51%|█████     | 255/500 [01:27<00:15, 15.84it/s, train loss=0.776, val loss=0.849]\u001b[A\n",
      "Training:  51%|█████     | 256/500 [01:27<00:15, 15.84it/s, train loss=0.772, val loss=0.836]\u001b[A\n",
      "Training:  51%|█████▏    | 257/500 [01:27<00:15, 15.84it/s, train loss=0.777, val loss=0.852]\u001b[A\n",
      "Training:  52%|█████▏    | 258/500 [01:27<00:15, 15.84it/s, train loss=0.77, val loss=0.843] \u001b[A\n",
      "Training:  52%|█████▏    | 259/500 [01:27<00:15, 15.84it/s, train loss=0.768, val loss=0.838]\u001b[A\n",
      "Training:  52%|█████▏    | 260/500 [01:27<00:12, 19.72it/s, train loss=0.768, val loss=0.838]\u001b[A\n",
      "Training:  52%|█████▏    | 260/500 [01:27<00:12, 19.72it/s, train loss=0.774, val loss=0.844]\u001b[A\n",
      "Training:  52%|█████▏    | 261/500 [01:27<00:12, 19.72it/s, train loss=0.771, val loss=0.839]\u001b[A\n",
      "Training:  52%|█████▏    | 262/500 [01:27<00:12, 19.72it/s, train loss=0.768, val loss=0.838]\u001b[A\n",
      "Training:  53%|█████▎    | 263/500 [01:27<00:12, 19.72it/s, train loss=0.782, val loss=0.856]\u001b[A\n",
      "\n",
      "Training:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Training:   0%|          | 0/500 [00:00<?, ?it/s, train loss=0, val loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Training:   0%|          | 1/500 [00:00<06:21,  1.31it/s, train loss=0, val loss=0]\u001b[A\u001b[A\n",
      "\n",
      "Training:   0%|          | 1/500 [00:00<06:21,  1.31it/s, train loss=2.85, val loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "Training:   0%|          | 2/500 [00:01<08:38,  1.04s/it, train loss=2.85, val loss=2.93]\u001b[A\u001b[A\n",
      "\n",
      "Training:   0%|          | 2/500 [00:02<08:38,  1.04s/it, train loss=2.45, val loss=2.48]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 3/500 [00:02<08:07,  1.02it/s, train loss=2.45, val loss=2.48]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 3/500 [00:02<08:07,  1.02it/s, train loss=2.12, val loss=2.14]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 4/500 [00:03<07:47,  1.06it/s, train loss=2.12, val loss=2.14]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 4/500 [00:03<07:47,  1.06it/s, train loss=1.85, val loss=1.87]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 5/500 [00:04<07:33,  1.09it/s, train loss=1.85, val loss=1.87]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 5/500 [00:04<07:33,  1.09it/s, train loss=1.69, val loss=1.7] \u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 6/500 [00:05<07:26,  1.11it/s, train loss=1.69, val loss=1.7]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|          | 6/500 [00:05<07:26,  1.11it/s, train loss=1.6, val loss=1.61]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|▏         | 7/500 [00:06<07:23,  1.11it/s, train loss=1.6, val loss=1.61]\u001b[A\u001b[A\n",
      "\n",
      "Training:   1%|▏         | 7/500 [00:06<07:23,  1.11it/s, train loss=1.52, val loss=1.53]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 8/500 [00:07<07:14,  1.13it/s, train loss=1.52, val loss=1.53]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 8/500 [00:07<07:14,  1.13it/s, train loss=1.47, val loss=1.47]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 9/500 [00:08<07:09,  1.14it/s, train loss=1.47, val loss=1.47]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 9/500 [00:08<07:09,  1.14it/s, train loss=1.42, val loss=1.41]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 10/500 [00:08<07:06,  1.15it/s, train loss=1.42, val loss=1.41]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 10/500 [00:09<07:06,  1.15it/s, train loss=1.38, val loss=1.35]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 11/500 [00:09<07:11,  1.13it/s, train loss=1.38, val loss=1.35]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 11/500 [00:09<07:11,  1.13it/s, train loss=1.33, val loss=1.31]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 12/500 [00:10<07:08,  1.14it/s, train loss=1.33, val loss=1.31]\u001b[A\u001b[A\n",
      "\n",
      "Training:   2%|▏         | 12/500 [00:10<07:08,  1.14it/s, train loss=1.3, val loss=1.26] \u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 13/500 [00:11<07:10,  1.13it/s, train loss=1.3, val loss=1.26]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 13/500 [00:11<07:10,  1.13it/s, train loss=1.27, val loss=1.23]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 14/500 [00:12<07:06,  1.14it/s, train loss=1.27, val loss=1.23]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 14/500 [00:12<07:06,  1.14it/s, train loss=1.24, val loss=1.21]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 15/500 [00:13<07:06,  1.14it/s, train loss=1.24, val loss=1.21]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 15/500 [00:13<07:06,  1.14it/s, train loss=1.21, val loss=1.18]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 16/500 [00:14<07:06,  1.14it/s, train loss=1.21, val loss=1.18]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 16/500 [00:14<07:06,  1.14it/s, train loss=1.19, val loss=1.14]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 17/500 [00:15<07:07,  1.13it/s, train loss=1.19, val loss=1.14]\u001b[A\u001b[A\n",
      "\n",
      "Training:   3%|▎         | 17/500 [00:15<07:07,  1.13it/s, train loss=1.17, val loss=1.13]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▎         | 18/500 [00:16<07:03,  1.14it/s, train loss=1.17, val loss=1.13]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▎         | 18/500 [00:16<07:03,  1.14it/s, train loss=1.16, val loss=1.13]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 19/500 [00:16<07:01,  1.14it/s, train loss=1.16, val loss=1.13]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 19/500 [00:16<07:01,  1.14it/s, train loss=1.13, val loss=1.08]\u001b[A\u001b[A\n",
      "Training:  53%|█████▎    | 263/500 [01:45<00:12, 19.72it/s, train loss=0.782, val loss=0.856]\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 20/500 [00:17<07:00,  1.14it/s, train loss=1.13, val loss=1.08]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 20/500 [00:17<07:00,  1.14it/s, train loss=1.11, val loss=1.08]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 21/500 [00:18<06:57,  1.15it/s, train loss=1.11, val loss=1.08]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 21/500 [00:18<06:57,  1.15it/s, train loss=1.1, val loss=1.06] \u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 22/500 [00:19<06:56,  1.15it/s, train loss=1.1, val loss=1.06]\u001b[A\u001b[A\n",
      "\n",
      "Training:   4%|▍         | 22/500 [00:19<06:56,  1.15it/s, train loss=1.09, val loss=1.05]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▍         | 23/500 [00:20<06:56,  1.15it/s, train loss=1.09, val loss=1.05]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▍         | 23/500 [00:20<06:56,  1.15it/s, train loss=1.08, val loss=1.04]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▍         | 24/500 [00:21<07:37,  1.04it/s, train loss=1.08, val loss=1.04]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▍         | 24/500 [00:21<07:37,  1.04it/s, train loss=1.06, val loss=1.02]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▌         | 25/500 [00:22<07:24,  1.07it/s, train loss=1.06, val loss=1.02]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▌         | 25/500 [00:22<07:24,  1.07it/s, train loss=1.06, val loss=1.02]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▌         | 26/500 [00:22<07:23,  1.07it/s, train loss=1.05, val loss=0.994]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▌         | 27/500 [00:23<05:35,  1.41it/s, train loss=1.05, val loss=0.994]\u001b[A\u001b[A\n",
      "\n",
      "Training:   5%|▌         | 27/500 [00:23<05:35,  1.41it/s, train loss=1.03, val loss=0.979]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▌         | 28/500 [00:24<06:02,  1.30it/s, train loss=1.03, val loss=0.979]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▌         | 28/500 [00:24<06:02,  1.30it/s, train loss=1.02, val loss=0.98] \u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▌         | 29/500 [00:24<06:02,  1.30it/s, train loss=1.01, val loss=0.973]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▌         | 30/500 [00:25<05:01,  1.56it/s, train loss=1.01, val loss=0.973]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▌         | 30/500 [00:25<05:01,  1.56it/s, train loss=1.01, val loss=0.966]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▌         | 31/500 [00:26<05:26,  1.44it/s, train loss=1.01, val loss=0.966]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▌         | 31/500 [00:26<05:26,  1.44it/s, train loss=0.998, val loss=0.966]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▋         | 32/500 [00:26<05:47,  1.35it/s, train loss=0.998, val loss=0.966]\u001b[A\u001b[A\n",
      "\n",
      "Training:   6%|▋         | 32/500 [00:26<05:47,  1.35it/s, train loss=0.99, val loss=0.937] \u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 33/500 [00:27<06:04,  1.28it/s, train loss=0.99, val loss=0.937]\u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 33/500 [00:27<06:04,  1.28it/s, train loss=0.984, val loss=0.925]\u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 34/500 [00:28<06:17,  1.23it/s, train loss=0.984, val loss=0.925]\u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 34/500 [00:28<06:17,  1.23it/s, train loss=0.981, val loss=0.94] \u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 35/500 [00:28<06:16,  1.23it/s, train loss=0.973, val loss=0.903]\u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 36/500 [00:29<05:02,  1.53it/s, train loss=0.973, val loss=0.903]\u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 36/500 [00:29<05:02,  1.53it/s, train loss=0.968, val loss=0.909]\u001b[A\u001b[A\n",
      "\n",
      "Training:   7%|▋         | 37/500 [00:29<05:02,  1.53it/s, train loss=0.971, val loss=0.945]\u001b[A\u001b[A\n",
      "\n",
      "Training:   8%|▊         | 38/500 [00:29<05:01,  1.53it/s, train loss=0.949, val loss=0.905]\u001b[A\u001b[A\n",
      "\n",
      "Training:   8%|▊         | 39/500 [00:29<05:00,  1.53it/s, train loss=0.944, val loss=0.884]\u001b[A\u001b[A\n",
      "\n",
      "Training:   8%|▊         | 40/500 [00:30<03:15,  2.35it/s, train loss=0.944, val loss=0.884]\u001b[A\u001b[A\n",
      "\n",
      "Training:   8%|▊         | 40/500 [00:30<03:15,  2.35it/s, train loss=0.945, val loss=0.902]\u001b[A\u001b[A\n",
      "\n",
      "Training:   8%|▊         | 41/500 [00:30<03:15,  2.35it/s, train loss=0.945, val loss=0.906]\u001b[A\u001b[A\n",
      "\n",
      "Training:   8%|▊         | 42/500 [00:30<03:15,  2.35it/s, train loss=0.934, val loss=0.871]\u001b[A\u001b[A\n",
      "\n",
      "Training:   9%|▊         | 43/500 [00:31<02:57,  2.58it/s, train loss=0.934, val loss=0.871]\u001b[A\u001b[A\n",
      "\n",
      "Training:   9%|▊         | 43/500 [00:31<02:57,  2.58it/s, train loss=0.931, val loss=0.887]\u001b[A\u001b[A\n",
      "\n",
      "Training:   9%|▉         | 44/500 [00:31<02:57,  2.58it/s, train loss=0.926, val loss=0.892]\u001b[A\u001b[A\n",
      "\n",
      "Training:   9%|▉         | 45/500 [00:31<02:56,  2.58it/s, train loss=0.918, val loss=0.879]\u001b[A\u001b[A\n",
      "\n",
      "Training:   9%|▉         | 46/500 [00:31<02:56,  2.58it/s, train loss=0.922, val loss=0.861]\u001b[A\u001b[A\n",
      "\n",
      "Training:   9%|▉         | 47/500 [00:32<02:28,  3.05it/s, train loss=0.922, val loss=0.861]\u001b[A\u001b[A\n",
      "\n",
      "Training:   9%|▉         | 47/500 [00:32<02:28,  3.05it/s, train loss=0.915, val loss=0.851]\u001b[A\u001b[A\n",
      "\n",
      "Training:  10%|▉         | 48/500 [00:33<03:00,  2.51it/s, train loss=0.915, val loss=0.851]\u001b[A\u001b[A\n",
      "\n",
      "Training:  10%|▉         | 48/500 [00:33<03:00,  2.51it/s, train loss=0.909, val loss=0.864]\u001b[A\u001b[A\n",
      "\n",
      "Training:  10%|▉         | 49/500 [00:33<02:59,  2.51it/s, train loss=0.905, val loss=0.868]\u001b[A\u001b[A\n",
      "\n",
      "Training:  10%|█         | 50/500 [00:33<02:59,  2.51it/s, train loss=0.919, val loss=0.9]  \u001b[A\u001b[A\n",
      "\n",
      "Training:  10%|█         | 51/500 [00:33<02:58,  2.51it/s, train loss=0.895, val loss=0.847]\u001b[A\u001b[A\n",
      "\n",
      "Training:  10%|█         | 52/500 [00:34<02:26,  3.05it/s, train loss=0.895, val loss=0.847]\u001b[A\u001b[A\n",
      "\n",
      "Training:  10%|█         | 52/500 [00:34<02:26,  3.05it/s, train loss=0.897, val loss=0.836]\u001b[A\u001b[A\n",
      "\n",
      "Training:  11%|█         | 53/500 [00:35<03:02,  2.46it/s, train loss=0.897, val loss=0.836]\u001b[A\u001b[A\n",
      "\n",
      "Training:  11%|█         | 53/500 [00:35<03:02,  2.46it/s, train loss=0.894, val loss=0.85] \u001b[A\u001b[A\n",
      "\n",
      "Training:  11%|█         | 54/500 [00:35<03:01,  2.46it/s, train loss=0.9, val loss=0.844] \u001b[A\u001b[A\n",
      "\n",
      "Training:  11%|█         | 55/500 [00:35<03:01,  2.46it/s, train loss=0.884, val loss=0.837]\u001b[A\u001b[A\n",
      "\n",
      "Training:  11%|█         | 56/500 [00:35<03:00,  2.46it/s, train loss=0.894, val loss=0.862]\u001b[A\u001b[A\n",
      "\n",
      "Training:  11%|█▏        | 57/500 [00:35<03:00,  2.46it/s, train loss=0.883, val loss=0.835]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 58/500 [00:36<02:15,  3.27it/s, train loss=0.883, val loss=0.835]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 58/500 [00:36<02:15,  3.27it/s, train loss=0.881, val loss=0.83] \u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 59/500 [00:37<02:47,  2.64it/s, train loss=0.881, val loss=0.83]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 59/500 [00:37<02:47,  2.64it/s, train loss=0.875, val loss=0.824]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 60/500 [00:38<03:19,  2.20it/s, train loss=0.875, val loss=0.824]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 60/500 [00:38<03:19,  2.20it/s, train loss=0.877, val loss=0.824]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 61/500 [00:38<03:19,  2.20it/s, train loss=0.875, val loss=0.822]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 62/500 [00:39<03:19,  2.20it/s, train loss=0.875, val loss=0.822]\u001b[A\u001b[A\n",
      "\n",
      "Training:  12%|█▏        | 62/500 [00:39<03:19,  2.20it/s, train loss=0.871, val loss=0.813]\u001b[A\u001b[A\n",
      "\n",
      "Training:  13%|█▎        | 63/500 [00:39<03:48,  1.91it/s, train loss=0.871, val loss=0.813]\u001b[A\u001b[A\n",
      "\n",
      "Training:  13%|█▎        | 63/500 [00:39<03:48,  1.91it/s, train loss=0.869, val loss=0.813]\u001b[A\u001b[A\n",
      "\n",
      "Training:  13%|█▎        | 64/500 [00:40<04:18,  1.68it/s, train loss=0.869, val loss=0.813]\u001b[A\u001b[A\n",
      "\n",
      "Training:  13%|█▎        | 64/500 [00:40<04:18,  1.68it/s, train loss=0.874, val loss=0.813]\u001b[A\u001b[A\n",
      "\n",
      "Training:  13%|█▎        | 65/500 [00:40<04:18,  1.68it/s, train loss=0.87, val loss=0.813] \u001b[A\u001b[A\n",
      "\n",
      "Training:  13%|█▎        | 66/500 [00:40<04:17,  1.68it/s, train loss=0.872, val loss=0.808]\u001b[A\u001b[A\n",
      "\n",
      "Training:  13%|█▎        | 67/500 [00:41<03:18,  2.18it/s, train loss=0.872, val loss=0.808]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 67/500 [00:41<03:18,  2.18it/s, train loss=0.864, val loss=0.815]\u001b[A\u001b[A\n",
      "\n",
      "Training:  14%|█▎        | 68/500 [00:41<03:17,  2.18it/s, train loss=0.862, val loss=0.83] \u001b[A\u001b[A\n",
      "\n",
      "Training:  14%|█▍        | 69/500 [00:41<03:17,  2.18it/s, train loss=0.859, val loss=0.81]\u001b[A\u001b[A\n",
      "\n",
      "Training:  14%|█▍        | 70/500 [00:41<03:17,  2.18it/s, train loss=0.857, val loss=0.81]\u001b[A\u001b[A\n",
      "\n",
      "Training:  14%|█▍        | 71/500 [00:41<01:49,  3.91it/s, train loss=0.857, val loss=0.81]\u001b[A\u001b[A\n",
      "\n",
      "Training:  14%|█▍        | 71/500 [00:41<01:49,  3.91it/s, train loss=0.855, val loss=0.822]\u001b[A\u001b[A\n",
      "\n",
      "Training:  14%|█▍        | 72/500 [00:41<01:49,  3.91it/s, train loss=0.853, val loss=0.817]\u001b[A\u001b[A\n",
      "\n",
      "Training:  15%|█▍        | 73/500 [00:41<01:49,  3.91it/s, train loss=0.856, val loss=0.836]\u001b[A\u001b[A\n",
      "\n",
      "Training:  15%|█▍        | 74/500 [00:41<01:48,  3.91it/s, train loss=0.852, val loss=0.795]\u001b[A\u001b[A\n",
      "\n",
      "Training:  15%|█▌        | 75/500 [00:42<01:45,  4.02it/s, train loss=0.852, val loss=0.795]\u001b[A\u001b[A\n",
      "\n",
      "Training:  15%|█▌        | 75/500 [00:42<01:45,  4.02it/s, train loss=0.854, val loss=0.802]\u001b[A\u001b[A\n",
      "\n",
      "Training:  15%|█▌        | 76/500 [00:42<01:45,  4.02it/s, train loss=0.845, val loss=0.812]\u001b[A\u001b[A\n",
      "\n",
      "Training:  15%|█▌        | 77/500 [00:42<01:45,  4.02it/s, train loss=0.848, val loss=0.825]\u001b[A\u001b[A\n",
      "\n",
      "Training:  16%|█▌        | 78/500 [00:42<01:45,  4.02it/s, train loss=0.845, val loss=0.796]\u001b[A\u001b[A\n",
      "\n",
      "Training:  16%|█▌        | 79/500 [00:42<01:10,  5.97it/s, train loss=0.845, val loss=0.796]\u001b[A\u001b[A\n",
      "\n",
      "Training:  16%|█▌        | 79/500 [00:42<01:10,  5.97it/s, train loss=0.84, val loss=0.801] \u001b[A\u001b[A\n",
      "\n",
      "Training:  16%|█▌        | 80/500 [00:42<01:10,  5.97it/s, train loss=0.848, val loss=0.816]\u001b[A\u001b[A\n",
      "\n",
      "Training:  16%|█▌        | 81/500 [00:42<01:10,  5.97it/s, train loss=0.838, val loss=0.795]\u001b[A\u001b[A\n",
      "\n",
      "Training:  16%|█▋        | 82/500 [00:42<01:10,  5.97it/s, train loss=0.837, val loss=0.787]\u001b[A\u001b[A\n",
      "\n",
      "Training:  17%|█▋        | 83/500 [00:43<01:20,  5.19it/s, train loss=0.837, val loss=0.787]\u001b[A\u001b[A\n",
      "\n",
      "Training:  17%|█▋        | 83/500 [00:43<01:20,  5.19it/s, train loss=0.839, val loss=0.804]\u001b[A\u001b[A\n",
      "\n",
      "Training:  17%|█▋        | 84/500 [00:43<01:20,  5.19it/s, train loss=0.837, val loss=0.813]\u001b[A\u001b[A\n",
      "\n",
      "Training:  17%|█▋        | 85/500 [00:43<01:19,  5.19it/s, train loss=0.834, val loss=0.803]\u001b[A\u001b[A\n",
      "\n",
      "Training:  17%|█▋        | 86/500 [00:43<01:19,  5.19it/s, train loss=0.832, val loss=0.8]  \u001b[A\u001b[A\n",
      "\n",
      "Training:  17%|█▋        | 87/500 [00:43<00:56,  7.27it/s, train loss=0.832, val loss=0.8]\u001b[A\u001b[A\n",
      "\n",
      "Training:  17%|█▋        | 87/500 [00:43<00:56,  7.27it/s, train loss=0.836, val loss=0.801]\u001b[A\u001b[A\n",
      "\n",
      "Training:  18%|█▊        | 88/500 [00:43<00:56,  7.27it/s, train loss=0.836, val loss=0.787]\u001b[A\u001b[A\n",
      "\n",
      "Training:  18%|█▊        | 89/500 [00:44<00:56,  7.27it/s, train loss=0.837, val loss=0.79] \u001b[A\u001b[A\n",
      "\n",
      "Training:  18%|█▊        | 90/500 [00:44<01:14,  5.49it/s, train loss=0.837, val loss=0.79]\u001b[A\u001b[A\n",
      "\n",
      "Training:  18%|█▊        | 90/500 [00:44<01:14,  5.49it/s, train loss=0.841, val loss=0.794]\u001b[A\u001b[A\n",
      "\n",
      "Training:  18%|█▊        | 91/500 [00:44<01:14,  5.49it/s, train loss=0.829, val loss=0.79] \u001b[A\u001b[A\n",
      "\n",
      "Training:  18%|█▊        | 92/500 [00:44<01:14,  5.49it/s, train loss=0.831, val loss=0.782]\u001b[A\u001b[A\n",
      "\n",
      "Training:  19%|█▊        | 93/500 [00:45<01:28,  4.61it/s, train loss=0.831, val loss=0.782]\u001b[A\u001b[A\n",
      "\n",
      "Training:  19%|█▊        | 93/500 [00:45<01:28,  4.61it/s, train loss=0.833, val loss=0.79] \u001b[A\u001b[A\n",
      "\n",
      "Training:  19%|█▉        | 94/500 [00:45<01:28,  4.61it/s, train loss=0.826, val loss=0.788]\u001b[A\u001b[A\n",
      "\n",
      "Training:  19%|█▉        | 95/500 [00:45<01:27,  4.61it/s, train loss=0.825, val loss=0.783]\u001b[A\u001b[A\n",
      "\n",
      "Training:  19%|█▉        | 96/500 [00:45<01:27,  4.61it/s, train loss=0.823, val loss=0.785]\u001b[A\u001b[A\n",
      "\n",
      "Training:  19%|█▉        | 97/500 [00:45<01:01,  6.59it/s, train loss=0.823, val loss=0.785]\u001b[A\u001b[A\n",
      "\n",
      "Training:  19%|█▉        | 97/500 [00:45<01:01,  6.59it/s, train loss=0.824, val loss=0.775]\u001b[A\u001b[A\n",
      "\n",
      "Training:  20%|█▉        | 98/500 [00:46<01:01,  6.59it/s, train loss=0.83, val loss=0.819] \u001b[A\u001b[A\n",
      "\n",
      "Training:  20%|█▉        | 99/500 [00:46<01:00,  6.59it/s, train loss=0.82, val loss=0.786]\u001b[A\u001b[A\n",
      "\n",
      "Training:  20%|██        | 100/500 [00:46<01:17,  5.14it/s, train loss=0.82, val loss=0.786]\u001b[A\u001b[A\n",
      "\n",
      "Training:  20%|██        | 100/500 [00:46<01:17,  5.14it/s, train loss=0.82, val loss=0.786]\u001b[A\u001b[A\n",
      "\n",
      "Training:  20%|██        | 101/500 [00:46<01:17,  5.14it/s, train loss=0.826, val loss=0.773]\u001b[A\u001b[A\n",
      "\n",
      "Training:  20%|██        | 102/500 [00:47<01:38,  4.05it/s, train loss=0.826, val loss=0.773]\u001b[A\u001b[A\n",
      "\n",
      "Training:  20%|██        | 102/500 [00:47<01:38,  4.05it/s, train loss=0.818, val loss=0.782]\u001b[A\u001b[A\n",
      "\n",
      "Training:  21%|██        | 103/500 [00:47<01:38,  4.05it/s, train loss=0.821, val loss=0.782]\u001b[A\u001b[A\n",
      "\n",
      "Training:  21%|██        | 104/500 [00:47<01:37,  4.05it/s, train loss=0.825, val loss=0.781]\u001b[A\u001b[A\n",
      "\n",
      "Training:  21%|██        | 105/500 [00:47<01:37,  4.05it/s, train loss=0.821, val loss=0.781]\u001b[A\u001b[A\n",
      "\n",
      "Training:  21%|██        | 106/500 [00:47<01:05,  6.04it/s, train loss=0.821, val loss=0.781]\u001b[A\u001b[A\n",
      "\n",
      "Training:  21%|██        | 106/500 [00:47<01:05,  6.04it/s, train loss=0.818, val loss=0.79] \u001b[A\u001b[A\n",
      "\n",
      "Training:  21%|██▏       | 107/500 [00:47<01:05,  6.04it/s, train loss=0.831, val loss=0.803]\u001b[A\u001b[A\n",
      "\n",
      "Training:  22%|██▏       | 108/500 [00:47<01:04,  6.04it/s, train loss=0.826, val loss=0.814]\u001b[A\u001b[A\n",
      "\n",
      "Training:  22%|██▏       | 109/500 [00:47<01:04,  6.04it/s, train loss=0.815, val loss=0.773]\u001b[A\u001b[A\n",
      "\n",
      "Training:  22%|██▏       | 110/500 [00:48<01:15,  5.16it/s, train loss=0.815, val loss=0.773]\u001b[A\u001b[A\n",
      "\n",
      "Training:  22%|██▏       | 110/500 [00:48<01:15,  5.16it/s, train loss=0.812, val loss=0.788]\u001b[A\u001b[A\n",
      "\n",
      "Training:  22%|██▏       | 111/500 [00:48<01:15,  5.16it/s, train loss=0.816, val loss=0.778]\u001b[A\u001b[A\n",
      "\n",
      "Training:  22%|██▏       | 112/500 [00:48<01:15,  5.16it/s, train loss=0.822, val loss=0.769]\u001b[A\u001b[A\n",
      "\n",
      "Training:  23%|██▎       | 113/500 [00:49<01:26,  4.45it/s, train loss=0.822, val loss=0.769]\u001b[A\u001b[A\n",
      "\n",
      "Training:  23%|██▎       | 113/500 [00:49<01:26,  4.45it/s, train loss=0.83, val loss=0.778] \u001b[A\u001b[A\n",
      "\n",
      "Training:  23%|██▎       | 114/500 [00:49<01:26,  4.45it/s, train loss=0.81, val loss=0.785]\u001b[A\u001b[A\n",
      "\n",
      "Training:  23%|██▎       | 115/500 [00:49<01:26,  4.45it/s, train loss=0.81, val loss=0.789]\u001b[A\u001b[A\n",
      "\n",
      "Training:  23%|██▎       | 116/500 [00:49<01:26,  4.45it/s, train loss=0.811, val loss=0.794]\u001b[A\u001b[A\n",
      "\n",
      "Training:  23%|██▎       | 117/500 [00:49<01:25,  4.45it/s, train loss=0.808, val loss=0.783]\u001b[A\u001b[A\n",
      "\n",
      "Training:  24%|██▎       | 118/500 [00:49<00:56,  6.82it/s, train loss=0.808, val loss=0.783]\u001b[A\u001b[A\n",
      "\n",
      "Training:  24%|██▎       | 118/500 [00:49<00:56,  6.82it/s, train loss=0.808, val loss=0.777]\u001b[A\u001b[A\n",
      "\n",
      "Training:  24%|██▍       | 119/500 [00:49<00:55,  6.82it/s, train loss=0.808, val loss=0.778]\u001b[A\u001b[A\n",
      "\n",
      "Training:  24%|██▍       | 120/500 [00:49<00:55,  6.82it/s, train loss=0.806, val loss=0.78] \u001b[A\u001b[A\n",
      "\n",
      "Training:  24%|██▍       | 121/500 [00:49<00:55,  6.82it/s, train loss=0.815, val loss=0.771]\u001b[A\u001b[A\n",
      "\n",
      "Training:  24%|██▍       | 122/500 [00:49<00:55,  6.82it/s, train loss=0.815, val loss=0.786]\u001b[A\u001b[A\n",
      "\n",
      "Training:  25%|██▍       | 123/500 [00:49<00:38,  9.71it/s, train loss=0.815, val loss=0.786]\u001b[A\u001b[A\n",
      "\n",
      "Training:  25%|██▍       | 123/500 [00:49<00:38,  9.71it/s, train loss=0.805, val loss=0.787]\u001b[A\u001b[A\n",
      "\n",
      "Training:  25%|██▍       | 124/500 [00:49<00:38,  9.71it/s, train loss=0.806, val loss=0.77] \u001b[A\u001b[A\n",
      "\n",
      "Training:  25%|██▌       | 125/500 [00:49<00:38,  9.71it/s, train loss=0.818, val loss=0.817]\u001b[A\u001b[A\n",
      "\n",
      "Training:  25%|██▌       | 126/500 [00:49<00:38,  9.71it/s, train loss=0.815, val loss=0.778]\u001b[A\u001b[A\n",
      "\n",
      "Training:  25%|██▌       | 127/500 [00:50<00:38,  9.71it/s, train loss=0.803, val loss=0.788]\u001b[A\u001b[A\n",
      "\n",
      "Training:  26%|██▌       | 128/500 [00:50<00:28, 13.08it/s, train loss=0.803, val loss=0.788]\u001b[A\u001b[A\n",
      "\n",
      "Training:  26%|██▌       | 128/500 [00:50<00:28, 13.08it/s, train loss=0.824, val loss=0.812]\u001b[A\u001b[A\n",
      "\n",
      "Training:  26%|██▌       | 129/500 [00:50<00:28, 13.08it/s, train loss=0.803, val loss=0.787]\u001b[A\u001b[A\n",
      "\n",
      "Training:  26%|██▌       | 130/500 [00:50<00:28, 13.08it/s, train loss=0.81, val loss=0.778] \u001b[A\u001b[A\n",
      "\n",
      "Training:  26%|██▌       | 131/500 [00:50<00:28, 13.08it/s, train loss=0.815, val loss=0.777]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 132/500 [00:50<02:21,  2.60it/s, train loss=0.803, val loss=0.773]\u001b[A\u001b[A\n",
      "Training:  47%|████▋     | 235/500 [03:54<04:24,  1.00it/s, train loss=0.788, val loss=0.875]\n",
      "Training:  53%|█████▎    | 263/500 [02:19<02:05,  1.88it/s, train loss=0.782, val loss=0.856]\n",
      "Training:  32%|███▏      | 160/500 [00:54<01:55,  2.94it/s, train loss=0.789, val loss=0.879]\n",
      "Training:  25%|██▌       | 125/500 [00:44<00:20, 18.08it/s, train loss=0.784, val loss=0.919]\n",
      "Training:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   0%|          | 0/500 [00:00<?, ?it/s, train loss=0, val loss=0]\u001b[A\n",
      "Training:   0%|          | 1/500 [00:01<11:08,  1.34s/it, train loss=0, val loss=0]\u001b[A\n",
      "Training:   0%|          | 1/500 [00:01<11:08,  1.34s/it, train loss=2.22, val loss=2.25]\u001b[A\n",
      "Training:   0%|          | 2/500 [00:02<11:47,  1.42s/it, train loss=2.22, val loss=2.25]\u001b[A\n",
      "Training:   0%|          | 2/500 [00:02<11:47,  1.42s/it, train loss=1.81, val loss=1.81]\u001b[A\n",
      "Training:   1%|          | 3/500 [00:03<10:16,  1.24s/it, train loss=1.81, val loss=1.81]\u001b[A\n",
      "Training:   1%|          | 3/500 [00:03<10:16,  1.24s/it, train loss=1.51, val loss=1.51]\u001b[A\n",
      "Training:   1%|          | 4/500 [00:04<09:34,  1.16s/it, train loss=1.51, val loss=1.51]\u001b[A\n",
      "Training:   1%|          | 4/500 [00:04<09:34,  1.16s/it, train loss=1.26, val loss=1.25]\u001b[A\n",
      "Training:   1%|          | 5/500 [00:05<09:07,  1.11s/it, train loss=1.26, val loss=1.25]\u001b[A\n",
      "Training:   1%|          | 5/500 [00:05<09:07,  1.11s/it, train loss=1.06, val loss=1.07]\u001b[A\n",
      "Training:   1%|          | 6/500 [00:06<08:57,  1.09s/it, train loss=1.06, val loss=1.07]\u001b[A\n",
      "Training:   1%|          | 6/500 [00:06<08:57,  1.09s/it, train loss=0.978, val loss=0.97]\u001b[A\n",
      "Training:   1%|▏         | 7/500 [00:08<08:51,  1.08s/it, train loss=0.978, val loss=0.97]\u001b[A\n",
      "Training:   1%|▏         | 7/500 [00:08<08:51,  1.08s/it, train loss=0.931, val loss=0.941]\u001b[A\n",
      "Training:   2%|▏         | 8/500 [00:09<08:47,  1.07s/it, train loss=0.931, val loss=0.941]\u001b[A\n",
      "Training:   2%|▏         | 8/500 [00:09<08:47,  1.07s/it, train loss=0.91, val loss=0.945] \u001b[A\n",
      "Training:   2%|▏         | 9/500 [00:09<08:46,  1.07s/it, train loss=0.904, val loss=0.92]\u001b[A\n",
      "Training:   2%|▏         | 10/500 [00:10<06:42,  1.22it/s, train loss=0.904, val loss=0.92]\u001b[A\n",
      "Training:   2%|▏         | 10/500 [00:10<06:42,  1.22it/s, train loss=0.888, val loss=0.898]\u001b[A\n",
      "Training:   2%|▏         | 11/500 [00:11<07:05,  1.15it/s, train loss=0.888, val loss=0.898]\u001b[A\n",
      "Training:   2%|▏         | 11/500 [00:11<07:05,  1.15it/s, train loss=0.928, val loss=0.958]\u001b[A\n",
      "Training:   2%|▏         | 12/500 [00:11<07:04,  1.15it/s, train loss=0.886, val loss=0.95] \u001b[A\n",
      "Training:   3%|▎         | 13/500 [00:11<04:18,  1.89it/s, train loss=0.886, val loss=0.95]\u001b[A\n",
      "Training:   3%|▎         | 13/500 [00:11<04:18,  1.89it/s, train loss=0.846, val loss=0.88]\u001b[A\n",
      "Training:   3%|▎         | 14/500 [00:12<05:13,  1.55it/s, train loss=0.846, val loss=0.88]\u001b[A\n",
      "Training:   3%|▎         | 14/500 [00:12<05:13,  1.55it/s, train loss=0.84, val loss=0.884]\u001b[A\n",
      "Training:   3%|▎         | 15/500 [00:12<05:12,  1.55it/s, train loss=0.833, val loss=0.887]\u001b[A\n",
      "Training:   3%|▎         | 16/500 [00:12<03:19,  2.43it/s, train loss=0.833, val loss=0.887]\u001b[A\n",
      "Training:   3%|▎         | 16/500 [00:12<03:19,  2.43it/s, train loss=0.825, val loss=0.87] \u001b[A\n",
      "Training:   3%|▎         | 17/500 [00:13<04:28,  1.80it/s, train loss=0.825, val loss=0.87]\u001b[A\n",
      "Training:   3%|▎         | 17/500 [00:13<04:28,  1.80it/s, train loss=0.835, val loss=0.878]\u001b[A\n",
      "Training:   4%|▎         | 18/500 [00:13<04:28,  1.80it/s, train loss=0.817, val loss=0.861]\u001b[A\n",
      "Training:   4%|▍         | 19/500 [00:14<04:26,  1.81it/s, train loss=0.817, val loss=0.861]\u001b[A\n",
      "Training:   4%|▍         | 19/500 [00:14<04:26,  1.81it/s, train loss=0.85, val loss=0.912] \u001b[A\n",
      "Training:   4%|▍         | 20/500 [00:14<04:25,  1.81it/s, train loss=0.852, val loss=0.897]\u001b[A\n",
      "Training:   4%|▍         | 21/500 [00:14<03:00,  2.65it/s, train loss=0.852, val loss=0.897]\u001b[A\n",
      "Training:   4%|▍         | 21/500 [00:14<03:00,  2.65it/s, train loss=0.862, val loss=0.896]\u001b[A\n",
      "Training:   4%|▍         | 22/500 [00:14<03:00,  2.65it/s, train loss=0.817, val loss=0.86] \u001b[A\n",
      "Training:   5%|▍         | 23/500 [00:15<03:27,  2.30it/s, train loss=0.817, val loss=0.86]\u001b[A\n",
      "Training:   5%|▍         | 23/500 [00:15<03:27,  2.30it/s, train loss=0.816, val loss=0.86]\u001b[A\n",
      "Training:   5%|▍         | 24/500 [00:15<03:26,  2.30it/s, train loss=0.831, val loss=0.882]\u001b[A\n",
      "Training:   5%|▌         | 25/500 [00:15<02:28,  3.20it/s, train loss=0.831, val loss=0.882]\u001b[A\n",
      "Training:   5%|▌         | 25/500 [00:15<02:28,  3.20it/s, train loss=0.808, val loss=0.898]\u001b[A\n",
      "Training:   5%|▌         | 26/500 [00:15<02:28,  3.20it/s, train loss=0.821, val loss=0.868]\u001b[A\n",
      "Training:   5%|▌         | 27/500 [00:16<01:49,  4.30it/s, train loss=0.821, val loss=0.868]\u001b[A\n",
      "Training:  25%|██▌       | 125/500 [01:01<00:20, 18.08it/s, train loss=0.784, val loss=0.919][A\n",
      "Training:   6%|▌         | 28/500 [00:17<01:49,  4.30it/s, train loss=0.825, val loss=0.899]\u001b[A\n",
      "Training:   6%|▌         | 29/500 [00:17<02:37,  3.00it/s, train loss=0.825, val loss=0.899]\u001b[A\n",
      "Training:   6%|▌         | 29/500 [00:17<02:37,  3.00it/s, train loss=0.803, val loss=0.878]\u001b[A\n",
      "Training:   6%|▌         | 30/500 [00:17<02:36,  3.00it/s, train loss=0.862, val loss=0.966]\u001b[A\n",
      "Training:   6%|▌         | 31/500 [00:17<01:56,  4.02it/s, train loss=0.862, val loss=0.966]\u001b[A\n",
      "Training:   6%|▌         | 31/500 [00:17<01:56,  4.02it/s, train loss=0.848, val loss=0.965]\u001b[A\n",
      "Training:   6%|▋         | 32/500 [00:17<01:56,  4.02it/s, train loss=0.809, val loss=0.881]\u001b[A\n",
      "Training:   7%|▋         | 33/500 [00:17<01:29,  5.24it/s, train loss=0.809, val loss=0.881]\u001b[A\n",
      "Training:   7%|▋         | 33/500 [00:17<01:29,  5.24it/s, train loss=0.79, val loss=0.876] \u001b[A\n",
      "Training:   7%|▋         | 34/500 [00:17<01:28,  5.24it/s, train loss=0.805, val loss=0.88]\u001b[A\n",
      "Training:   7%|▋         | 35/500 [00:17<01:10,  6.62it/s, train loss=0.805, val loss=0.88]\u001b[A\n",
      "Training:   7%|▋         | 35/500 [00:17<01:10,  6.62it/s, train loss=0.827, val loss=0.88]\u001b[A\n",
      "Training:   7%|▋         | 36/500 [00:17<01:10,  6.62it/s, train loss=0.816, val loss=0.907]\u001b[A\n",
      "Training:   7%|▋         | 37/500 [00:17<00:57,  8.11it/s, train loss=0.816, val loss=0.907]\u001b[A\n",
      "Training:   7%|▋         | 37/500 [00:17<00:57,  8.11it/s, train loss=0.79, val loss=0.865] \u001b[A\n",
      "Training:   8%|▊         | 38/500 [00:17<00:56,  8.11it/s, train loss=0.79, val loss=0.843]\u001b[A\n",
      "Training:   8%|▊         | 39/500 [00:18<01:57,  3.92it/s, train loss=0.79, val loss=0.843]\u001b[A\n",
      "Training:   8%|▊         | 39/500 [00:18<01:57,  3.92it/s, train loss=0.816, val loss=0.892]\u001b[A\n",
      "Training:   8%|▊         | 40/500 [00:18<01:57,  3.92it/s, train loss=0.818, val loss=0.886]\u001b[A\n",
      "Training:   8%|▊         | 41/500 [00:18<01:30,  5.10it/s, train loss=0.818, val loss=0.886]\u001b[A\n",
      "Training:   8%|▊         | 41/500 [00:18<01:30,  5.10it/s, train loss=0.804, val loss=0.863]\u001b[A\n",
      "Training:   8%|▊         | 42/500 [00:18<01:29,  5.10it/s, train loss=0.791, val loss=0.869]\u001b[A\n",
      "Training:   9%|▊         | 43/500 [00:18<01:10,  6.46it/s, train loss=0.791, val loss=0.869]\u001b[A\n",
      "Training:   9%|▊         | 43/500 [00:18<01:10,  6.46it/s, train loss=0.789, val loss=0.877]\u001b[A\n",
      "Training:   9%|▉         | 44/500 [00:19<01:10,  6.46it/s, train loss=0.781, val loss=0.866]\u001b[A\n",
      "Training:   9%|▉         | 45/500 [00:19<00:57,  7.90it/s, train loss=0.781, val loss=0.866]\u001b[A\n",
      "Training:   9%|▉         | 45/500 [00:19<00:57,  7.90it/s, train loss=0.801, val loss=0.912]\u001b[A\n",
      "Training:   9%|▉         | 46/500 [00:19<00:57,  7.90it/s, train loss=0.793, val loss=0.871]\u001b[A\n",
      "Training:   9%|▉         | 47/500 [00:19<00:48,  9.40it/s, train loss=0.793, val loss=0.871]\u001b[A\n",
      "Training:   9%|▉         | 47/500 [00:19<00:48,  9.40it/s, train loss=0.772, val loss=0.852]\u001b[A\n",
      "Training:  10%|▉         | 48/500 [00:19<00:48,  9.40it/s, train loss=0.797, val loss=0.91] \u001b[A\n",
      "Training:  10%|▉         | 49/500 [00:19<00:41, 10.86it/s, train loss=0.797, val loss=0.91]\u001b[A\n",
      "Training:  10%|▉         | 49/500 [00:19<00:41, 10.86it/s, train loss=0.774, val loss=0.879]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 50/500 [00:19<00:41, 10.86it/s, train loss=0.787, val loss=0.89] \u001b[A\n",
      "Training:  10%|█         | 51/500 [00:19<00:36, 12.15it/s, train loss=0.787, val loss=0.89]\u001b[A\n",
      "Training:  10%|█         | 51/500 [00:19<00:36, 12.15it/s, train loss=0.796, val loss=0.909]\u001b[A\n",
      "Training:  10%|█         | 52/500 [00:19<00:36, 12.15it/s, train loss=0.781, val loss=0.87] \u001b[A\n",
      "Training:  11%|█         | 53/500 [00:19<00:33, 13.22it/s, train loss=0.781, val loss=0.87]\u001b[A\n",
      "Training:  11%|█         | 53/500 [00:19<00:33, 13.22it/s, train loss=0.803, val loss=0.873]\u001b[A\n",
      "Training:  11%|█         | 54/500 [00:19<00:33, 13.22it/s, train loss=0.824, val loss=0.901]\u001b[A\n",
      "Training:  11%|█         | 55/500 [00:19<00:31, 14.16it/s, train loss=0.824, val loss=0.901]\u001b[A\n",
      "Training:  11%|█         | 55/500 [00:19<00:31, 14.16it/s, train loss=0.793, val loss=0.946]\u001b[A\n",
      "Training:  11%|█         | 56/500 [00:19<00:31, 14.16it/s, train loss=0.769, val loss=0.863]\u001b[A\n",
      "Training:  11%|█▏        | 57/500 [00:19<00:29, 14.87it/s, train loss=0.769, val loss=0.863]\u001b[A\n",
      "Training:  11%|█▏        | 57/500 [00:19<00:29, 14.87it/s, train loss=0.776, val loss=0.88] \u001b[A\n",
      "Training:  12%|█▏        | 58/500 [00:19<00:29, 14.87it/s, train loss=0.814, val loss=0.988]\u001b[A\u001b[43m\u001b[31m____PROCESS0 for NN_filename=[array([0.0001]), array([100]), array([0.0001])]has finished training pydelfi____\u001b[0m\n",
      "\n",
      "Training:  12%|█▏        | 58/500 [00:36<00:29, 14.87it/s, train loss=0.814, val loss=0.988]\u001b[ARemoved no burn in\n",
      "Training:  12%|█▏        | 58/500 [08:32<1:05:02,  8.83s/it, train loss=0.814, val loss=0.988]Figure(1200x1200)\n",
      "Removed no burn in\n",
      "Removed no burn in\n",
      "\u001b[41m\u001b[33m____PROCESS0 for NN_filename=[array([0.0001]), array([100]), array([0.0001])]has finished____\u001b[0m\n",
      "\n",
      "./pydelfi_t1/delfi.py:632: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(xtl, rotation=45)\n",
      "Training:  25%|██▌       | 125/500 [09:20<28:01,  4.48s/it, train loss=0.784, val loss=0.919]"
     ]
    }
   ],
   "source": [
    "all_real_data = True\n",
    "if all_real_data == True:\n",
    "    for k in range (1):\n",
    "        np.save('real_data_element',k)\n",
    "        if MPI_process == True:\n",
    "            !mpiexec -np 1 python LFI.py\n",
    "        else:\n",
    "            %run LFI.py\n",
    "        dest = '../LFI_results/results_pydelfi_{}'.format(k)\n",
    "        if os.path.isdir(dest) == True:\n",
    "            for file in glob.glob('../results_pydelfi/*'):\n",
    "                shutil.move(file, dest)\n",
    "        else:\n",
    "            os.rename('../results_pydelfi',dest)\n",
    "    os.remove('real_data_element.npy')\n",
    "else:\n",
    "    if MPI_process == True:\n",
    "        !mpiexec -np 1 python LFI.py\n",
    "    else:\n",
    "        %run LFI.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
